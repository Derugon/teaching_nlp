{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/Copie_de_M2-ATAL-2021-22_02_NER_with_BiLSTM_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWNr2Oc6qJHX"
      },
      "source": [
        "---\n",
        "#¬†Recent Advances in Sequence Labeling from Deep Learning Models\n",
        "\n",
        "Les approches pour l'√©tiquetage de s√©quence fond√©es sur les r√©seaux de neurones profonds compte trois √©tapes :\n",
        "1. The embedding module is the first stage that maps words into their distributed representations (pretrained word embeddings, character-\n",
        "level representations, hand-crafted features and sentence-level\n",
        "representations). \n",
        "2. The context encoder module extracts contextual features (e.g. RNN/Bi-LSTM, CNN)\n",
        "3. and the inference module predict labels and generate optimal label sequence as output of the model (e.g. SoftMax, CRF, RNN). \n",
        "\n",
        "[Zhiyong He, Zanbo Wang, Sheng Jiang. A Survey on Recent Advances in Sequence Labeling from Deep Learning Models. Published 13 November 2020. Computer Science. ArXiv](https://arxiv.org/pdf/2011.06727.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0boga_k7vMTc"
      },
      "source": [
        "---\n",
        "# Bref historique des syst√®mes de NER neuronaux\n",
        "\n",
        "On ne vous demande pas de lire les articles suivants mais √† minima de lire ce bref historique et de jeter un oeil aux sections 2.2 √† 2.5 de (Huang et al., 2015) pour comprendre le mod√®le Bi-LSTM_CRF.\n",
        "\n",
        "* L'architecture \"SENNA\", novatrice dans l'id√©e de la r√©solution des t√¢ches du TAL avec un mod√®le de langue neuronal (incluant notamment une m√©thode de construction de \"pretrained word embeddings\") : R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P. Kuksa. Natural Language Processing (Almost) from Scratch, Journal of Machine Learning Research (JMLR), 2011. ; [[article]](http://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf) ; [[impl√©mentation]](https://ronan.collobert.com/senna/)\n",
        "* Premier article √† appliquer les BiLSTM-CRF au NER : Zhiheng Huang, Wei Xu, Kai Yu, Bidirectional LSTM-CRF Models for Sequence Tagging, Arxiv, Computation and Language, Submitted on 9 Aug 2015 ; [[article]](https://arxiv.org/pdf/1508.01991.pdf) ; [[impl√©mentation1]](https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html) (tutoriel avanc√© de pytorch) ; [[impl√©mentation2]](https://github.com/ZubinGou/NER-BiLSTM-CRF-PyTorch) (inclut aussi un mod√®le Bi-LSTM-CNN-CRF) ; [[impl√©mentation3]](https://github.com/jidasheng/bi-lstm-crf)  ; [[impl√©mentation4]](http://www.gabormelli.com/RKB/index.php?title=Bidirectional_LSTM/CRF_(BiLTSM-CRF)_Training_System) ; [[impl√©mentation5]](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html) (avec tensorflow)\n",
        "* BiLSTM-CNN-CRF Implementation for Sequence Tagging (extension with the ELMo representations) : Reimers, Nils, and Gurevych, Iryna, Reporting Score Distributions Makes a Difference: Performance Study of LSTM-networks for Sequence Tagging, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP), September 2017, Copenhagen, Denmark, 338-348 ; [[article]](http://aclweb.org/anthology/D17-1035) ; [[impl√©mentation]](https://github.com/UKPLab/emnlp2017-bilstm-cnn-crf)\n",
        "* Le 3e mod√®le le plus performant en 2020 sur la t√¢che NER sans ressources externes : Ying Luo, Fengshun Xiao, and Hai Zhao. Hierarchical contextualized representation for named entity recognition. In AAAI, pages 8441‚Äì8448, 2020 ; [[impl√©mentation]](https://github.com/cslydia/Hire-NER) ; Utilise [NCRF++: An Open-source Neural Sequence Labeling Toolkit](https://github.com/jiesutd/NCRFpp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inik1ZFZ2tOa"
      },
      "source": [
        "---\n",
        "#¬†Bidirectional LSTM-CRF Impl√©mentation de (Huang et al., 2015)\n",
        "\n",
        "Le code dans les cellules suivantes provient de l'[impl√©mentation 3](https://github.com/jidasheng/bi-lstm-crf/) de (Huang et al., 2015). Celle-ci s'appuie sur la biblioth√®que pytorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLo59Npr9S5-"
      },
      "source": [
        "\n",
        "### VOTRE TRAVAIL \n",
        "* Ex√©cutez les cellules sans passer trop de temps √† comprendre les d√©tails de l'impl√©mentation. R√©pondez aux questions quand vous y √™tes invit√©.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZoON5ru4-Ed"
      },
      "source": [
        "##¬†Installation des d√©pendances \n",
        "\n",
        "Passez en type d'ex√©cution \"gpu\". Plus tard vous ferez un test en type \"None\" c'est-√†-dire \"cpu\" afin d'avoir une id√©e des temps d'entra√Ænement de l'architecture.\n",
        "\n",
        "üí° La cellule suivante requiert 2 ex√©cutions. Executez la une fois puis lancer une ex√©cution de \"tout\". Vous gagnerez un peu de temps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr7DMncsp_uN",
        "outputId": "2463fdf5-1b90-4b24-cc25-37341433fd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 748.8 MB 16 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.9 MB 21.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n"
          ]
        }
      ],
      "source": [
        "#¬†https://stackoverflow.com/questions/54358280/packed-padded-sequence-gives-error-when-used-with-gpu\n",
        "!pip install torch==1.6.0 torchvision==0.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQK2lrEy5PSH"
      },
      "source": [
        "V√©rifie que le hardware de votre machine dispose d'un gpu. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOVf1iODp5Gj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Get cpu or gpu device for training.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSzPQYDlMtsu"
      },
      "source": [
        "## D√©finition d'une cellule neuronale CRF \n",
        "\n",
        "* Trouve la s√©quence d'√©tiquettes la plus probable correspondant √† une s√©quence de mots donn√©e\n",
        "* Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/model/crf.py\n",
        "* A l'aide d'un treillis mots x etiquettes, l'_algorithme Viterbi_ retourne la s√©quence d'√©tiquettes la plus probables pour une s√©quence de mots (d'une phrase) donn√©e.\n",
        "* Les _probabilit√©s de transition_ sont des probabilit√©s conditionnelles. Il s'agit de la probabilit√© d'avoir une √©tiquette sachant 1 historique d'√©tiquettes `P(t_i|t_i-1)` (ici dans un mod√®le bigramme). Les _probabilit√©s d'√©mission_ sont les probabilit√©s des mots `P(w_i | t_i)` √† √™tre g√©n√©r√©s par leur propre √©tiquette. \n",
        "* En savoir plus sur le [\"Sequence Labeling\"](https://courses.engr.illinois.edu/cs447/fa2018/Slides/Lecture07.pdf). \n",
        "* En savoir plus sur le [\"CRF\"](http://www.cs.columbia.edu/~mcollins/crf.pdf).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kyEIEbBGMp8j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def log_sum_exp(x):\n",
        "    \"\"\"calculate log(sum(exp(x))) = max(x) + log(sum(exp(x - max(x))))\n",
        "    \"\"\"\n",
        "    max_score = x.max(-1)[0]\n",
        "    return max_score + (x - max_score.unsqueeze(-1)).exp().sum(-1).log()\n",
        "\n",
        "\n",
        "IMPOSSIBLE = -1e4\n",
        "\n",
        "class CRF(nn.Module):\n",
        "    \"\"\"General CRF module.\n",
        "    The CRF module contain a inner Linear Layer which transform the input from features space to tag space.\n",
        "\n",
        "    :param in_features: number of features for the input\n",
        "    :param num_tag: number of tags. DO NOT include START, STOP tags, they are included internal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, num_tags):\n",
        "        super(CRF, self).__init__()\n",
        "\n",
        "        self.num_tags = num_tags + 2\n",
        "        self.start_idx = self.num_tags - 2\n",
        "        self.stop_idx = self.num_tags - 1\n",
        "\n",
        "        self.fc = nn.Linear(in_features, self.num_tags)\n",
        "\n",
        "        # transition factor, Tij mean transition from j to i\n",
        "        self.transitions = nn.Parameter(torch.randn(self.num_tags, self.num_tags), requires_grad=True)\n",
        "        self.transitions.data[self.start_idx, :] = IMPOSSIBLE\n",
        "        self.transitions.data[:, self.stop_idx] = IMPOSSIBLE\n",
        "\n",
        "    def forward(self, features, masks):\n",
        "        \"\"\"decode tags\n",
        "\n",
        "        :param features: [B, L, C], batch of unary scores\n",
        "        :param masks: [B, L] masks\n",
        "        :return: (best_score, best_paths)\n",
        "            best_score: [B]\n",
        "            best_paths: [B, L]\n",
        "        \"\"\"\n",
        "        features = self.fc(features)\n",
        "        return self.__viterbi_decode(features, masks[:, :features.size(1)].float())\n",
        "\n",
        "    def loss(self, features, ys, masks):\n",
        "        \"\"\"negative log likelihood loss\n",
        "        B: batch size, L: sequence length, D: dimension\n",
        "\n",
        "        :param features: [B, L, D]\n",
        "        :param ys: tags, [B, L]\n",
        "        :param masks: masks for padding, [B, L]\n",
        "        :return: loss\n",
        "        \"\"\"\n",
        "        features = self.fc(features)\n",
        "\n",
        "        L = features.size(1)\n",
        "        masks_ = masks[:, :L].float()\n",
        "\n",
        "        forward_score = self.__forward_algorithm(features, masks_)\n",
        "        gold_score = self.__score_sentence(features, ys[:, :L].long(), masks_)\n",
        "        loss = (forward_score - gold_score).mean()\n",
        "        return loss\n",
        "\n",
        "    def __score_sentence(self, features, tags, masks):\n",
        "        \"\"\"Gives the score of a provided tag sequence\n",
        "\n",
        "        :param features: [B, L, C]\n",
        "        :param tags: [B, L]\n",
        "        :param masks: [B, L]\n",
        "        :return: [B] score in the log space\n",
        "        \"\"\"\n",
        "        B, L, C = features.shape\n",
        "\n",
        "        # emission score\n",
        "        emit_scores = features.gather(dim=2, index=tags.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # transition score\n",
        "        start_tag = torch.full((B, 1), self.start_idx, dtype=torch.long, device=tags.device)\n",
        "        tags = torch.cat([start_tag, tags], dim=1)  # [B, L+1]\n",
        "        trans_scores = self.transitions[tags[:, 1:], tags[:, :-1]]\n",
        "\n",
        "        # last transition score to STOP tag\n",
        "        last_tag = tags.gather(dim=1, index=masks.sum(1).long().unsqueeze(1)).squeeze(1)  # [B]\n",
        "        last_score = self.transitions[self.stop_idx, last_tag]\n",
        "\n",
        "        score = ((trans_scores + emit_scores) * masks).sum(1) + last_score\n",
        "        return score\n",
        "\n",
        "    def __viterbi_decode(self, features, masks):\n",
        "        \"\"\"decode to tags using viterbi algorithm\n",
        "\n",
        "        :param features: [B, L, C], batch of unary scores\n",
        "        :param masks: [B, L] masks\n",
        "        :return: (best_score, best_paths)\n",
        "            best_score: [B]\n",
        "            best_paths: [B, L]\n",
        "        \"\"\"\n",
        "        B, L, C = features.shape\n",
        "\n",
        "        bps = torch.zeros(B, L, C, dtype=torch.long, device=features.device)  # back pointers\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        max_score = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
        "        max_score[:, self.start_idx] = 0\n",
        "\n",
        "        for t in range(L):\n",
        "            mask_t = masks[:, t].unsqueeze(1)  # [B, 1]\n",
        "            emit_score_t = features[:, t]  # [B, C]\n",
        "\n",
        "            # [B, 1, C] + [C, C]\n",
        "            acc_score_t = max_score.unsqueeze(1) + self.transitions  # [B, C, C]\n",
        "            acc_score_t, bps[:, t, :] = acc_score_t.max(dim=-1)\n",
        "            acc_score_t += emit_score_t\n",
        "            max_score = acc_score_t * mask_t + max_score * (1 - mask_t)  # max_score or acc_score_t\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        max_score += self.transitions[self.stop_idx]\n",
        "        best_score, best_tag = max_score.max(dim=-1)\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_paths = []\n",
        "        bps = bps.cpu().numpy()\n",
        "        for b in range(B):\n",
        "            best_tag_b = best_tag[b].item()\n",
        "            seq_len = int(masks[b, :].sum().item())\n",
        "\n",
        "            best_path = [best_tag_b]\n",
        "            for bps_t in reversed(bps[b, :seq_len]):\n",
        "                best_tag_b = bps_t[best_tag_b]\n",
        "                best_path.append(best_tag_b)\n",
        "            # drop the last tag and reverse the left\n",
        "            best_paths.append(best_path[-2::-1])\n",
        "\n",
        "        return best_score, best_paths\n",
        "\n",
        "    def __forward_algorithm(self, features, masks):\n",
        "        \"\"\"calculate the partition function with forward algorithm.\n",
        "        TRICK: log_sum_exp([x1, x2, x3, x4, ...]) = log_sum_exp([log_sum_exp([x1, x2]), log_sum_exp([x3, x4]), ...])\n",
        "\n",
        "        :param features: features. [B, L, C]\n",
        "        :param masks: [B, L] masks\n",
        "        :return:    [B], score in the log space\n",
        "        \"\"\"\n",
        "        B, L, C = features.shape\n",
        "\n",
        "        scores = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
        "        scores[:, self.start_idx] = 0.\n",
        "        trans = self.transitions.unsqueeze(0)  # [1, C, C]\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for t in range(L):\n",
        "            emit_score_t = features[:, t].unsqueeze(2)  # [B, C, 1]\n",
        "            score_t = scores.unsqueeze(1) + trans + emit_score_t  # [B, 1, C] + [1, C, C] + [B, C, 1] => [B, C, C]\n",
        "            score_t = log_sum_exp(score_t)  # [B, C]\n",
        "\n",
        "            mask_t = masks[:, t].unsqueeze(1)  # [B, 1]\n",
        "            scores = score_t * mask_t + scores * (1 - mask_t)\n",
        "        scores = log_sum_exp(scores + self.transitions[self.stop_idx])\n",
        "        return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byc18sR5FNSu"
      },
      "source": [
        "### VOTRE TRAVAIL\n",
        "\n",
        "Dans GColab, Faire Outils > Param√®tres > Cocher \"affichage de la num√©rotation des lignes\"\n",
        "\n",
        "* Quel est le nom de la _loss function_ ? A quelle ligne est-ce sp√©cifi√©e ?\n",
        "* En quelques mots, √† quoi sert l'algorithme de Viterbi ? Cherchez sur le web...\n",
        "\n",
        "Eventuellement, en apprendre davantage sur quelques [_loss functions_](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZZnpMvM20E"
      },
      "source": [
        "## D√©finition d'une architecture neuronale Bi-LSTM CRF\n",
        "\n",
        "La classe suivante impl√©mente un mod√®le Bi-LSTM CRF\n",
        "- Construction des embeddings de la s√©quence\n",
        "- Capture du contexte avec une cellule RNN \n",
        "- Pr√©diction de la s√©quence d'√©tiquetage √† l'aide de la cellule CRF qui prend comme input la sortie du RNN\n",
        "\n",
        "Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/model/model.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvjvPnHDM3Nx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class BiRnnCrf(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, num_rnn_layers=1, rnn=\"lstm\"):\n",
        "        super(BiRnnCrf, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tagset_size = tagset_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        RNN = nn.LSTM if rnn == \"lstm\" else nn.GRU\n",
        "        self.rnn = RNN(embedding_dim, hidden_dim // 2, num_layers=num_rnn_layers,\n",
        "                       bidirectional=True, batch_first=True)\n",
        "        self.crf = CRF(hidden_dim, self.tagset_size)\n",
        "\n",
        "    def __build_features(self, sentences):\n",
        "        masks = sentences.gt(0)\n",
        "        embeds = self.embedding(sentences.long())\n",
        "        \n",
        "        seq_length = masks.sum(1)\n",
        "        sorted_seq_length, perm_idx = seq_length.sort(descending=True)\n",
        "        embeds = embeds[perm_idx, :]\n",
        "\n",
        "        pack_sequence = pack_padded_sequence(embeds, lengths=sorted_seq_length,  batch_first=True)\n",
        "        packed_output, _ = self.rnn(pack_sequence)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        _, unperm_idx = perm_idx.sort()\n",
        "        lstm_out = lstm_out[unperm_idx, :]\n",
        "        return lstm_out, masks\n",
        "\n",
        "    def loss(self, xs, tags):\n",
        "        features, masks = self.__build_features(xs)\n",
        "        loss = self.crf.loss(features, tags, masks=masks)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, xs):\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        features, masks = self.__build_features(xs)\n",
        "        scores, tag_seq = self.crf(features, masks)\n",
        "        return scores, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons test√© un mod√®le construit sur le **fran√ßais**. Il ne fait pas partie de ceux de la gensim-data mais il fait parti des [mod√®les mis √† disposition par Jean-Philippe Fauconnier](https://fauconnier.github.io/#data)."
      ],
      "metadata": {
        "id": "98cnIwBhdCUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin -P embeddings\n",
        "#!wget -nc https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_500_skip_cut100.bin -P embeddings"
      ],
      "metadata": {
        "id": "u6B8Fl40c-b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¬†Chargement du mod√®le d'embeddings pr√©-entra√Æn√©s\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "w2v_pretrained_embeddings_path = \"embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin\"\n",
        "#w2v_pretrained_embeddings_path = \"embeddings/frWac_non_lem_no_postag_no_phrase_500_skip_cut100.bin\"\n",
        "\n",
        "w2v_pretrained_embeddings = KeyedVectors.load_word2vec_format(w2v_pretrained_embeddings_path, binary=True, unicode_errors=\"ignore\")\n",
        "#print (w2v_pretrained_embeddings.vectors[0])\n",
        "print ('#vocab',len(w2v_pretrained_embeddings.vectors))\n",
        "w2v_pretrained_embeddings_vocab = list(w2v_pretrained_embeddings.vocab)\n",
        "\n",
        "import torch\n",
        "weights = torch.FloatTensor(w2v_pretrained_embeddings.vectors) \n",
        "#print (weights[0])\n",
        "# export vocab au format bi_lstm_crf \n",
        "with open('data/w2v_pretrained_embeddings_vocab.json', 'w', encoding='utf-8') as f:\n",
        "  json.dump(w2v_pretrained_embeddings_vocab, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "AYS7fUlbdJ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class BiRnnCrf(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, num_rnn_layers=1, rnn=\"lstm\"):\n",
        "        super(BiRnnCrf, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tagset_size = tagset_size\n",
        "\n",
        "#        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding = embedding = nn.Embedding.from_pretrained(weights)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        # Get embeddings for index 1\n",
        "        #input = torch.LongTensor([1])\n",
        "        #embedding(input)\n",
        "\n",
        "\n",
        "\n",
        "        RNN = nn.LSTM if rnn == \"lstm\" else nn.GRU\n",
        "        self.rnn = RNN(embedding_dim, hidden_dim // 2, num_layers=num_rnn_layers,\n",
        "                       bidirectional=True, batch_first=True)\n",
        "        self.crf = CRF(hidden_dim, self.tagset_size)\n",
        "\n",
        "    def __build_features(self, sentences):\n",
        "        masks = sentences.gt(0)\n",
        "        embeds = self.embedding(sentences.long())\n",
        "        \n",
        "        seq_length = masks.sum(1)\n",
        "        sorted_seq_length, perm_idx = seq_length.sort(descending=True)\n",
        "        embeds = embeds[perm_idx, :]\n",
        "\n",
        "        pack_sequence = pack_padded_sequence(embeds, lengths=sorted_seq_length,  batch_first=True)\n",
        "        packed_output, _ = self.rnn(pack_sequence)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        _, unperm_idx = perm_idx.sort()\n",
        "        lstm_out = lstm_out[unperm_idx, :]\n",
        "        return lstm_out, masks\n",
        "\n",
        "    def loss(self, xs, tags):\n",
        "        features, masks = self.__build_features(xs)\n",
        "        loss = self.crf.loss(features, tags, masks=masks)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, xs):\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        features, masks = self.__build_features(xs)\n",
        "        scores, tag_seq = self.crf(features, masks)\n",
        "        return scores, tag_seq"
      ],
      "metadata": {
        "id": "5Be3aoXkc1lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcA7yrXSDkPP"
      },
      "source": [
        "### VOTRE TRAVAIL\n",
        "\n",
        "Dans GColab, Faire Outils > Param√®tres > Cocher \"affichage de la num√©rotation des lignes\"\n",
        "\n",
        "* Une couche d'[Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) est une table qui associe √† un mot du vocabulaire (en fait son indice num√©rique) un vecteur d'embeddings. Les valeurs des embeddings sont initialement tir√©es al√©atoirement. Elles peuvent √™tre surcharg√©es en chargeant des embeddings pre-entra√Æn√©es avec Word2Vec, Glove ou FastText par exemple. Par d√©faut (`embedding.weight.requires_grad = True`), ces vecteurs seront consid√©r√©s comme des param√®tres du mod√®le et ils seront \"_fine-tuned_\" durant l'entra√Ænement (`train`) par _\"backpropagation\"_. Indiquez le num√©ro de ligne qui d√©finit la couche d'embedding et celui de la ligne o√π les embeddings sont initialis√©es. \n",
        "Plus d'information sur [embedding-in-pytorch](https://stackoverflow.com/questions/50747947/embedding-in-pytorch) (stackoverflow).\n",
        "* L'impl√©mentation offre deux types de cellules RNN possibles. Indiquez la ligne o√π ce choix est possible. Indiquez la ligne qui sp√©cifie le choix par d√©faut.\n",
        "* Apr√®s la repr√©sentation en embeddings des phrase et avant le passage √† la cellule RNN, quel type de traitement est r√©alis√© ? Indiquez le num√©ro de ligne o√π ce traitement est sp√©cifi√©. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGl1Xe3C9rVd"
      },
      "source": [
        "---\n",
        "##¬†D√©finition des pr√©traitement des donn√©es \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViLNx_efOyez"
      },
      "source": [
        "D'abord la d√©finition de m√©thodes \"utils\" pour la phase de pr√©traitement √† savoir la sauvegarde et le chargement de fichiers de configuration e.g. vocabulaire, jeu d'√©tiquettes, param√®tres du mod√®le neuronal (dimension des embeddings...), partition des donn√©es g√©n√©r√©es...\n",
        "\n",
        "Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/app/preprocessing/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hUPqw3j6Oyte"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "\n",
        "PAD = \"<PAD>\"\n",
        "OOV = \"<OOV>\"\n",
        "\n",
        "\n",
        "def save_json_file(obj, file_path):\n",
        "    with open(file_path, \"w\", encoding=\"utf8\") as f:\n",
        "        f.write(json.dumps(obj, ensure_ascii=False))\n",
        "\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    with open(file_path, encoding=\"utf8\") as f:\n",
        "        return json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhsxcoePO-4C"
      },
      "source": [
        "Puis la classe de pr√©-traitement des donn√©es qui sera initialis√© √† l'aide des chemins des fichiers contenant le vocabulaire, le jeu d'√©tiquettes et les donn√©es annot√©es (phrases d√©coup√©es en mots avec √©tiquettes). Outre charger ces fichiers de configuration et donn√©es, la classe partitionne les donn√©es en ensemble d'entrainement, de validation et de tests (d'apr√®s les param√®tres sp√©cifi√©s par d√©faut ou √† l'appel du syst√®me). Les donn√©es sont aussi \"vectoris√©es\". Il s'agit essentiellement d'une substitution des mots des phrases par leur identifiant num√©rique correspondant √† une entr√©e dans le vocabulaire donn√©.\n",
        "\n",
        "https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/app/preprocessing/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyRopi-JO799"
      },
      "outputs": [],
      "source": [
        "from os.path import join, exists\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "#FILE_VOCAB = \"vocab.json\"\n",
        "#FILE_TAGS = \"tags.json\"\n",
        "#FILE_DATASET = \"dataset.txt\"\n",
        "#FILE_DATASET_CACHE = \"dataset_cache_{}.npz\"\n",
        "\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, config_dir, save_config_dir=None, verbose=True):\n",
        "        self.config_dir = config_dir\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.vocab, self.vocab_dict = self.__load_list_file(FILE_VOCAB, offset=1, verbose=verbose)\n",
        "        self.tags, self.tags_dict = self.__load_list_file(FILE_TAGS, verbose=verbose)\n",
        "        if save_config_dir:\n",
        "            self.__save_config(save_config_dir)\n",
        "\n",
        "        self.PAD_IDX = 0\n",
        "        self.OOV_IDX = len(self.vocab)\n",
        "        self.__adjust_vocab()\n",
        "\n",
        "    def __load_list_file(self, file_name, offset=0, verbose=False):\n",
        "        file_path = join(self.config_dir, file_name)\n",
        "        if not exists(file_path):\n",
        "            raise ValueError('\"{}\" file does not exist.'.format(file_path))\n",
        "        else:\n",
        "            elements = load_json_file(file_path)\n",
        "            elements_dict = {w: idx + offset for idx, w in enumerate(elements)}\n",
        "            if verbose:\n",
        "                print(\"config {} loaded\".format(file_path))\n",
        "            return elements, elements_dict\n",
        "\n",
        "    def __adjust_vocab(self):\n",
        "        self.vocab.insert(0, PAD)\n",
        "        self.vocab_dict[PAD] = 0\n",
        "\n",
        "        self.vocab.append(OOV)\n",
        "        self.vocab_dict[OOV] = len(self.vocab) - 1\n",
        "\n",
        "    def __save_config(self, dst_dir):\n",
        "        char_file = join(dst_dir, FILE_VOCAB)\n",
        "        save_json_file(self.vocab, char_file)\n",
        "\n",
        "        tag_file = join(dst_dir, FILE_TAGS)\n",
        "        save_json_file(self.tags, tag_file)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"tag dict file => {}\".format(tag_file))\n",
        "            print(\"tag dict file => {}\".format(char_file))\n",
        "\n",
        "    @staticmethod\n",
        "    def __cache_file_path(corpus_dir, max_seq_len):\n",
        "        return join(corpus_dir, FILE_DATASET_CACHE.format(max_seq_len))\n",
        "\n",
        "    def load_dataset(self, corpus_dir, val_split, test_split, max_seq_len):\n",
        "        \"\"\"load the train set\n",
        "        :return: (xs, ys)\n",
        "            xs: [B, L]\n",
        "            ys: [B, L, C]\n",
        "        \"\"\"\n",
        "        ds_path = self.__cache_file_path(corpus_dir, max_seq_len)\n",
        "        if not exists(ds_path):\n",
        "            xs, ys = self.__build_corpus(corpus_dir, max_seq_len)\n",
        "        else:\n",
        "            print(\"loading dataset {} ...\".format(ds_path))\n",
        "            dataset = np.load(ds_path)\n",
        "            xs, ys = dataset[\"xs\"], dataset[\"ys\"]\n",
        "\n",
        "        xs, ys = map(\n",
        "            torch.tensor, (xs, ys)\n",
        "        )\n",
        "\n",
        "        # split the dataset\n",
        "        total_count = len(xs)\n",
        "        assert total_count == len(ys)\n",
        "        val_count = int(total_count * val_split)\n",
        "        test_count = int(total_count * test_split)\n",
        "        train_count = total_count - val_count - test_count\n",
        "        assert train_count > 0 and val_count > 0\n",
        "\n",
        "        indices = np.cumsum([0, train_count, val_count, test_count])\n",
        "        datasets = [(xs[s:e], ys[s:e]) for s, e in zip(indices[:-1], indices[1:])]\n",
        "        print(\"datasets loaded:\")\n",
        "        for (xs_, ys_), name in zip(datasets, [\"train\", \"val\", \"test\"]):\n",
        "            print(\"\\t{}: {}, {}\".format(name, xs_.shape, ys_.shape))\n",
        "        return datasets\n",
        "\n",
        "    def decode_tags(self, batch_tags):\n",
        "        batch_tags = [\n",
        "            [self.tags[t] for t in tags]\n",
        "            for tags in batch_tags\n",
        "        ]\n",
        "        return batch_tags\n",
        "\n",
        "    def sent_to_vector(self, sentence, max_seq_len=0):\n",
        "        max_seq_len = max_seq_len if max_seq_len > 0 else len(sentence)\n",
        "        for c in sentence[:max_seq_len]:\n",
        "          if not(c in self.vocab_dic):\n",
        "            print ('c not in vocab')\n",
        "        vec = [self.vocab_dict.get(c, self.OOV_IDX) for c in sentence[:max_seq_len]]\n",
        "\n",
        "        return vec + [self.PAD_IDX] * (max_seq_len - len(vec))\n",
        "\n",
        "    def tags_to_vector(self, tags, max_seq_len=0):\n",
        "        max_seq_len = max_seq_len if max_seq_len > 0 else len(tags)\n",
        "        vec = [self.tags_dict[c] for c in tags[:max_seq_len]]\n",
        "        return vec + [0] * (max_seq_len - len(vec))\n",
        "\n",
        "    def __build_corpus(self, corpus_dir, max_seq_len):\n",
        "      #¬†remove cache files !!!\n",
        "        file_path = join(corpus_dir, FILE_DATASET)\n",
        "        xs, ys = [], []\n",
        "        with open(file_path, encoding=\"utf8\") as f:\n",
        "            for idx, line in tqdm(enumerate(f), desc=\"parsing {}\".format(file_path)):\n",
        "                fields = line.strip().split(\"\\t\")\n",
        "                if len(fields) != 2:\n",
        "                    raise ValueError(\"format error in line {}, tabs count: {}\".format(idx + 1, len(fields) - 1))\n",
        "\n",
        "                sentence, tags = fields\n",
        "\n",
        "\n",
        "                try:\n",
        "                    if sentence[0] == \"[\":\n",
        "                        sentence = json.loads(sentence)\n",
        "                    tags = json.loads(tags)\n",
        "\n",
        "                    #print ('Debug: sentence', sentence)\n",
        "                    #print ('Debug: tags', tags)\n",
        "\n",
        "                    xs.append(self.sent_to_vector(sentence, max_seq_len=max_seq_len))\n",
        "                    ys.append(self.tags_to_vector(tags, max_seq_len=max_seq_len))\n",
        "                    if len(sentence) != len(tags):\n",
        "                        raise ValueError('\"sentence length({})\" != \"tags length({})\" in line {}\"'.format(\n",
        "                            len(sentence), len(tags), idx + 1))\n",
        "                except Exception as e:\n",
        "                    raise ValueError(\"exception raised when parsing line {}\\n\\t{}\\n\\t{}\".format(idx + 1, line, e))\n",
        "\n",
        "        xs, ys = np.asarray(xs), np.asarray(ys)\n",
        "\n",
        "        # save train set\n",
        "        cache_file = self.__cache_file_path(corpus_dir, max_seq_len)\n",
        "        np.savez(cache_file, xs=xs, ys=ys)\n",
        "        print(\"dataset cache({}, {}) => {}\".format(xs.shape, ys.shape, cache_file))\n",
        "        return xs, ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS9TOT0hPgd4"
      },
      "source": [
        "## D√©finition du mod√®le et de la m√©thode d'entra√Ænement \n",
        "\n",
        "D'abord la d√©finition de la m√©thode qui instancie l'architecture. Les fichiers associ√©s (_model_ et _arguments_) seront sauv√©s (ou charg√©s si un pr√©c√©dent entra√Ænement a d√©j√† eu lieu)  depuis _model_dir_.\n",
        "\n",
        "Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/app/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oQjVXdb8Pdjp"
      },
      "outputs": [],
      "source": [
        "from os.path import exists, join\n",
        "import torch\n",
        "\n",
        "#FILE_ARGUMENTS = \"arguments.json\"\n",
        "#FILE_MODEL = \"model.pth\"\n",
        "\n",
        "def arguments_filepath(model_dir):\n",
        "    return join(model_dir, FILE_ARGUMENTS)\n",
        "\n",
        "\n",
        "def model_filepath(model_dir):\n",
        "    return join(model_dir, FILE_MODEL)\n",
        "\n",
        "\n",
        "def build_model(args, processor, load=True, verbose=False):\n",
        "  # NH FIX not actived rnn_type by adding rnn=args['rnn_type']\n",
        "    model = BiRnnCrf(len(processor.vocab), len(processor.tags), embedding_dim=args['embedding_dim'], hidden_dim=args['hidden_dim'], num_rnn_layers=args['num_rnn_layers'], rnn=args['rnn_type'])\n",
        "\n",
        "    # weights\n",
        "    model_path = model_filepath(args['model_dir'])\n",
        "    if exists(model_path) and load:\n",
        "        state_dict = torch.load(model_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "        if verbose:\n",
        "            print(\"load model weights from {}\".format(model_path))\n",
        "    return model\n",
        "\n",
        "\n",
        "def running_device(device):\n",
        "    if torch.cuda.is_available():\n",
        "      print ('running_device gpu')\n",
        "    else:  print ('running_device cpu')\n",
        "    return device if device else torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znjmr60SPtZ4"
      },
      "source": [
        "Puis la d√©finition des m√©thodes d√©di√©es √† l'entra√Ænement du mod√®le\n",
        "\n",
        "Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/app/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3zYXtKrJPssX"
      },
      "outputs": [],
      "source": [
        "from os import mkdir\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def __eval_model(model, device, dataloader, desc):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # eval\n",
        "        losses, nums = zip(*[\n",
        "            (model.loss(xb.to(device), yb.to(device)), len(xb))\n",
        "            for xb, yb in tqdm(dataloader, desc=desc)])\n",
        "        return np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "\n",
        "def __save_loss(losses, file_path):\n",
        "    pd.DataFrame(data=losses, columns=[\"epoch\", \"batch\", \"train_loss\", \"val_loss\"]).to_csv(file_path, index=False)\n",
        "\n",
        "\n",
        "def __save_model(model_dir, model):\n",
        "    model_path = model_filepath(model_dir)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(\"save model => {}\".format(model_path))\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    model_dir = args['model_dir']\n",
        "    if not exists(model_dir):\n",
        "        mkdir(model_dir)\n",
        "#    save_json_file(vars(args), arguments_filepath(model_dir))\n",
        "    save_json_file(args, arguments_filepath(model_dir))\n",
        "\n",
        "    preprocessor = Preprocessor(config_dir=args['corpus_dir'], save_config_dir=args['model_dir'], verbose=True)\n",
        "    model = build_model(args, preprocessor, load=args['recovery'], verbose=True)\n",
        "\n",
        "    # loss\n",
        "    loss_path = join(args['model_dir'], \"loss.csv\")\n",
        "    losses = pd.read_csv(loss_path).values.tolist() if args['recovery'] and exists(loss_path) else []\n",
        "\n",
        "    # datasets\n",
        "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = preprocessor.load_dataset(\n",
        "        args['corpus_dir'], args['val_split'], args['test_split'], max_seq_len=args['max_seq_len'])\n",
        "    train_dl = DataLoader(TensorDataset(x_train, y_train), batch_size=args['batch_size'], shuffle=True)\n",
        "    valid_dl = DataLoader(TensorDataset(x_val, y_val), batch_size=args['batch_size'] * 2)\n",
        "    test_dl = DataLoader(TensorDataset(x_test, y_test), batch_size=args['batch_size'] * 2)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "    device = running_device(args['device'])\n",
        "    model.to(device)\n",
        "\n",
        "    val_loss = 0\n",
        "    best_val_loss = 1e4\n",
        "    for epoch in range(args['num_epoch']):\n",
        "        # train\n",
        "        model.train()\n",
        "        bar = tqdm(train_dl)\n",
        "        for bi, (xb, yb) in enumerate(bar):\n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = model.loss(xb.to(device), yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            bar.set_description(\"{:2d}/{} loss: {:5.2f}, val_loss: {:5.2f}\".format(\n",
        "                epoch+1, args['num_epoch'], loss, val_loss))\n",
        "            losses.append([epoch, bi, loss.item(), np.nan])\n",
        "\n",
        "        # evaluation\n",
        "        val_loss = __eval_model(model, device, dataloader=valid_dl, desc=\"eval\").item()\n",
        "        # save losses\n",
        "        losses[-1][-1] = val_loss\n",
        "        __save_loss(losses, loss_path)\n",
        "\n",
        "        # save model\n",
        "        if not args['save_best_val_model'] or val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            __save_model(args['model_dir'], model)\n",
        "            print(\"save model(epoch: {}) => {}\".format(epoch, loss_path))\n",
        "\n",
        "    # test\n",
        "    test_loss = __eval_model(model, device, dataloader=test_dl, desc=\"test\").item()\n",
        "    last_loss = losses[-1][:]\n",
        "    last_loss[-1] = test_loss\n",
        "    losses.append(last_loss)\n",
        "    __save_loss(losses, loss_path)\n",
        "    print(\"training completed. test loss: {:.2f}\".format(test_loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssoc_QOnVUVH"
      },
      "source": [
        "## D√©finition de la m√©thode de pr√©diction (utilisation du mod√®le)\n",
        "\n",
        "La classe WordsTagger effectue l'√©tiquetage √† proprement parler d'une nouvelle s√©quence de mots. Elle requiert le chemin vers un mod√®le.\n",
        "\n",
        "Source : https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/app/predict.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7aPsc2UMVTSH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class WordsTagger:\n",
        "    def __init__(self, model_dir, device=None):\n",
        "        args = load_json_file(arguments_filepath(model_dir))\n",
        "        #args = dict()\n",
        "        args['model_dir'] = model_dir\n",
        "        self.args = args\n",
        "\n",
        "        self.preprocessor = Preprocessor(config_dir=model_dir, verbose=False)\n",
        "        self.model = build_model(self.args, self.preprocessor, load=True, verbose=False)\n",
        "        self.device = running_device(device)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "    def __call__(self, sentences, begin_tags=\"BS\"):\n",
        "        \"\"\"predict texts\n",
        "        :param sentences: a text or a list of text\n",
        "        :param begin_tags: begin tags for the beginning of a span\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if not isinstance(sentences, (list, tuple)):\n",
        "            raise ValueError(\"sentences must be a list of sentence\")\n",
        "\n",
        "        try:\n",
        "            sent_tensor = np.asarray([self.preprocessor.sent_to_vector(s) for s in sentences])\n",
        "            sent_tensor = torch.from_numpy(sent_tensor).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                _, tags = self.model(sent_tensor)\n",
        "            tags = self.preprocessor.decode_tags(tags)\n",
        "        except RuntimeError as e:\n",
        "            print(\"*** runtime error: {}\".format(e))\n",
        "            raise e\n",
        "        return tags, self.tokens_from_tags(sentences, tags, begin_tags=begin_tags)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokens_from_tags(sentences, tags_list, begin_tags):\n",
        "        \"\"\"extract entities from tags\n",
        "        :param sentences: a list of sentence\n",
        "        :param tags_list: a list of tags\n",
        "        :param begin_tags:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if not tags_list:\n",
        "            return []\n",
        "\n",
        "        def _tokens(sentence, ts):\n",
        "            # begins: [(idx, label), ...]\n",
        "            all_begin_tags = begin_tags + \"O\"\n",
        "            begins = [(idx, t[2:]) for idx, t in enumerate(ts) if t[0] in all_begin_tags]\n",
        "            begins = [\n",
        "                         (idx, label)\n",
        "                         for idx, label in begins\n",
        "                         if ts[idx] != \"O\" or (idx > 0 and ts[idx - 1] != \"O\")\n",
        "                     ] + [(len(ts), \"\")]\n",
        "\n",
        "            tokens_ = [(sentence[s:e], label) for (s, label), (e, _) in zip(begins[:-1], begins[1:]) if label]\n",
        "            return [((t, tag) if tag else t) for t, tag in tokens_]\n",
        "\n",
        "        tokens_list = [_tokens(sentence, ts) for sentence, ts in zip(sentences, tags_list)]\n",
        "        return tokens_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjl9xpPIIj54"
      },
      "source": [
        "---\n",
        "## Entrainement effectif du mod√®le "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_WA1wg_JdOP"
      },
      "source": [
        "### Pr√©paration des donn√©es d'entra√Ænement WikiNER et des fichiers de configuration requis\n",
        "\n",
        "R√©cup√©ration des donn√©es d'entra√Ænement Wikiner et pr√©pation des fichiers de configuration : vocabulaire, √©tiquettes et donn√©es au format du code utilis√©.\n",
        "\n",
        "Apr√®s ex√©cution de la cellule, consulter le r√©pertoire `data` pour y trouver les fichiers tagset, vocab et txt produits pour le syst√®me NER pr√©c√©demment d√©fini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXeEbpt4eJ2C"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data \n",
        "!wget -nc https://github.com/nicolashernandez/teaching_nlp/raw/main/data/wikiner_ud.joblib.bz2 -P data\n",
        "!bzip2 -dk data/wikiner_ud.joblib.bz2\n",
        "\n",
        "# Loading the corpus \n",
        "from joblib import load\n",
        "wikiner_corpus = load('data/wikiner_ud.joblib') \n",
        "\n",
        "# Aper√ßu du nombre de phrases et d'une phrase annot√©e (liste de tokens compos√©s de la forme, de la cat√©gorie grammaticale et de l'√©tiquette BIO correspondant en l'entit√© nomm√©e.\n",
        "print ('#sentences: ', len(wikiner_corpus))\n",
        "# 132257\n",
        "vocab = set()\n",
        "tagset = set()\n",
        "for s in wikiner_corpus:\n",
        "  for w,p,n in s:\n",
        "    vocab.add(w.lower())\n",
        "    tagset.add(n)\n",
        "print ('#vocab: ', len(vocab))\n",
        "print ('#tags in tagset: ', len(tagset))\n",
        "\n",
        "print ('first sentence:', wikiner_corpus[0]) \n",
        "\n",
        "print ('tagset: ', tagset)\n",
        "\n",
        "# {'B-LOC', 'B-ORG', 'I-ORG', 'B-MISC', 'I-MISC', 'I-LOC', 'B-PER', 'I-PER', 'O'}\n",
        "\n",
        "# export\n",
        "with open('data/wikiner_corpus.txt', 'w', encoding='utf-8') as f:\n",
        "    for line in wikiner_corpus:\n",
        "      sentence = list()\n",
        "      tags = list()    \n",
        "      for w,p,n in line:\n",
        "        sentence.append(w.lower())\n",
        "        tags.append(n)\n",
        "      f.write('{}\\t{}\\n'.format(json.dumps(sentence), json.dumps(tags)))\n",
        "\n",
        "# export tagset au format bi_lstm_crf \n",
        "import json\n",
        "with open('data/wikiner_corpus_tagset.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(list(tagset), f, ensure_ascii=False)\n",
        "\n",
        "# export vocab au format bi_lstm_crf \n",
        "with open('data/wikiner_corpus_vocab.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(list(vocab), f, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGLGylxgJ8WP"
      },
      "source": [
        "D√©claration du r√©pertoire de donn√©es et des noms des fichiers de vocab, du jeu d'√©tiquettes et du corpus √©tiquet√©s. En fait les noms des repertoires des donn√©es et du mod√®les sont d√©finis un peu plus bas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW6hifzxd4Ra"
      },
      "outputs": [],
      "source": [
        "FILE_VOCAB = \"wikiner_corpus_vocab.json\"\n",
        "FILE_VOCAB = \"w2v_pretrained_embeddings_vocab.json\"\n",
        "FILE_TAGS = \"wikiner_corpus_tagset.json\"\n",
        "FILE_DATASET = \"wikiner_corpus.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ismdbZLeRo"
      },
      "source": [
        "D√©claration du r√©pertoire du mod√®le qui sera g√©n√©r√© "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T177RCDzLXSD"
      },
      "outputs": [],
      "source": [
        "FILE_DATASET_CACHE = \"dataset_cache_{}.npz\"\n",
        "FILE_ARGUMENTS = \"arguments.json\"\n",
        "FILE_MODEL = \"model.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeiBr7WGL3Rf"
      },
      "source": [
        "###¬†Ex√©cution de l'entra√Ænement √† partir de param√®tres du mod√®le donn√©s\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMQ1SrmTTnl"
      },
      "source": [
        "#### VOTRE TRAVAIL\n",
        "\n",
        "* Avec le type d'ex√©cution \"cpu\", l'entra√Ænement peut prendre quelques minutes. Regardez le temps approximatif annonc√© pour 1 √©poque. Passez en type \"gpu\" et comparez le temps.\n",
        "* Avec les param√®tres par d√©faut, quelle score de loss obtenez-vous pour les donn√©es de validation suite √† la derni√®re √©poque d'entra√Ænement ? Et sur les donn√©es de test ?\n",
        "\n",
        "‚ö†Ô∏è Attention, l'impl√©mentation cherchera √† charger une configuration existante dans le r√©pertoire du mod√®le sp√©cifi√©. Si vous changez le param√©trage alors supprimer les fichiers sp√©cifiques au mod√®le ou bien sp√©cifier un nouveau r√©pertoire pour le nouveau mod√®le.\n",
        "L'erreur `RuntimeError: Error(s) in loading state_dict for BiRnnCrf:` est retourn√©e quand vous lancez un entra√Ænement (`train`) apr√®s avoir modifi√© des param√®tres qui ne sont plus en coh√©rence avec une configuration d√©j√† pr√©sente dans le r√©pertoire `model_dir`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "g-ZDugjeXRt_",
        "outputId": "1b818f05-17f5-4c39-df7c-948b8bf3284a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'model_*': No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac4729312617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -r model_*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "args = dict()\n",
        "args['corpus_dir'] = \"data\"  # the corpus directory\n",
        "args['model_dir'] = \"model_wikiner_vanilla\"       # the output directory for model files\n",
        "args['num_epoch'] = 5 # 5                # number of epoch to train\n",
        "args['lr'] = 1e-3                     #¬†learning rate\n",
        "args['weight_decay'] = 0.             # the L2 normalization parameter\n",
        "args['batch_size'] = 1000             # batch size for training\n",
        "args['device'] = None                 # the training device: \"cuda:0\", \"cpu:0\". It will be auto-detected by default\n",
        "args['max_seq_len'] = 100 #¬†100              #¬†max sequence length within training\n",
        "args['val_split'] = 0.2                  #¬†the split for the validation dataset\n",
        "args['test_split'] = 0.2                 # the split for the testing dataset\n",
        "args['recovery'] = \"store_true\"       #¬†continue to train from the saved model in model_dir\n",
        "args['save_best_val_model'] = \"store_true\" # save the model whose validation score is smallest\n",
        "args['embedding_dim'] = 200 # 100           #¬†the dimension of the embedding layer\n",
        "args['hidden_dim'] = 128              # the dimension of the RNN hidden state\n",
        "args['num_rnn_layers'] = 1 # 1            # the number of RNN layers\n",
        "args['rnn_type'] = \"lstm\"              # RNN type, choice: \"lstm\", \"gru\"\n",
        "#¬†print(args)\n",
        "\n",
        "#\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "!rm -r model_*\n",
        "train(args)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "# --- 162.1955807209015 seconds --- gpu 5 epochs max_seq_len 100 embedding_dim 100 num_rnn_layers 1 val_loss:  4.47 test_loss: 4.27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w08NdCkzR8mM"
      },
      "source": [
        "## Pr√©diction effective du mod√®le"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLRzOY3QZOR"
      },
      "source": [
        "### Pr√©paration des donn√©es de tests WiNER\n",
        "\n",
        "D'abord la d√©finition de quelques m√©thodes utiles pour la pr√©paration des donn√©es de tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmrbXjoIQrh-"
      },
      "outputs": [],
      "source": [
        "# utilities \n",
        "def flatten(t):\n",
        "  # applatie une liste de listes en une unique liste... \n",
        "  #¬†[[a, b], [c], [d, e, f]] -> [a, b, c, d, e, f]\n",
        "  return [item for sublist in t for item in sublist]\n",
        "\n",
        "import re \n",
        "def normalise_labels(sentences):\n",
        "  # normalise les sorties des √©tiquettes NER utilis√©es par les diff√©rents \n",
        "  # syst√®mes afin de les rendre comparable\n",
        "  new_sentences = list()\n",
        "  for sentence in sentences:\n",
        "    new_sentence = list()\n",
        "    for label in sentence:\n",
        "      if label != 'O':\n",
        "        label = re.sub('^[A-Z]-','', label)\n",
        "      new_sentence.append(label)\n",
        "    new_sentences.append(new_sentence)\n",
        "  return new_sentences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmZ4UIFORdVZ"
      },
      "source": [
        "Pr√©paration des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8aIpI_0sIqW"
      },
      "outputs": [],
      "source": [
        "# load the test corpus\n",
        "!mkdir -p data\n",
        "!wget -nc https://github.com/nicolashernandez/teaching_nlp/raw/main/data/winer_dev.joblib -P data\n",
        "from joblib import load\n",
        "winer_corpus = load('data/winer_dev.joblib')\n",
        "\n",
        "# get the tokens of each text\n",
        "# liste chaque forme de surface de chaque mot de chaque phrase\n",
        "winer_tokens = [[token for token, pos, label in text] for text in winer_corpus]\n",
        "# liste chaque √©tiquette (label) de chaque mot de chaque phrase\n",
        "winer_ref = [[label for token, pos, label in text] for text in winer_corpus]\n",
        "labels = list(set(flatten(winer_ref)))\n",
        "\n",
        "#\n",
        "print ('#texts:', len(winer_corpus))\n",
        "print ('labels:', labels)\n",
        "\n",
        "print ('sample of annotated texts:', winer_corpus[0])   \n",
        "print ('sample of tokenized text:', winer_tokens[0])   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONcPIZxFQ8HZ"
      },
      "source": [
        "###¬†D√©finition de la m√©thode d'√©valuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq_F2cQAQ8m8"
      },
      "outputs": [],
      "source": [
        "# Measures definition\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def results_per_class(labels, y_ref, y_hyp):\n",
        "  # Inspect per-class results in more detail:\n",
        "  sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        "  )\n",
        "  # print ('y_ref', len(y_ref), 'y_hyp', len(y_hyp), 'sorted_labels', len(sorted_labels))\n",
        "  return classification_report(flatten(y_ref), flatten(y_hyp), labels=sorted_labels, digits=3)\n",
        "\n",
        "# Il y a beaucoup plus d'entit√©s 'O' que les autres dans le corpus, \n",
        "#¬†mais nous sommes davantage int√©ress√©s par les autres entit√©s. \n",
        "#¬†Pour ne pas biaiser les scores de moyenne, on retire les √©tiquettes qui ne nous int√©ressent pas.\n",
        "print (\"before removing:\", labels)\n",
        "labels_to_remove = ['O', 'Event', 'Date', 'Hour']\n",
        "for l in labels_to_remove:\n",
        "  if l in labels: labels.remove(l)\n",
        "print (\"after removing:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLwtv_AAUuDZ"
      },
      "source": [
        "Pr√©diction sur une phrase exemple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDbE4MwVvtTr",
        "outputId": "2c17939c-ffe7-486a-a82c-4a0183c4766e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_device gpu\n",
            "Debug: sentences: tensor([[108023, 108023, 108023,  42420,  98502, 102707, 108023,  53714, 108023,\n",
            "          53385]], device='cuda:0')\n",
            "\n",
            "sentences[0]: tensor([108023, 108023, 108023,  42420,  98502, 102707, 108023,  53714, 108023,\n",
            "         53385], device='cuda:0')\n",
            "\n",
            "Debug: sentences.long(): tensor([[108023, 108023, 108023,  42420,  98502, 102707, 108023,  53714, 108023,\n",
            "          53385]], device='cuda:0')\n",
            "\n",
            "embeds[0]: tensor([[-7.7274e-01, -7.3910e-01,  1.8585e-01, -2.7139e+00, -3.7198e-01,\n",
            "          1.5138e-01, -6.1113e-01,  3.5186e-01, -2.7297e-01,  6.3638e-01,\n",
            "          1.9423e+00,  2.3150e+00,  3.8779e-01, -3.2206e-02,  1.5872e+00,\n",
            "          1.0083e+00, -1.4601e+00,  9.5189e-01,  1.7435e+00, -1.4199e+00,\n",
            "         -9.7507e-01,  1.3477e+00, -2.2467e-01, -3.8277e-02, -4.3248e-01,\n",
            "          2.4503e+00,  1.6005e+00, -7.7569e-01,  2.1241e+00, -1.1094e+00,\n",
            "          2.4002e+00,  7.6819e-01,  2.6026e-01,  5.6378e-01, -1.5258e+00,\n",
            "         -1.7320e+00,  5.4848e-01, -3.8789e-01,  1.1702e+00,  5.4513e-02,\n",
            "         -1.2308e-01, -1.4765e+00, -1.0484e+00, -1.5999e+00,  1.5693e+00,\n",
            "         -5.1265e-01, -2.9131e-01, -5.9624e-01,  7.4924e-01, -1.0979e+00,\n",
            "         -2.2036e-01,  5.8186e-01,  2.8079e-01,  3.0139e-01, -4.2670e-01,\n",
            "          3.5102e-01,  1.1180e+00, -1.2881e-01,  1.1582e+00, -5.2957e-01,\n",
            "          6.6737e-01,  1.1160e+00, -2.0109e+00,  7.2134e-01, -1.1198e+00,\n",
            "         -1.6943e-01,  2.9846e-01, -7.4892e-01,  5.9282e-01,  8.8018e-01,\n",
            "         -1.5012e-01, -2.6703e+00,  6.2959e-01,  8.5398e-01, -4.1259e-01,\n",
            "         -1.3284e-01,  1.1379e+00,  7.7759e-01, -4.9023e-01,  3.0550e-01,\n",
            "          4.7057e-01,  6.8958e-01,  1.7579e-01, -1.4416e+00, -3.3960e-01,\n",
            "         -2.9037e-01, -9.2436e-01, -1.1693e+00,  1.0451e+00,  1.7689e+00,\n",
            "         -5.8901e-01, -1.4956e+00,  2.1199e-01, -1.1385e+00,  1.2274e+00,\n",
            "          2.2126e+00, -6.9881e-02,  2.3903e+00, -1.5815e+00,  1.0286e+00],\n",
            "        [-7.7274e-01, -7.3910e-01,  1.8585e-01, -2.7139e+00, -3.7198e-01,\n",
            "          1.5138e-01, -6.1113e-01,  3.5186e-01, -2.7297e-01,  6.3638e-01,\n",
            "          1.9423e+00,  2.3150e+00,  3.8779e-01, -3.2206e-02,  1.5872e+00,\n",
            "          1.0083e+00, -1.4601e+00,  9.5189e-01,  1.7435e+00, -1.4199e+00,\n",
            "         -9.7507e-01,  1.3477e+00, -2.2467e-01, -3.8277e-02, -4.3248e-01,\n",
            "          2.4503e+00,  1.6005e+00, -7.7569e-01,  2.1241e+00, -1.1094e+00,\n",
            "          2.4002e+00,  7.6819e-01,  2.6026e-01,  5.6378e-01, -1.5258e+00,\n",
            "         -1.7320e+00,  5.4848e-01, -3.8789e-01,  1.1702e+00,  5.4513e-02,\n",
            "         -1.2308e-01, -1.4765e+00, -1.0484e+00, -1.5999e+00,  1.5693e+00,\n",
            "         -5.1265e-01, -2.9131e-01, -5.9624e-01,  7.4924e-01, -1.0979e+00,\n",
            "         -2.2036e-01,  5.8186e-01,  2.8079e-01,  3.0139e-01, -4.2670e-01,\n",
            "          3.5102e-01,  1.1180e+00, -1.2881e-01,  1.1582e+00, -5.2957e-01,\n",
            "          6.6737e-01,  1.1160e+00, -2.0109e+00,  7.2134e-01, -1.1198e+00,\n",
            "         -1.6943e-01,  2.9846e-01, -7.4892e-01,  5.9282e-01,  8.8018e-01,\n",
            "         -1.5012e-01, -2.6703e+00,  6.2959e-01,  8.5398e-01, -4.1259e-01,\n",
            "         -1.3284e-01,  1.1379e+00,  7.7759e-01, -4.9023e-01,  3.0550e-01,\n",
            "          4.7057e-01,  6.8958e-01,  1.7579e-01, -1.4416e+00, -3.3960e-01,\n",
            "         -2.9037e-01, -9.2436e-01, -1.1693e+00,  1.0451e+00,  1.7689e+00,\n",
            "         -5.8901e-01, -1.4956e+00,  2.1199e-01, -1.1385e+00,  1.2274e+00,\n",
            "          2.2126e+00, -6.9881e-02,  2.3903e+00, -1.5815e+00,  1.0286e+00],\n",
            "        [-7.7274e-01, -7.3910e-01,  1.8585e-01, -2.7139e+00, -3.7198e-01,\n",
            "          1.5138e-01, -6.1113e-01,  3.5186e-01, -2.7297e-01,  6.3638e-01,\n",
            "          1.9423e+00,  2.3150e+00,  3.8779e-01, -3.2206e-02,  1.5872e+00,\n",
            "          1.0083e+00, -1.4601e+00,  9.5189e-01,  1.7435e+00, -1.4199e+00,\n",
            "         -9.7507e-01,  1.3477e+00, -2.2467e-01, -3.8277e-02, -4.3248e-01,\n",
            "          2.4503e+00,  1.6005e+00, -7.7569e-01,  2.1241e+00, -1.1094e+00,\n",
            "          2.4002e+00,  7.6819e-01,  2.6026e-01,  5.6378e-01, -1.5258e+00,\n",
            "         -1.7320e+00,  5.4848e-01, -3.8789e-01,  1.1702e+00,  5.4513e-02,\n",
            "         -1.2308e-01, -1.4765e+00, -1.0484e+00, -1.5999e+00,  1.5693e+00,\n",
            "         -5.1265e-01, -2.9131e-01, -5.9624e-01,  7.4924e-01, -1.0979e+00,\n",
            "         -2.2036e-01,  5.8186e-01,  2.8079e-01,  3.0139e-01, -4.2670e-01,\n",
            "          3.5102e-01,  1.1180e+00, -1.2881e-01,  1.1582e+00, -5.2957e-01,\n",
            "          6.6737e-01,  1.1160e+00, -2.0109e+00,  7.2134e-01, -1.1198e+00,\n",
            "         -1.6943e-01,  2.9846e-01, -7.4892e-01,  5.9282e-01,  8.8018e-01,\n",
            "         -1.5012e-01, -2.6703e+00,  6.2959e-01,  8.5398e-01, -4.1259e-01,\n",
            "         -1.3284e-01,  1.1379e+00,  7.7759e-01, -4.9023e-01,  3.0550e-01,\n",
            "          4.7057e-01,  6.8958e-01,  1.7579e-01, -1.4416e+00, -3.3960e-01,\n",
            "         -2.9037e-01, -9.2436e-01, -1.1693e+00,  1.0451e+00,  1.7689e+00,\n",
            "         -5.8901e-01, -1.4956e+00,  2.1199e-01, -1.1385e+00,  1.2274e+00,\n",
            "          2.2126e+00, -6.9881e-02,  2.3903e+00, -1.5815e+00,  1.0286e+00],\n",
            "        [-8.6749e-01,  1.0295e+00, -1.4392e+00,  2.1098e-01, -8.1808e-01,\n",
            "         -1.6392e+00,  8.3204e-01,  8.9946e-01,  1.9900e+00, -1.6130e-01,\n",
            "          2.1953e+00,  1.3697e+00,  1.8291e-01,  1.3159e+00, -1.0427e+00,\n",
            "         -8.8583e-01,  1.5447e-01, -2.8203e+00, -1.8451e-01, -7.5662e-01,\n",
            "          9.9635e-01,  1.7867e-01, -1.9823e+00, -3.9788e-01,  1.0901e+00,\n",
            "         -9.6276e-01,  2.4049e-01,  6.9956e-01,  1.8659e+00,  9.9995e-01,\n",
            "         -1.9584e-01, -6.5430e-01, -7.5259e-01,  3.6408e-01,  1.9020e+00,\n",
            "         -1.1501e+00,  9.9723e-01, -3.4483e-01,  5.8387e-01,  4.2398e-01,\n",
            "          8.0508e-01, -1.2367e-01,  6.7627e-01, -1.7614e-01,  1.6426e+00,\n",
            "          5.9111e-01, -9.1473e-01,  4.5986e-01, -6.1413e-01,  7.7267e-01,\n",
            "         -1.4791e+00, -1.1689e-02,  1.2028e+00,  2.4076e-01,  1.1676e+00,\n",
            "          7.0542e-01,  9.0205e-02, -6.4390e-01, -1.5760e+00,  7.6833e-01,\n",
            "          2.6507e+00, -6.3048e-01,  1.5146e-01, -6.4880e-01,  1.5102e+00,\n",
            "         -8.8496e-01,  6.1917e-01,  1.1262e+00,  2.1171e+00, -1.5895e+00,\n",
            "          3.8808e-01,  8.7394e-01,  1.0156e+00,  8.8781e-02, -7.8353e-01,\n",
            "         -7.7246e-01, -1.0675e+00, -1.0963e+00,  1.4542e+00,  1.5540e-01,\n",
            "         -5.8194e-01,  1.5695e-01, -1.1034e+00,  5.7383e-01,  1.5700e+00,\n",
            "         -4.4760e-01, -2.5658e+00,  7.1521e-01, -4.5380e-01,  3.2469e-01,\n",
            "          1.2999e+00, -1.9916e+00,  1.5019e-01, -2.3173e-01, -2.8396e+00,\n",
            "         -5.3228e-01,  2.3582e-01, -8.2884e-01,  4.6074e-04, -6.9591e-01],\n",
            "        [-1.7809e-01, -3.9530e-01,  2.0897e+00, -1.0992e+00,  1.5514e-01,\n",
            "          4.8122e-01,  1.8404e+00,  1.5378e+00, -1.0363e+00,  1.3412e+00,\n",
            "         -1.6025e-01, -1.7020e-02,  6.0695e-01,  8.6742e-02, -1.0709e+00,\n",
            "          3.9915e-01, -5.0267e-01, -8.2583e-01,  1.7812e+00, -2.1776e-01,\n",
            "         -1.7563e+00,  1.1976e+00,  5.4247e-01, -1.2498e+00, -1.4754e+00,\n",
            "          4.3542e-01, -1.2864e+00, -1.0068e+00,  7.2480e-01, -2.1561e+00,\n",
            "          1.0735e+00, -2.9282e-01,  8.6429e-01, -1.2845e+00,  3.9631e-01,\n",
            "          1.4554e-01,  1.2494e-02, -1.5304e+00, -1.0270e+00,  5.1327e-01,\n",
            "          3.0204e-01,  4.7107e-01,  8.1255e-01,  7.2900e-01,  1.0534e+00,\n",
            "         -1.6729e+00,  8.9754e-01, -2.1485e-01,  1.0564e+00, -2.2922e-01,\n",
            "          1.0683e+00, -1.1803e+00, -7.5600e-01,  1.0091e+00,  1.4122e+00,\n",
            "          3.1351e-01,  1.2981e+00,  3.9039e-01,  4.2852e-01,  1.1747e+00,\n",
            "          4.3452e-01, -4.8680e-01, -8.7734e-02, -1.9058e+00, -7.0032e-01,\n",
            "         -8.8926e-01,  3.5889e-01,  9.2697e-01,  2.3567e-01, -1.4124e+00,\n",
            "         -3.4353e-01, -5.5784e-01,  8.1224e-01,  5.2452e-02,  1.1392e+00,\n",
            "         -6.4026e-01,  1.1157e-01,  6.0451e-01,  1.8677e+00,  4.2960e-02,\n",
            "          8.3063e-01,  4.7238e-01, -1.8164e+00, -6.2322e-01, -1.0201e-01,\n",
            "          1.1965e+00,  9.6135e-01, -1.0653e+00,  1.1143e+00, -2.5786e-01,\n",
            "          1.6842e-01,  1.6504e+00,  7.0647e-01,  5.6059e-01,  8.0466e-01,\n",
            "         -2.1293e-01, -4.1849e-01, -6.5484e-01, -1.8614e-02, -1.0861e+00],\n",
            "        [-1.6812e-01,  1.4864e+00,  6.5903e-01, -3.3289e-01,  6.4652e-01,\n",
            "         -1.3271e-01, -1.6818e+00, -6.7624e-01, -6.0031e-01,  3.3299e-01,\n",
            "         -9.1158e-01,  7.5532e-01, -2.8960e-02,  1.1343e+00, -1.9507e-01,\n",
            "         -1.6780e+00, -1.1885e-01,  5.3263e-01,  1.4462e+00, -2.7507e-02,\n",
            "          6.7687e-01, -7.7249e-01, -7.6327e-01, -1.0170e+00,  7.3206e-01,\n",
            "         -7.4785e-01,  4.3085e-01,  1.2455e+00, -1.6615e-01,  9.5014e-01,\n",
            "          9.2555e-01, -2.0845e-01,  2.3267e-01,  6.4170e-01,  1.0110e+00,\n",
            "         -5.2113e-01, -7.1241e-01,  9.9715e-01,  1.2335e+00,  1.0439e+00,\n",
            "         -3.6071e-01, -2.1090e+00, -2.3062e-01,  1.3155e+00, -4.4820e-01,\n",
            "         -2.9695e-01,  3.6680e-01, -7.8477e-01, -1.6093e+00, -6.3151e-01,\n",
            "         -1.8251e+00,  7.9556e-01,  4.1672e-01,  9.4586e-02,  1.6548e-01,\n",
            "         -8.6093e-01,  1.1705e+00,  4.6678e-01, -1.1141e+00, -1.2777e+00,\n",
            "          4.4274e-01,  4.0516e-01, -1.6843e+00, -7.7497e-02, -1.1438e+00,\n",
            "         -3.1899e+00, -9.1625e-01, -1.4938e+00,  1.4474e-01,  1.6349e+00,\n",
            "         -3.3282e-01,  5.1806e-01,  2.5046e+00,  1.5057e+00,  5.6725e-01,\n",
            "         -9.2540e-01,  3.6861e-02, -2.2812e-01, -1.2902e+00,  1.2762e-01,\n",
            "          1.0796e+00,  6.9800e-01,  4.8082e-01,  4.5131e-01,  3.0987e-01,\n",
            "         -1.4934e+00,  5.6402e-01,  1.5296e-01, -1.5991e-01,  6.9097e-01,\n",
            "         -5.6177e-01, -2.2529e+00, -6.8857e-01, -1.1460e+00, -6.5516e-01,\n",
            "         -1.4411e+00,  1.8403e-01, -4.7894e-01,  2.4218e-01, -1.9465e-01],\n",
            "        [-7.7274e-01, -7.3910e-01,  1.8585e-01, -2.7139e+00, -3.7198e-01,\n",
            "          1.5138e-01, -6.1113e-01,  3.5186e-01, -2.7297e-01,  6.3638e-01,\n",
            "          1.9423e+00,  2.3150e+00,  3.8779e-01, -3.2206e-02,  1.5872e+00,\n",
            "          1.0083e+00, -1.4601e+00,  9.5189e-01,  1.7435e+00, -1.4199e+00,\n",
            "         -9.7507e-01,  1.3477e+00, -2.2467e-01, -3.8277e-02, -4.3248e-01,\n",
            "          2.4503e+00,  1.6005e+00, -7.7569e-01,  2.1241e+00, -1.1094e+00,\n",
            "          2.4002e+00,  7.6819e-01,  2.6026e-01,  5.6378e-01, -1.5258e+00,\n",
            "         -1.7320e+00,  5.4848e-01, -3.8789e-01,  1.1702e+00,  5.4513e-02,\n",
            "         -1.2308e-01, -1.4765e+00, -1.0484e+00, -1.5999e+00,  1.5693e+00,\n",
            "         -5.1265e-01, -2.9131e-01, -5.9624e-01,  7.4924e-01, -1.0979e+00,\n",
            "         -2.2036e-01,  5.8186e-01,  2.8079e-01,  3.0139e-01, -4.2670e-01,\n",
            "          3.5102e-01,  1.1180e+00, -1.2881e-01,  1.1582e+00, -5.2957e-01,\n",
            "          6.6737e-01,  1.1160e+00, -2.0109e+00,  7.2134e-01, -1.1198e+00,\n",
            "         -1.6943e-01,  2.9846e-01, -7.4892e-01,  5.9282e-01,  8.8018e-01,\n",
            "         -1.5012e-01, -2.6703e+00,  6.2959e-01,  8.5398e-01, -4.1259e-01,\n",
            "         -1.3284e-01,  1.1379e+00,  7.7759e-01, -4.9023e-01,  3.0550e-01,\n",
            "          4.7057e-01,  6.8958e-01,  1.7579e-01, -1.4416e+00, -3.3960e-01,\n",
            "         -2.9037e-01, -9.2436e-01, -1.1693e+00,  1.0451e+00,  1.7689e+00,\n",
            "         -5.8901e-01, -1.4956e+00,  2.1199e-01, -1.1385e+00,  1.2274e+00,\n",
            "          2.2126e+00, -6.9881e-02,  2.3903e+00, -1.5815e+00,  1.0286e+00],\n",
            "        [-8.1491e-01,  2.1522e+00,  4.8114e-02,  2.0087e+00,  2.8292e-02,\n",
            "         -1.2397e+00, -1.4105e+00,  1.1386e+00,  7.2558e-01,  5.3568e-01,\n",
            "         -2.5733e-01, -6.2405e-01,  4.3778e-01, -4.7319e-01,  8.7105e-03,\n",
            "         -1.5254e-01,  2.9226e-01, -5.5800e-01, -7.5302e-01,  1.5971e+00,\n",
            "          3.0000e-01,  9.0764e-02, -7.6960e-01,  5.5657e-01, -2.0926e-01,\n",
            "          2.0675e+00,  5.3098e-01,  8.4053e-01, -1.0688e+00, -7.8558e-01,\n",
            "          1.1916e+00, -8.0026e-01, -8.6503e-01, -7.9886e-01,  3.9270e-01,\n",
            "          1.0280e-01,  1.0713e+00,  1.0873e-01,  9.8564e-01,  1.9027e-01,\n",
            "          2.0285e+00, -7.9846e-01,  7.4454e-01,  1.1472e+00,  1.9561e+00,\n",
            "          3.1428e-01,  3.8540e-01,  1.0232e-01, -5.1814e-02,  9.4050e-01,\n",
            "          1.3866e-01,  6.9797e-02, -1.3184e+00,  5.2020e-01,  1.5430e-02,\n",
            "          1.0293e+00,  2.1384e-01, -5.7178e-01,  4.6721e-01, -2.8244e-01,\n",
            "         -9.5361e-02,  1.7861e+00,  9.7052e-01,  1.3667e+00, -5.6411e-01,\n",
            "          1.6511e+00,  1.6202e-01, -1.1077e+00,  2.6700e-01,  2.7040e-01,\n",
            "          2.0631e-01, -4.6430e-01, -2.0190e-01,  5.3491e-01,  1.3209e-01,\n",
            "          1.6763e+00,  2.5925e-01,  9.6220e-02,  1.5617e+00,  4.0727e-01,\n",
            "          1.7958e+00,  7.4943e-01,  2.7203e-01,  5.0750e-01,  1.6041e+00,\n",
            "          4.8663e-01,  8.2682e-01,  3.7552e-01, -1.3759e+00, -1.8818e-01,\n",
            "          1.8168e+00,  7.3423e-01,  9.4429e-01, -6.1255e-01, -1.2182e+00,\n",
            "         -7.6601e-01, -1.1907e-01,  1.4394e+00, -4.4954e-01, -9.6907e-01],\n",
            "        [-7.7274e-01, -7.3910e-01,  1.8585e-01, -2.7139e+00, -3.7198e-01,\n",
            "          1.5138e-01, -6.1113e-01,  3.5186e-01, -2.7297e-01,  6.3638e-01,\n",
            "          1.9423e+00,  2.3150e+00,  3.8779e-01, -3.2206e-02,  1.5872e+00,\n",
            "          1.0083e+00, -1.4601e+00,  9.5189e-01,  1.7435e+00, -1.4199e+00,\n",
            "         -9.7507e-01,  1.3477e+00, -2.2467e-01, -3.8277e-02, -4.3248e-01,\n",
            "          2.4503e+00,  1.6005e+00, -7.7569e-01,  2.1241e+00, -1.1094e+00,\n",
            "          2.4002e+00,  7.6819e-01,  2.6026e-01,  5.6378e-01, -1.5258e+00,\n",
            "         -1.7320e+00,  5.4848e-01, -3.8789e-01,  1.1702e+00,  5.4513e-02,\n",
            "         -1.2308e-01, -1.4765e+00, -1.0484e+00, -1.5999e+00,  1.5693e+00,\n",
            "         -5.1265e-01, -2.9131e-01, -5.9624e-01,  7.4924e-01, -1.0979e+00,\n",
            "         -2.2036e-01,  5.8186e-01,  2.8079e-01,  3.0139e-01, -4.2670e-01,\n",
            "          3.5102e-01,  1.1180e+00, -1.2881e-01,  1.1582e+00, -5.2957e-01,\n",
            "          6.6737e-01,  1.1160e+00, -2.0109e+00,  7.2134e-01, -1.1198e+00,\n",
            "         -1.6943e-01,  2.9846e-01, -7.4892e-01,  5.9282e-01,  8.8018e-01,\n",
            "         -1.5012e-01, -2.6703e+00,  6.2959e-01,  8.5398e-01, -4.1259e-01,\n",
            "         -1.3284e-01,  1.1379e+00,  7.7759e-01, -4.9023e-01,  3.0550e-01,\n",
            "          4.7057e-01,  6.8958e-01,  1.7579e-01, -1.4416e+00, -3.3960e-01,\n",
            "         -2.9037e-01, -9.2436e-01, -1.1693e+00,  1.0451e+00,  1.7689e+00,\n",
            "         -5.8901e-01, -1.4956e+00,  2.1199e-01, -1.1385e+00,  1.2274e+00,\n",
            "          2.2126e+00, -6.9881e-02,  2.3903e+00, -1.5815e+00,  1.0286e+00],\n",
            "        [ 1.0809e-01, -9.4072e-01,  4.0461e-02, -6.7010e-01,  9.1044e-02,\n",
            "         -8.8389e-01, -1.3951e-02,  3.3731e-01,  6.7184e-01,  1.7459e+00,\n",
            "         -6.5706e-02,  2.8295e+00, -2.2785e+00,  1.5844e+00, -1.5828e-01,\n",
            "         -1.3936e+00,  5.4770e-01, -1.0461e+00,  6.7867e-01, -9.7732e-02,\n",
            "         -3.1562e-01, -8.7535e-01, -1.5829e+00, -1.4234e+00,  5.9520e-01,\n",
            "         -7.3205e-01, -6.3089e-01, -5.9721e-01, -6.0376e-01, -1.4663e+00,\n",
            "         -5.6542e-01, -1.0048e+00, -7.5972e-01,  2.5724e+00, -3.1450e-01,\n",
            "         -2.5791e+00, -7.8030e-01,  7.6930e-01,  1.1887e+00, -4.1775e-01,\n",
            "          6.3630e-01, -9.5021e-01, -1.3291e+00,  8.7334e-01,  1.0315e+00,\n",
            "          5.5045e-01, -1.4711e+00, -8.4053e-01, -7.6588e-01,  3.0995e-01,\n",
            "         -8.4749e-01, -6.0567e-01, -2.3250e+00,  3.0761e-01, -1.0807e-01,\n",
            "         -1.0243e+00,  1.0441e+00, -1.3532e-01, -7.0724e-01,  3.0964e-01,\n",
            "         -1.2821e+00, -1.3223e+00, -1.0001e+00, -9.7859e-01,  2.4109e-02,\n",
            "          1.0652e+00, -1.7991e+00,  6.1324e-01, -2.9770e-03,  5.5810e-01,\n",
            "         -1.0964e+00, -1.9200e+00, -1.6769e+00, -1.4074e-01,  1.8702e-01,\n",
            "          1.0172e+00, -1.5013e+00, -3.0473e-01,  6.8057e-01, -1.8217e-01,\n",
            "         -8.4792e-01, -4.7246e-01,  3.8446e-01, -9.0887e-01,  9.1114e-01,\n",
            "         -2.0796e-01, -6.1911e-01,  3.7152e-01, -4.8550e-02, -9.1197e-02,\n",
            "         -6.2393e-01, -2.1232e-01, -4.1319e-01, -1.9011e-01, -1.2397e+00,\n",
            "         -6.4006e-01, -6.5325e-01, -1.1111e-01, -4.0329e-01, -6.2091e-01]],\n",
            "       device='cuda:0')\n",
            "\n",
            "[['O', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O']]\n"
          ]
        }
      ],
      "source": [
        "model = WordsTagger(model_dir=\"model_wikiner_vanilla\")\n",
        "tags, sequences = model([['George', 'W.', 'Bush', 'fut', 'pr√©sident', 'des', '√âtats-Unis', \"d'\", 'Am√©rique', '.']])  # CHAR-based model\n",
        "print(tags)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW3LdyPBUymu"
      },
      "source": [
        "###¬†Ex√©cution de la pr√©diction sur les donn√©es de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3aL5ctwsXTc",
        "outputId": "43f26d9c-64d5-437a-a479-1709ef2b08ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_device gpu\n",
            "--- 34.635338306427 seconds ---\n",
            "bilstmcrf_hyp ['O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'I-MISC', 'O', 'O', 'I-PER', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
            "normalized_bilstmcrf_hyp ['O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'LOC', 'O', 'O', 'O', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'MISC', 'PER', 'MISC', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'MISC', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'MISC', 'O', 'O', 'PER', 'MISC', 'MISC', 'O', 'O', 'MISC', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'O', 'O', 'LOC', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'MISC', 'MISC', 'MISC', 'O', 'O', 'O']\n",
            "winer_ref ['O', 'O', 'O', 'O', 'PER', 'PER', 'Date', 'Date', 'Date', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'PER', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O']\n",
            "\n",
            "{'corpus_dir': 'data', 'model_dir': 'model_wikiner_vanilla', 'num_epoch': 5, 'lr': 0.001, 'weight_decay': 0.0, 'batch_size': 1000, 'device': None, 'max_seq_len': 100, 'val_split': 0.2, 'test_split': 0.2, 'recovery': 'store_true', 'save_best_val_model': 'store_true', 'embedding_dim': 100, 'hidden_dim': 128, 'num_rnn_layers': 1, 'rnn_type': 'lstm'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER      0.274     0.592     0.374      4483\n",
            "        MISC      0.011     0.673     0.022       443\n",
            "         LOC      0.385     0.363     0.374      4724\n",
            "         ORG      0.405     0.174     0.244      3816\n",
            "\n",
            "   micro avg      0.127     0.396     0.193     13466\n",
            "   macro avg      0.269     0.450     0.254     13466\n",
            "weighted avg      0.342     0.396     0.326     13466\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# predict\n",
        "#from bi_lstm_crf.app import WordsTagger\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "bilstmcrf_model = WordsTagger(model_dir=\"model_wikiner_vanilla\") #_vanilla\n",
        "\n",
        "bilstmcrf_hyp = []\n",
        "# pour chaque phrase de wikiner\n",
        "for text in winer_tokens:\n",
        "    tags, sequences = bilstmcrf_model([text])    \n",
        "    bilstmcrf_hyp.append(tags[0])\n",
        "    #print (tags)\n",
        "    #break\n",
        "\n",
        "#\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "# --- 40.24239158630371 seconds ---\n",
        "# --- 144.3440752029419 seconds ---\n",
        "# --- 33.92570495605469 seconds ---\n",
        "\n",
        "# normalize the hyp labels\n",
        "print ('bilstmcrf_hyp', bilstmcrf_hyp[0])\n",
        "normalized_bilstmcrf_hyp = normalise_labels(bilstmcrf_hyp)\n",
        "print ('normalized_bilstmcrf_hyp', normalized_bilstmcrf_hyp[0])\n",
        "print ('winer_ref', winer_ref[0])\n",
        "print()\n",
        "\n",
        "# Evaluate on data \n",
        "print (args)\n",
        "print (results_per_class(labels, winer_ref, normalized_bilstmcrf_hyp))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'corpus_dir': 'data', 'model_dir': 'model_wikiner_boost', 'num_epoch': 10, 'lr': 0.001, 'weight_decay': 0.0, 'batch_size': 1000, 'device': None, 'max_seq_len': 300, 'val_split': 0.2, 'test_split': 0.2, 'recovery': 'store_true', 'save_best_val_model': 'store_true', 'embedding_dim': 300, 'hidden_dim': 128, 'num_rnn_layers': 4, 'rnn_type': 'lstm'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         PER      0.223     0.713     0.340      4483\n",
        "        MISC      0.013     0.492     0.024       443\n",
        "         LOC      0.401     0.424     0.412      4724\n",
        "         ORG      0.447     0.213     0.289      3816\n",
        "\n",
        "   micro avg      0.162     0.463     0.240     13466\n",
        "   macro avg      0.271     0.461     0.266     13466\n",
        "weighted avg      0.342     0.463     0.340     13466\n"
      ],
      "metadata": {
        "id": "-5AQKIGuGBav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa8P9aeHVZqq",
        "outputId": "0553ca0b-6730-478d-cb9d-ccf381f8b010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bilstmcrf_hyp ['O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'I-MISC', 'O', 'O', 'I-PER', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'I-MISC', 'I-PER', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
            "normalized_bilstmcrf_hyp ['O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'LOC', 'O', 'O', 'O', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'MISC', 'PER', 'MISC', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'MISC', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'MISC', 'O', 'O', 'PER', 'MISC', 'MISC', 'O', 'O', 'MISC', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'O', 'O', 'LOC', 'O', 'O', 'O', 'MISC', 'PER', 'MISC', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'MISC', 'MISC', 'MISC', 'O', 'O', 'O']\n",
            "winer_ref ['O', 'O', 'O', 'O', 'PER', 'PER', 'Date', 'Date', 'Date', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'PER', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O']\n"
          ]
        }
      ],
      "source": [
        "# normalize the hyp labels\n",
        "print ('bilstmcrf_hyp', bilstmcrf_hyp[0])\n",
        "normalized_bilstmcrf_hyp = normalise_labels(bilstmcrf_hyp)\n",
        "print ('normalized_bilstmcrf_hyp', normalized_bilstmcrf_hyp[0])\n",
        "print ('winer_ref', winer_ref[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWbW17grVzQg"
      },
      "source": [
        "avec les valeurs par d√©faut\n",
        "\n",
        "```\n",
        "running_device gpu\n",
        "--- 49.18917155265808 seconds ---\n",
        "['O', 'O', 'O', 'O', 'I-PER', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'I-LOC', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'I-LOC', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'I-LOC', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O']\n",
        "['O', 'O', 'O', 'O', 'PER', 'MISC', 'O', 'O', 'O', 'O', 'MISC', 'MISC', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'LOC', 'LOC', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'MISC', 'MISC', 'O', 'MISC', 'MISC', 'MISC', 'O', 'O', 'O', 'O', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'LOC', 'O', 'O', 'MISC', 'MISC', 'MISC', 'O', 'O', 'LOC', 'O', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'LOC', 'O', 'O', 'O', 'LOC', 'LOC', 'LOC', 'O', 'LOC', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'ORG', 'O', 'O', 'O']\n",
        "['O', 'O', 'O', 'O', 'PER', 'PER', 'Date', 'Date', 'Date', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'PER', 'PER', 'PER', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Date', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'Date', 'O']\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         PER      0.287     0.659     0.400      4483\n",
        "        MISC      0.012     0.625     0.024       443\n",
        "         LOC      0.341     0.502     0.406      4724\n",
        "         ORG      0.331     0.232     0.273      3816\n",
        "\n",
        "   micro avg      0.154     0.482     0.233     13466\n",
        "   macro avg      0.243     0.504     0.276     13466\n",
        "weighted avg      0.309     0.482     0.354     13466\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rEMG4w79NWt"
      },
      "source": [
        "---\n",
        "# VOTRE TRAVAIL\n",
        "\n",
        "* Jouez avec le param√©trage d'entra√Ænement du mod√®le (par exemple en doublant les valeurs par d√©faut): nombre d'√©poque, taille des phrases consid√©r√©es (max_seq_len), dimension des embeddings (embedding_dim), nombre de couches RNN (num_rnn_layers), type de cellule RNN (rnn_type), nombre de dimension du RNN (hidden state), le taux d'apprentissage (lr)... D√©terminer l'apport de chaque param√®tre. Discuter les performances en termes de pr√©cision, rappel et micro/macro-F1.\n",
        "* Dans vos exp√©riences, rencontrez-vous des limites avec le hardware mis √† disposition par gcolab ? \n",
        "* Exp√©rimenter une modification en profondeur (au choix, d'autres sont possibles)\n",
        "  * Modifiez le code pour utiliser des _pre-trained word embeddings_. Mesurez leur apport. Exp√©rimentez √† minima le mod√®le [word2vec de 200 dimensions construit avec skipgram sur le corpus FrWac, et mis √† disposition par Jean-Philippe Fauconnier](https://fauconnier.github.io/#data)  \n",
        "  * Ajouter les traits sur la surface des mots\n",
        "* Faire un retour sur les diff√©rents mod√®les que vous avez impl√©ment√©s (y compris √† base de CRF pur).\n",
        "* Suivant votre avancement, d'autres word embeddings peuvent √™tre test√©s (e.g. glove), une architecture [BERT-CRF](https://github.com/jidasheng/bi-lstm-crf) (cf. fin du README)...\n",
        "\n",
        "Ci dessous quelques pointeurs sur comment utiliser des mod√®les pr√©-entra√Æn√©s avec pytorch\n",
        "* https://stackoverflow.com/questions/49710537/pytorch-gensim-how-to-load-pre-trained-word-embeddings\n",
        "* https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76 \n",
        "* https://towardsdatascience.com/deep-learning-for-nlp-with-pytorch-and-torchtext-4f92d69052f\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copie de M2-ATAL-2021-22_02_NER with BiLSTM-CRF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQgLIOFiQaD/38aPxRva+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}