{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0B9daf8oqMQ"
      },
      "source": [
        "# (Pré-)-Traitement Automatique des Langues\n",
        "\n",
        "Suivant le contexte, le terme de *Traitement Automatique des Langues* désigne les traitements de préparation (ou pré-traitements) que l'on applique au texte pour le rendre traitable par une application de \"plus haut niveau\" (e.g. découper en phrases un texte, pour déterminer les phrases les plus saillantes à faire apparaître dans un résumé). Le terme englobe aussi la désignation de ces applications de plus haut niveau ou avec utilisateur humain.\n",
        "\n",
        "### Objectif  \n",
        "* analyser et interpréter les sorties et la qualité d'analyseurs linguistiques\n",
        "* découvrir les caractéristiques (en particulier linguistiques) d'une donnée langagière qui peuvent influer sur les traitements automatiques et la qualité de ceux-ci\n",
        "\n",
        "### NLP (python) Libraries\n",
        "* [spaCy](https://spacy.io/): \"_Support for 64+ languages ; 64 trained pipelines for 19 languages; Multi-task learning with pretrained transformers like BERT; Pretrained word vectors; State-of-the-art speed\n",
        "Production-ready training system;\n",
        "Linguistically-motivated tokenization;\n",
        "Components for named entity recognition, part-of-speech tagging, dependency parsing, sentence segmentation, text classification, lemmatization, morphological analysis, entity linking and more;\n",
        "Easily extensible with custom components and attributes;\n",
        "Support for custom models in PyTorch, TensorFlow and other frameworks;  \n",
        "Built in visualizers for syntax and NER_\" (state-of-the-art natural language processing with industrial motivations and tools, 'Cy' for 'Cython', multilingue, statistical/neuronal models https://spacy.io/usage/linguistic-features)\n",
        "* [NLTK](https://www.nltk.org) : \"_NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum_\" (pédagogique, des approches à base de règles ou statistiques, multilingues)\n",
        "* [Stanza](https://stanfordnlp.github.io/stanza/index.html) : \"_Stanza is a collection of accurate and efficient tools for the linguistic analysis of many human languages. Starting from raw text to syntactic analysis and entity recognition, Stanza brings state-of-the-art NLP models to languages of your choosing_\" (python, nouveau framework de Stanford, modèles neuronaux entraînés sur données UD, 66 langues)\n",
        "* [flair](https://github.com/flairNLP/flair), \"_A powerful NLP library. Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as named entity recognition (NER), part-of-speech tagging (PoS), special support for biomedical data, sense disambiguation and classification, with support for a rapidly growing number of languages._\" ; \"_A text embedding library. Flair has simple interfaces that allow you to use and combine different word and document embeddings, including our proposed Flair embeddings, BERT embeddings and ELMo embeddings._\", \"_A PyTorch NLP framework. Our framework builds directly on PyTorch, making it easy to train your own models and experiment with new approaches using Flair embeddings and classes._\"\n",
        " (fondé sur PyTorch, multilingue, support spécial pour le biomedical, COLING18, EACL19)\n",
        "* [Trankit](https://trankit.readthedocs.io/) \"_is a light-weight Transformer-based Python Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsing while maintaining competitive performance for tokenization, multi-word token expansion, and lemmatization over 90 Universal Dependencies v2.5 treebanks. Our pipeline also obtains competitive or better named entity recognition (NER) performance compared to existing popular toolkits on 11 public NER datasets over 8 languages._\" (EACL'2021)\n",
        "* [gluon](https://github.com/dmlc/gluon-nlp/) MXNet, Amazon\n",
        "* [TextBlob](https://textblob.readthedocs.io) \"_is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob stands on the giant shoulders of NLTK and pattern, and plays nicely with both._\"\n",
        "* [Gensim](https://radimrehurek.com/gensim/): \"_Gensim is a free open-source Python library for representing documents as semantic vectors, as efficiently (computer-wise) and painlessly (human-wise) as possible.\n",
        "Gensim is designed to process raw, unstructured digital texts (”plain text”) using unsupervised machine learning algorithms.\n",
        "The algorithms in Gensim, such as Word2Vec, FastText, Latent Semantic Indexing (LSI, LSA, LsiModel), Latent Dirichlet Allocation (LDA, LdaModel) etc, automatically discover the semantic structure of documents by examining statistical co-occurrence patterns within a corpus of training documents. These algorithms are unsupervised, which means no human input is necessary – you only need a corpus of plain text documents. Once these statistical patterns are found, any plain text documents (sentence, phrase, word…) can be succinctly expressed in the new, semantic representation and queried for topical similarity against other documents (words, phrases…)._\" (topic modeling and similarity detection\n",
        "* [udpipe](https://ufal.mff.cuni.cz/udpipe/)\n",
        "\n",
        "Mais aussi en java    \n",
        "* [Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/) : \"_CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish._\" (multilingue, statistique, résolution de la coréference)\n",
        "* [DKPro](https://dkpro.github.io/) \"_A collection of software components for natural language processing (NLP) based on the Apache UIMA framework._\"\n",
        "* [Apache OpenNLP](https://opennlp.apache.org/) \"_OpenNLP supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking, parsing, language detection and coreference resolution._\"\n",
        "\n",
        "### Thèmes abordés\n",
        "\n",
        "* (Pré-)traitements linguistiques\n",
        "  * Tokenization, Sentence segmentation\n",
        "  * POS tagging, Morphology, Lemmatization, Dependency parsing,\n",
        "  * Named Entities Recognition (NER)\n",
        "  * (Language Detection)\n",
        "* Mise en application\n",
        "  * Langue : Français\n",
        "  * Types de texte : Dépèches journalistiques, Tweets, romans et textes juridiques\n",
        "  * Dimension multilingue\n",
        "\n",
        "### Consignes de travail\n",
        "\n",
        "Réponse aux questions dans la section \"votre réponse\". Des réponses brèves et simples sont attendues.\n",
        "\n",
        "Vous avez le droit de modifier le code pour vous permettre de plus facilement répondre aux questions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfKO-7ZT7x4y"
      },
      "source": [
        "---\n",
        "# Installation de l'environnement : chargement des modèles et des données\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Executer le code suivant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhTHluRv9RIb",
        "outputId": "e8589052-f949-4cf7-e762-64bf011686c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Téléchargement d'un modèle pour le traitement du français\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-12 06:23:22.105856: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-12 06:23:24.295979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting fr-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.6.0/fr_core_news_sm-3.6.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z199LIHqPoc"
      },
      "source": [
        "# Importation de la bibliothèque spaCy\n",
        "import spacy\n",
        "\n",
        "# Chargement du modèle pour le français\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# Importation d'une liste d'exemple de phrases en français\n",
        "from spacy.lang.fr.examples import sentences"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZwjmG6GrRiA"
      },
      "source": [
        "Si vous obtenez l'erreur suivante\n",
        "```\n",
        "# OSError: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.\n",
        "```\n",
        "Alors\n",
        "- Faire `Exécution > Redémarrer l'environnement d'Exécution`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwWQQfB-kDf4"
      },
      "source": [
        "Executer aussi :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQGZh5n0kDM7",
        "outputId": "a0665443-5b5b-4de2-f19a-7b2c84e5826d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Z4qHGSYKCV"
      },
      "source": [
        "# Analyses linguistiques du français\n",
        "\n",
        "Par la suite nous utiliserons principalement la bibliothèque spaCy et sa méthode `nlp` que l'on applique à du texte brut `doc`. Avec cette méthode, spaCy réalise un certain nombre de traitements par défaut disponible dans le modèle chargé tel que la segmentation d'un texte en phrases, la tokenization, l'analyse grammaticale et morphologique des mots (dont lemmatisation), l'analyse en constituants syntaxiques, l'analyse en dépendance syntaxique, la reconnaissance des entités nommées. On désignera par `spacy_doc` l'objet qui correspond au résultat d'analyse (méthode `nlp`) de spaCy sur le texte `doc`.\n",
        "\n",
        "Parcourir l'objet spacy_doc comme une liste python fournira les informations rattachées à chaque token du texte. `spacy_doc.noun_chunks` donnera des informations sur les constituants syntaxiques. `spacy_doc.ents` donnera des informations sur les entités nommées détectées dans le texte.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQQ4CIckfKUR"
      },
      "source": [
        "## Tokénisation\n",
        "\n",
        "Un **token** est une instance d'une séquence de caractères dans un document donné qui constitue une unité pour une quelconque raison (e.g. délimitée par des espaces). Les tokens qui ont une réalité grammaticale (e.g. Nom, Verbe, Adjectif...) peuvent être considérés comme des instances de **mots**. Le mot a une réalité linguistique (ses caractères sont des lettres de l'alphabet plus l'espace et le tiret).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jh78yjel68T"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "Le code suivant commence par déclarer deux tokenizers utilisant des technologies différentes : l'un est proposé par la bibliothèque _nltk_ et l'autre _spaCy_. Le code se poursuit en calculant le nombre de tokens obtenus par chacun des tokenizers. Puis applique les deux tokenizers et affiche les différences de tokenization pour les 5 1ères phrases du corpus de phrases exemples en français de spaCy. Seules les différentes sont affichées en donnant quelques mots en contexte (et non toute la phrase). La bibliothèque utilisée donne aussi les offsets de début/fin de la différence observée.\n",
        "\n",
        "* Exécuter le code. Quelles erreurs/différences de tokenization observez-vous ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZYVlMjPfOAw",
        "outputId": "abd51dfe-8a1f-42da-85b0-8fb436ae2961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import spaCy and define a method to tokenize via spacy\n",
        "# en fait, la méthode récupère seulement la tokenization, mais la méthode 'nlp'\n",
        "# produit plusieurs analyses (on le verra plus tard)\n",
        "# machine learning based model\n",
        "import spacy\n",
        "spacy_tokenize = lambda text: [token.text for token in nlp(text)]\n",
        "\n",
        "# import un tokenizer de nltk\n",
        "# uses regular expressions (to fit the penn treebank corpus tokenization)\n",
        "# and an unsupervised sentence segmentation model (aka punkt)\n",
        "# to distinguish abreviations from sentence endings.\n",
        "from nltk import word_tokenize\n",
        "nltk_tokenize = lambda text: [token for token in word_tokenize(text, language='french')]\n",
        "\n",
        "\n",
        "# compte le nombre de phrases exemples et le nombre de tokens total obtenu\n",
        "# par chaque tokenizer nltk et spacy\n",
        "nltk_tokens = list()\n",
        "spacy_tokens = list()\n",
        "for i in range (0, len(sentences)):\n",
        "  nltk_tokens.extend(word_tokenize(sentences[i]))\n",
        "  spacy_tokens.extend(spacy_tokenize(sentences[i]))\n",
        "print('len_sentences=',len(sentences),' ; len_nltk_tokenize=', len(nltk_tokens), ' ; len_spacy_tokens=', len(spacy_tokens))\n",
        "print()\n",
        "\n",
        "# https://twitter.com/_inesmontani/status/1151447435195113472?lang=en\n",
        "#from spacy.gold import align\n",
        "#cost, a2b, b2a, a2b_multi, b2a_multi = align(nltk_tokens, spacy_tokens)\n",
        "#print ('cost:', cost)\n",
        "#print()\n",
        "\n",
        "# pour chaque phrase, chacun des tokenizers produit une liste de tokens\n",
        "# la phrase est affichée ainsi que les contextes des tokens où les tokenisations\n",
        "# n'ont pas produit la même analyse\n",
        "from difflib import context_diff, ndiff\n",
        "\n",
        "for i in range (0, 5):\n",
        "  print (i, sentences[i])\n",
        "  print('\\n'.join(context_diff(word_tokenize(sentences[i]), spacy_tokenize(sentences[i]), fromfile='nltk_tokenize', tofile='spacy_tokenize')))\n",
        "  print()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len_sentences= 12  ; len_nltk_tokenize= 113  ; len_spacy_tokens= 123\n",
            "\n",
            "0 Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars\n",
            "*** nltk_tokenize\n",
            "\n",
            "--- spacy_tokenize\n",
            "\n",
            "***************\n",
            "\n",
            "*** 3,9 ****\n",
            "\n",
            "  à\n",
            "  acheter\n",
            "  une\n",
            "! start-up\n",
            "  anglaise\n",
            "  pour\n",
            "  1\n",
            "--- 3,11 ----\n",
            "\n",
            "  à\n",
            "  acheter\n",
            "  une\n",
            "! start\n",
            "! -\n",
            "! up\n",
            "  anglaise\n",
            "  pour\n",
            "  1\n",
            "\n",
            "1 Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\n",
            "*** nltk_tokenize\n",
            "\n",
            "--- spacy_tokenize\n",
            "\n",
            "***************\n",
            "\n",
            "*** 5,11 ****\n",
            "\n",
            "  la\n",
            "  responsabilité\n",
            "  de\n",
            "! l'assurance\n",
            "  vers\n",
            "  les\n",
            "  constructeurs\n",
            "--- 5,12 ----\n",
            "\n",
            "  la\n",
            "  responsabilité\n",
            "  de\n",
            "! l'\n",
            "! assurance\n",
            "  vers\n",
            "  les\n",
            "  constructeurs\n",
            "\n",
            "2 San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n",
            "*** nltk_tokenize\n",
            "\n",
            "--- spacy_tokenize\n",
            "\n",
            "***************\n",
            "\n",
            "*** 1,7 ****\n",
            "\n",
            "  San\n",
            "  Francisco\n",
            "  envisage\n",
            "! d'interdire\n",
            "  les\n",
            "  robots\n",
            "  coursiers\n",
            "--- 1,8 ----\n",
            "\n",
            "  San\n",
            "  Francisco\n",
            "  envisage\n",
            "! d'\n",
            "! interdire\n",
            "  les\n",
            "  robots\n",
            "  coursiers\n",
            "\n",
            "3 Londres est une grande ville du Royaume-Uni\n",
            "*** nltk_tokenize\n",
            "\n",
            "--- spacy_tokenize\n",
            "\n",
            "***************\n",
            "\n",
            "*** 4,7 ****\n",
            "\n",
            "  grande\n",
            "  ville\n",
            "  du\n",
            "! Royaume-Uni\n",
            "--- 4,9 ----\n",
            "\n",
            "  grande\n",
            "  ville\n",
            "  du\n",
            "! Royaume\n",
            "! -\n",
            "! Uni\n",
            "\n",
            "4 L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe\n",
            "*** nltk_tokenize\n",
            "\n",
            "--- spacy_tokenize\n",
            "\n",
            "***************\n",
            "\n",
            "*** 1,5 ****\n",
            "\n",
            "! L\n",
            "! ’\n",
            "  Italie\n",
            "  choisit\n",
            "  ArcelorMittal\n",
            "--- 1,4 ----\n",
            "\n",
            "! L’\n",
            "  Italie\n",
            "  choisit\n",
            "  ArcelorMittal\n",
            "***************\n",
            "\n",
            "*** 9,14 ****\n",
            "\n",
            "  plus\n",
            "  grande\n",
            "  aciérie\n",
            "! d\n",
            "! ’\n",
            "  Europe\n",
            "--- 8,12 ----\n",
            "\n",
            "  plus\n",
            "  grande\n",
            "  aciérie\n",
            "! d’\n",
            "  Europe\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxwiphA6oq5d"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "*NLTK* :\n",
        "\n",
        "- ne semble pas considérer les caractères spéciaux, tels que les apostrophes et tirets, comme des séparateurs de tokens.\n",
        "- semble considérer qu'une majuscule initie un token.\n",
        "\n",
        "*spaCy* :\n",
        "\n",
        "- semble considérer les caractères spéciaux comme (1) des séparateurs de tokens et (2) des tokens en eux-mêmes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwIQMphkuiNS"
      },
      "source": [
        "\n",
        "## Analyse lexicale\n",
        "\n",
        "\n",
        "### Token vs Mot vs Formes morphologiques vs Lemme\n",
        "\n",
        "Le **mot** peut avoir plusieurs **formes (morphologiques)** lesquelles renseignent sur le genre, le nombre, le mode/temps; par exemples \"feuille\" et \"feuilles\" ou \"blanchir\" et \"blanchiront\". Ces variations sont propres à chaque **classe grammaticale** (e.g. nom, verbe, adjectif). On appelle **lemme** la forme référente d'un mot. \"feuille\" et \"blanchir\" sont des formes référentes.\n",
        "\n",
        "On appelle ces variations morphologiques des **flexions** (morphologie flexionnelle). Il existe d'autres formes de variations à base d'**affixe** (préfixe et suffixe). Ainsi \"feuillage\" et \"feuille\" sont liées par une relation de **dérivation** (morphologie dérivationnelle) et de même pour \"blanc\", \"blanchiment\" et \"blanchir\".\n",
        "\n",
        "Une **unité lexicale** est une unité de sens dans une langue. Ces unités peuvent être composés d'un ou plusieurs mots. Ainsi \"pomme de terre\" est aussi une **unité lexicale**.\n",
        "\n",
        "\n",
        "### Propriétés associées à un token mot dans Spacy\n",
        "\n",
        "Les modèles de Spacy produisent de base une analyse grammaticale, morphologique et syntaxique des mots pour plusieurs langues.\n",
        "Les propriétés suivantes informent de différents attributs (en particulier linguistiques associées) à chaque token.\n",
        "* `text`: The original word text\n",
        "* `lemma_`: The base form of the word.\n",
        "* `pos_`: The simple UPOS part-of-speech tag.\n",
        "* `tag_`: The detailed part-of-speech tag with morphological information.\n",
        "* `dep_`: Syntactic dependency, i.e. the relation between tokens.\n",
        "* `shape_`: The word shape – capitalization, punctuation, digits.\n",
        "* `is_alpha`: Is the token an alpha character?\n",
        "* `is_stop`: Is the token part of a stop list, i.e. the most common words of the language?\n",
        "\n",
        "Au sujet de la propriété `is_stop`, en français on parle de _mot outil_ ou de _mot vide_, vide de sens, qui ne permettent pas d'analyser le contenu \"thématique\" de la phrase. Ces mots sont en général des listes fermées et comptent les déterminants, les prépositions, et quelques adverbes. Statistiquement ils sont plus fréquents que d'autres (cf. la loi de zipf dans un prochain cours). Selon les usages, les mots vides peuvent être utiles. Par exemple, en analyse d'opinion, les adverbes de négation ou d'emphases jouent un rôle important.\n",
        "\n",
        "### Format CoNLL\n",
        "\n",
        "Il existe des formats de fichier pour représenter l'information de segmentation des phrases, de tokenization des mots, et toutes les informations issues des différentes analyses morpho-syntaxiques.\n",
        "\n",
        "Le format [conll](https://stackoverflow.com/questions/27416164/what-is-conll-data-format), et son extension [CoNLL-U](https://universaldependencies.org/docs/format.html), sont une référence à ce sujet.\n",
        "\n",
        "Globalement le fichier a un format tabulé où chaque ligne décrit en colonnes les différentes informations relatives à un mot.\n",
        "Une ligne vide correspond à un saut de phrase. Les commentaires sont possibles (#). Les informations en colonnes suivent un ordre et une désignation bien précises (cf. le lien sur CoNLL-U). Il est possible d'exprimer les relations qu'entretiennent certains mots en utilisant une colonne pour référencer l'id du mot avec lequel le mot courant entretient une relation (utile pour exprimer les relations syntaxiques).\n",
        "\n",
        "    1     I         I      PRON    PRP   Case=Nom|Number=Sing|Person=1                  2   nsubj\n",
        "    2     haven't   _      VERB    _     Negative=Neg|Number=Sing|Person=1|Tense=Pres   0   root\n",
        "    3     a         a      DET     DT    Definite=Ind|PronType=Art                      4   det\n",
        "    4     clue      clue   NOUN    NN    Number=Sing                                    2   dobj\n",
        "    5     .         .      PUNCT   .     _                                              2   punct\n",
        "\n",
        "Les traits de spaCy se retrouvent pour partie dans le format conll.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mZDBpp36KQT"
      },
      "source": [
        "### QUESTIONS\n",
        "Le code suivant permet d'appliquer un modèle Spacy offrant des traitements TAL à un document (ici une phrase) donné.\n",
        "* Ajouter les propriétés permettant d'observer les résultats de la lemmatisation, de l'étiquetage grammatical, de l'analyse morphologique et de l'analyse en dépendance syntaxique.\n",
        "* Consulter l'analyse des 5 premières phrases exemples de spacy (0 à 4). Donnez un exemple d'erreur de lemmatisation, d'erreur d'étiquetage grammatical, d'erreur d'analyse morphologique (idéalement dans des phrases différentes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl2wxiPM5y8S",
        "outputId": "b3060567-1905-4336-bfb4-f344674ab1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "# Ici le document est la 1ère phrase (sentence 0) des exemples de Spacy\n",
        "# de phrases écrites en français\n",
        "doc = sentences[2]\n",
        "\n",
        "# exécution des traitements en une seule commande\n",
        "spacy_doc = nlp(doc)\n",
        "\n",
        "# affichage de la phrase\n",
        "print(spacy_doc.text)\n",
        "\n",
        "# affichage de quelques résultats d'analyse\n",
        "# et ce, dans une pandas dataframe pour améliorer le visuel\n",
        "# importation de la bibliothèque pandas\n",
        "import pandas as pd\n",
        "# spécifie qu'au niveau de l'affichage il n'y a pas de limites, cad affiche toutes les colonnes et toutes les lignes\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "# pandas travaillant avec des listes python, on transforme le résultat d'analyse de spacy en liste\n",
        "from spacy.tokens.token import Token\n",
        "columns = ['Token', 'is_stop', 'Lemme', 'Gram.', 'Morph.', 'Dép.']\n",
        "mk_row = lambda t: (t.text, t.is_stop, t.lemma_, t.pos_.lower(), t.morph, t.dep_)\n",
        "\n",
        "pd.DataFrame(map(mk_row, spacy_doc), columns=columns)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Token  is_stop      Lemme  Gram.  \\\n",
              "0         San    False        san    det   \n",
              "1   Francisco    False  Francisco  propn   \n",
              "2    envisage    False  envisager   verb   \n",
              "3          d'     True         de    adp   \n",
              "4   interdire    False  interdire   noun   \n",
              "5         les     True         le    det   \n",
              "6      robots    False      robot   noun   \n",
              "7   coursiers    False   coursier    adj   \n",
              "8         sur     True        sur    adp   \n",
              "9         les     True         le    det   \n",
              "10  trottoirs    False   trottoir   noun   \n",
              "\n",
              "                                               Morph.     Dép.  \n",
              "0                           (Gender=Fem, Number=Sing)      det  \n",
              "1                          (Gender=Masc, Number=Sing)    nsubj  \n",
              "2   (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...     ROOT  \n",
              "3                                                  ()     case  \n",
              "4                                       (Number=Sing)    xcomp  \n",
              "5           (Definite=Def, Number=Plur, PronType=Art)      det  \n",
              "6                          (Gender=Masc, Number=Plur)      obj  \n",
              "7                          (Gender=Masc, Number=Plur)     amod  \n",
              "8                                                  ()     case  \n",
              "9           (Definite=Def, Number=Plur, PronType=Art)      det  \n",
              "10                         (Gender=Masc, Number=Plur)  obl:mod  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3f305e0-96cf-4030-a55b-04736bb0ad3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>is_stop</th>\n",
              "      <th>Lemme</th>\n",
              "      <th>Gram.</th>\n",
              "      <th>Morph.</th>\n",
              "      <th>Dép.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>San</td>\n",
              "      <td>False</td>\n",
              "      <td>san</td>\n",
              "      <td>det</td>\n",
              "      <td>(Gender=Fem, Number=Sing)</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Francisco</td>\n",
              "      <td>False</td>\n",
              "      <td>Francisco</td>\n",
              "      <td>propn</td>\n",
              "      <td>(Gender=Masc, Number=Sing)</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>envisage</td>\n",
              "      <td>False</td>\n",
              "      <td>envisager</td>\n",
              "      <td>verb</td>\n",
              "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d'</td>\n",
              "      <td>True</td>\n",
              "      <td>de</td>\n",
              "      <td>adp</td>\n",
              "      <td>()</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>interdire</td>\n",
              "      <td>False</td>\n",
              "      <td>interdire</td>\n",
              "      <td>noun</td>\n",
              "      <td>(Number=Sing)</td>\n",
              "      <td>xcomp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>les</td>\n",
              "      <td>True</td>\n",
              "      <td>le</td>\n",
              "      <td>det</td>\n",
              "      <td>(Definite=Def, Number=Plur, PronType=Art)</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>robots</td>\n",
              "      <td>False</td>\n",
              "      <td>robot</td>\n",
              "      <td>noun</td>\n",
              "      <td>(Gender=Masc, Number=Plur)</td>\n",
              "      <td>obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>coursiers</td>\n",
              "      <td>False</td>\n",
              "      <td>coursier</td>\n",
              "      <td>adj</td>\n",
              "      <td>(Gender=Masc, Number=Plur)</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sur</td>\n",
              "      <td>True</td>\n",
              "      <td>sur</td>\n",
              "      <td>adp</td>\n",
              "      <td>()</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>les</td>\n",
              "      <td>True</td>\n",
              "      <td>le</td>\n",
              "      <td>det</td>\n",
              "      <td>(Definite=Def, Number=Plur, PronType=Art)</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>trottoirs</td>\n",
              "      <td>False</td>\n",
              "      <td>trottoir</td>\n",
              "      <td>noun</td>\n",
              "      <td>(Gender=Masc, Number=Plur)</td>\n",
              "      <td>obl:mod</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3f305e0-96cf-4030-a55b-04736bb0ad3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3f305e0-96cf-4030-a55b-04736bb0ad3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3f305e0-96cf-4030-a55b-04736bb0ad3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52622f65-d42b-4149-b64e-c2ac5788e74b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52622f65-d42b-4149-b64e-c2ac5788e74b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52622f65-d42b-4149-b64e-c2ac5788e74b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQAdZqp5Hir"
      },
      "source": [
        "### VOTRE RÉPONSE\n",
        "\n",
        "1. Erreur de lemmatisation :\n",
        "```\n",
        "               Token          Lemme\n",
        "3   ArcelorMittal  arcelormittal\n",
        "```\n",
        "2. Erreur d'étiquetage grammatical :\n",
        "```\n",
        "                Token  Gram.\n",
        "3        déplacent    adv\n",
        "```\n",
        "3. Erreur d'analyse morphologique :\n",
        "```\n",
        "         Token              Morph.\n",
        "7      sent  (Number=Plur, ...)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slk2dK1aq-Jo",
        "outputId": "f2f23d06-213c-4c2f-d80f-5d7fc04dbd86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for sentence in sentences[1:6]:\n",
        "  doc = nlp(sentence)\n",
        "  print(doc.text)\n",
        "  print(pd.DataFrame(map(mk_row, doc), columns=columns))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\n",
            "             Token  is_stop           Lemme Gram.  \\\n",
            "0              Les     True              le   det   \n",
            "1         voitures    False         voiture  noun   \n",
            "2        autonomes    False        autonome   adj   \n",
            "3        déplacent    False        déplacer   adv   \n",
            "4               la     True              le   det   \n",
            "5   responsabilité    False  responsabilité  noun   \n",
            "6               de     True              de   adp   \n",
            "7               l'     True              le   det   \n",
            "8        assurance    False       assurance  noun   \n",
            "9             vers     True            vers   adp   \n",
            "10             les     True              le   det   \n",
            "11   constructeurs    False    constructeur  noun   \n",
            "\n",
            "                                               Morph.     Dép.  \n",
            "0           (Definite=Def, Number=Plur, PronType=Art)      det  \n",
            "1                           (Gender=Fem, Number=Plur)    nsubj  \n",
            "2                                       (Number=Plur)     ROOT  \n",
            "3                                                  ()   advmod  \n",
            "4   (Definite=Def, Gender=Fem, Number=Sing, PronTy...      det  \n",
            "5                           (Gender=Fem, Number=Sing)      obj  \n",
            "6                                                  ()     case  \n",
            "7           (Definite=Def, Number=Sing, PronType=Art)      det  \n",
            "8                           (Gender=Fem, Number=Sing)     nmod  \n",
            "9                                                  ()     case  \n",
            "10          (Definite=Def, Number=Plur, PronType=Art)      det  \n",
            "11                         (Gender=Masc, Number=Plur)  obl:mod  \n",
            "San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n",
            "        Token  is_stop      Lemme  Gram.  \\\n",
            "0         San    False        san    det   \n",
            "1   Francisco    False  Francisco  propn   \n",
            "2    envisage    False  envisager   verb   \n",
            "3          d'     True         de    adp   \n",
            "4   interdire    False  interdire   noun   \n",
            "5         les     True         le    det   \n",
            "6      robots    False      robot   noun   \n",
            "7   coursiers    False   coursier    adj   \n",
            "8         sur     True        sur    adp   \n",
            "9         les     True         le    det   \n",
            "10  trottoirs    False   trottoir   noun   \n",
            "\n",
            "                                               Morph.     Dép.  \n",
            "0                           (Gender=Fem, Number=Sing)      det  \n",
            "1                          (Gender=Masc, Number=Sing)    nsubj  \n",
            "2   (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...     ROOT  \n",
            "3                                                  ()     case  \n",
            "4                                       (Number=Sing)    xcomp  \n",
            "5           (Definite=Def, Number=Plur, PronType=Art)      det  \n",
            "6                          (Gender=Masc, Number=Plur)      obj  \n",
            "7                          (Gender=Masc, Number=Plur)     amod  \n",
            "8                                                  ()     case  \n",
            "9           (Definite=Def, Number=Plur, PronType=Art)      det  \n",
            "10                         (Gender=Masc, Number=Plur)  obl:mod  \n",
            "Londres est une grande ville du Royaume-Uni\n",
            "     Token  is_stop    Lemme  Gram.  \\\n",
            "0  Londres    False  Londres  propn   \n",
            "1      est     True     être    aux   \n",
            "2      une     True       un    det   \n",
            "3   grande    False    grand    adj   \n",
            "4    ville    False    ville   noun   \n",
            "5       du     True       de    adp   \n",
            "6  Royaume    False  Royaume  propn   \n",
            "7        -    False        -  propn   \n",
            "8      Uni    False      Uni  propn   \n",
            "\n",
            "                                              Morph.   Dép.  \n",
            "0                         (Gender=Masc, Number=Sing)  nsubj  \n",
            "1  (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...    cop  \n",
            "2  (Definite=Ind, Gender=Fem, Number=Sing, PronTy...    det  \n",
            "3                          (Gender=Fem, Number=Sing)   amod  \n",
            "4                          (Gender=Fem, Number=Sing)   ROOT  \n",
            "5  (Definite=Def, Gender=Masc, Number=Sing, PronT...   case  \n",
            "6                         (Gender=Masc, Number=Sing)   nmod  \n",
            "7                         (Gender=Masc, Number=Sing)   nmod  \n",
            "8                         (Gender=Masc, Number=Sing)   nmod  \n",
            "L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe\n",
            "            Token  is_stop          Lemme  Gram.  \\\n",
            "0              L’     True             l’    det   \n",
            "1          Italie    False         Italie  propn   \n",
            "2         choisit    False        choisit   noun   \n",
            "3   ArcelorMittal    False  arcelormittal    adj   \n",
            "4            pour     True           pour    adp   \n",
            "5       reprendre    False      reprendre   verb   \n",
            "6              la     True             le    det   \n",
            "7            plus     True           plus    adv   \n",
            "8          grande    False          grand    adj   \n",
            "9         aciérie    False        aciérie   noun   \n",
            "10             d’     True             d’      x   \n",
            "11         Europe    False         Europe  propn   \n",
            "\n",
            "                                               Morph.    Dép.  \n",
            "0   (Definite=Def, Gender=Masc, Number=Sing, PronT...     det  \n",
            "1                           (Gender=Fem, Number=Sing)   nsubj  \n",
            "2                          (Gender=Masc, Number=Sing)    ROOT  \n",
            "3                          (Gender=Masc, Number=Sing)    amod  \n",
            "4                                                  ()    mark  \n",
            "5                                      (VerbForm=Inf)   advcl  \n",
            "6   (Definite=Def, Gender=Fem, Number=Sing, PronTy...     det  \n",
            "7                                                  ()  advmod  \n",
            "8                           (Gender=Fem, Number=Sing)    amod  \n",
            "9                           (Gender=Fem, Number=Sing)     obj  \n",
            "10                                                 ()     dep  \n",
            "11                          (Gender=Fem, Number=Sing)    ROOT  \n",
            "Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\n",
            "      Token  is_stop    Lemme  Gram.  \\\n",
            "0     Apple    False    apple   noun   \n",
            "1     lance    False    lance   noun   \n",
            "2   HomePod    False  homepod    adj   \n",
            "3     parce     True    parce  sconj   \n",
            "4       qu'     True      que  sconj   \n",
            "5        il     True       il   pron   \n",
            "6        se     True       se   pron   \n",
            "7      sent     True   sentir   verb   \n",
            "8    menacé    False  menacer   verb   \n",
            "9       par     True      par    adp   \n",
            "10       l'     True       le    det   \n",
            "11     Echo    False     echo   noun   \n",
            "12       d'     True       de    adp   \n",
            "13   Amazon    False   Amazon  propn   \n",
            "\n",
            "                                               Morph.       Dép.  \n",
            "0                          (Gender=Masc, Number=Sing)       ROOT  \n",
            "1                           (Gender=Fem, Number=Sing)       amod  \n",
            "2                           (Gender=Fem, Number=Sing)       ROOT  \n",
            "3                                                  ()       mark  \n",
            "4                                                  ()      fixed  \n",
            "5                (Gender=Masc, Number=Sing, Person=3)      nsubj  \n",
            "6                              (Person=3, Reflex=Yes)  expl:comp  \n",
            "7   (Mood=Ind, Number=Plur, Person=3, Tense=Pres, ...   aux:pass  \n",
            "8   (Gender=Masc, Number=Sing, Tense=Past, VerbFor...       ROOT  \n",
            "9                                                  ()       case  \n",
            "10          (Definite=Def, Number=Sing, PronType=Art)        det  \n",
            "11                          (Gender=Fem, Number=Sing)  obl:agent  \n",
            "12                                                 ()       case  \n",
            "13                         (Gender=Masc, Number=Sing)       nmod  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3UeYPftYmIg"
      },
      "source": [
        "## Analyse syntaxique\n",
        "\n",
        "Si l'analyse lexicale vise à décrire le mot, la syntaxe a pour objet de décrire les groupes de mots et les relations entre les mots ou groupes de mots.\n",
        "\n",
        "En syntaxe, il existe deux modèles d'analyse de la structure syntaxique:\n",
        "- L'**analyse en constituants** qui met en avant des groupes de mots correspondants à des catégories d'objets syntaxiques : groupe nominal, groupe verbal, groupe prépositionnel... La catégorie vient de la nature grammaticale d'un mot directeur dans le groupe de mots. Ces groupes ont une structure récursive (e.g. un groupe nominal peut contenir un groupe prépositionnel... \"L'histoire de ma vie\" contient \"de ma vie\"...). Suivant les écoles, on parle d'**analyse syntagmatique** (qui produit des  **syntagmes**) (et en anglais on parle de _chunking_ qui produit des _chunks_).\n",
        "- L'**analyse en dépendances**  (_dependency parsing_ en anglais) qui met en avant les fonctions jouées par des têtes lexicales (e.g. sujet, objet, modifieur...) vis-à-vis d'autres mots avec lesquels ils entretiennent des relations directes. Les relations entre les mots dessinent un arbre orienté. Le verbe de la proposition principale joue le rôle de la racine. Par exemple, dans la phrase \"L'histoire de ma vie se résume simplement\". La racine est le verbe \"résume\" à partir duquel au moins deux relations directes pourront partir : l'une vers la tête du sujet à savoir le nom \"histoire\" et l'autre vers la tête du complément de manière \"simplement\".\n",
        "\n",
        "Les constituants peuvent jouer le rôle de termes candidats pour indexer de l'information.\n",
        "\n",
        "L'arbre syntaxique peut être exploitée en simplification de phrases (les mots les plus proches de la racine sont les plus importants) ou bien dans des systèmes de question-réponse pour apparier un verbe d'une question avec des arguments possibles dans des phrases contenant une réponse possible.\n",
        "\n",
        "Pour en savoir plus sur l'analyse syntaxique, vous pouvez consulter les chapitres 12 \"Constituency Grammars\", 13 \"Constituency Parsing\" et 14 \"Dependency Parsing\" de [Speech and Language Processing par Dan Jurafsky and James H. Martin](https://web.stanford.edu/~jurafsky/slp3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-x8Ysc7baMq"
      },
      "source": [
        "### QUESTIONS : Analyse en constituants\n",
        "Le code suivant permet d'observer les 5 premières phrases exemples.\n",
        "\n",
        "* A la main, identifier pour chacune des phrases les syntagmes nominaux maximums qui les composent. Le terme 'nominal' dans 'syntagme nominal' signifie que la tête sémantique (le mot le plus important du syntagme) est un nom. 'Maximum' signifie qu'il n'existe pas de constituants nominaux qui les englobent.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n5acAV2aBYn",
        "outputId": "64f6e209-96ef-4663-cb1c-951bbbff05ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Observation des 5 premières phrases exemples\n",
        "for i in range(0,5):\n",
        "  spacy_doc = nlp(sentences[i])\n",
        "  print(i, spacy_doc.text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars\n",
            "1 Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\n",
            "2 San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n",
            "3 Londres est une grande ville du Royaume-Uni\n",
            "4 L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT7E2wvnZ_5v"
      },
      "source": [
        "* Le code suivant réalise l'identification automatique des syntagmes nominaux. Quels types d'erreurs rencontrez-vous ? Les syntagmes nominaux sont-ils raccords avec l'analyse grammaticale produite sur les tokens mots ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOHFhADebWV8",
        "outputId": "a70a4d8f-3453-4ffb-eeda-b92c5f3d8efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#spacy_noun_chunks_as_list = [(chunk.text,  chunk.root.text, chunk.root.dep_,\n",
        "#            chunk.root.head.text) for chunk in spacy_doc.noun_chunks]\n",
        "#pd.DataFrame(spacy_noun_chunks_as_list, columns=['text', 'root', 'dep', 'head'])\n",
        "for i in range(0,5):\n",
        "  spacy_doc = nlp(sentences[i])\n",
        "  print('sentence',i, spacy_doc.text)\n",
        "  for chunk in spacy_doc.noun_chunks:\n",
        "    print('chunk:', chunk.text) #, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
        "  print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence 0 Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars\n",
            "chunk: Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars\n",
            "\n",
            "sentence 1 Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\n",
            "chunk: Les voitures\n",
            "chunk: la responsabilité\n",
            "chunk: l'assurance\n",
            "chunk: les constructeurs\n",
            "\n",
            "sentence 2 San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n",
            "chunk: San Francisco\n",
            "chunk: les robots coursiers\n",
            "chunk: les trottoirs\n",
            "\n",
            "sentence 3 Londres est une grande ville du Royaume-Uni\n",
            "chunk: Londres\n",
            "chunk: Royaume\n",
            "chunk: -\n",
            "chunk: Uni\n",
            "\n",
            "sentence 4 L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe\n",
            "chunk: L’Italie\n",
            "chunk: la plus grande aciérie\n",
            "chunk: Europe\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LADl-NVXSdQN"
      },
      "source": [
        "### VOTRE RÉPONSE\n",
        "\n",
        "#### Identification manuelle\n",
        "\n",
        "1. \"1 milliard de dollars\"\n",
        "2. \"la responsabilité de l'assurance\"\n",
        "3. \"les robots coursiers\"\n",
        "4. \"une grande ville du Royaume-Uni\"\n",
        "5. \"la plus grande aciérie d’Europe\"\n",
        "\n",
        "#### Identification automatique\n",
        "\n",
        "Erreurs :\n",
        "\n",
        "- adjectif non inclu dans le syntagme nominal :\n",
        "```\n",
        "sentence 1 Les voitures autonomes déplacent ...\n",
        "chunk: Les voitures\n",
        "```\n",
        "- mauvaise interprétation d'un token non-alphabétique :\n",
        "```\n",
        "sentence 3 ... du Royaume-Uni\n",
        "chunk: Royaume\n",
        "chunk: -\n",
        "chunk: Uni\n",
        "```\n",
        "- syntagme nominal oublié :\n",
        "```\n",
        "sentence 4 ... choisit ArcelorMittal pour ...\n",
        "```\n",
        "\n",
        "Les syntagmes nominaux semblent raccords avec l'analyse grammaticale produite sur les tokens mots, ce qui justifierait la détection d'un unique syntagme nominal dans la première phrase, où le verbe a été considéré comme un adverbe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrP0M_8dTqp_"
      },
      "source": [
        "### QUESTIONS : Analyse en dépendance\n",
        "\n",
        "\n",
        "* Avant d'exécuter le code ci-dessous, identifiez à la main les 3 mots que vous estimez le plus important dans les  5 premières phrases exemples de spacy (0 à 4). Vous pouvez appliquer la stratégie de rechercher les têtes lexicales en priorisant d'abord le verbe, puis le sujet, puis l'objet, puis les compléments.\n",
        "\n",
        "* Le code suivant permet de visualiser la structure syntaxique en dépendance pour chacune des 5 premières phrases exemples. Les analyses vous semblent-elles correctes ? Donnez deux exemples d'erreurs distinctes. Malgré les erreurs, retrouvez-vous vos mots dans les 3 premiers niveaux de l'arbre (le 1er niveau est la racine) ?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkgQPtnBs5uC",
        "outputId": "afadc0eb-4a4a-48d5-f330-ac28461a7de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import d'une bibliothèque qui permet de visualiser les résultats de spaCy\n",
        "# ici les liens de dépendances entre les mots\n",
        "from spacy import displacy\n",
        "\n",
        "for i in range(0,5):\n",
        "  spacy_doc = nlp(sentences[i])\n",
        "  displacy.render(spacy_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"b0f8df2210b24363b8b7e93d2564bd28-0\" class=\"displacy\" width=\"2325\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cherche</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">à</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">acheter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">une</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">start-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">up</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">anglaise</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">pour</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">milliard</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">de</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">dollars</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat:name</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-2\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-6\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,177.0 2140.0,177.0 2140.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,266.5 L1987,254.5 2003,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0f8df2210b24363b8b7e93d2564bd28-0-11\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,89.5 2145.0,89.5 2145.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0f8df2210b24363b8b7e93d2564bd28-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2145.0,266.5 L2153.0,254.5 2137.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"d3bc446628f04c5080362a9218870606-0\" class=\"displacy\" width=\"2150\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Les</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">voitures</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">autonomes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">déplacent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">la</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">responsabilité</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">de</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">l'</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">assurance</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">vers</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">les</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">constructeurs</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-4\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-7\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1445.0,354.0 L1453.0,342.0 1437.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d3bc446628f04c5080362a9218870606-0-10\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1975.0,2.0 1975.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d3bc446628f04c5080362a9218870606-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1975.0,354.0 L1983.0,342.0 1967.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"0bd0a2fb98ff4100b9b6195af62e8aee-0\" class=\"displacy\" width=\"1975\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">San</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Francisco</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">envisage</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">d'</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">interdire</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">les</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">robots</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">coursiers</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">les</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">trottoirs</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-5\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 1095.0,89.5 1095.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,354.0 L1103.0,342.0 1087.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1260.0,354.0 L1268.0,342.0 1252.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-9\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1800.0,2.0 1800.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0bd0a2fb98ff4100b9b6195af62e8aee-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1800.0,354.0 L1808.0,342.0 1792.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"e7efa48a50df409381d1cacb096d7e00-0\" class=\"displacy\" width=\"1450\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Londres</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">est</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">une</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">grande</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">ville</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">du</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Royaume-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Uni</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 750.0,2.0 750.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e7efa48a50df409381d1cacb096d7e00-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e7efa48a50df409381d1cacb096d7e00-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"3131a26fab8440abbae3ab8afad566a4-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">L’</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Italie</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">choisit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">ArcelorMittal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">pour</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">reprendre</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">la</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">plus</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">grande</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">aciérie</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">d’</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">X</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">Europe</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-8\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3131a26fab8440abbae3ab8afad566a4-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3131a26fab8440abbae3ab8afad566a4-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hevn0R8Aahvs"
      },
      "source": [
        "### VOTRE RÉPONSE\n",
        "\n",
        "#### Identification manuelle\n",
        "\n",
        "Mots estimés les plus importants :\n",
        "\n",
        "1. Apple ; acheter ; start-up\n",
        "2. voitures ; déplacent ; responsabilité\n",
        "3. San Francisco ; envisage ; robots\n",
        "4. Londres ; est ; ville\n",
        "5. Italie ; choisit ; ArcelorMittal\n",
        "\n",
        "#### Identification automatique\n",
        "\n",
        "Erreurs :\n",
        "\n",
        "- mauvais rôle :\n",
        "```\n",
        "   Apple\n",
        "     | [flat:name]\n",
        "cherche\n",
        "```\n",
        "- mauvaise tête :\n",
        "```\n",
        "autonomes\n",
        "     |\n",
        "voitures\n",
        "```\n",
        "\n",
        "\n",
        "1ers niveaux :\n",
        "```\n",
        "      Apple\n",
        "        |\n",
        "   +----+----+\n",
        "   |         |\n",
        "cherche   acheter\n",
        "```\n",
        "```\n",
        "                  autonomes\n",
        "                      |\n",
        "   +------------+-----+------+----------------+\n",
        "   |            |            |                |\n",
        "voitures   déplacent   responsabilité   constructeurs\n",
        "```\n",
        "```\n",
        "                 envisage\n",
        "                     |\n",
        "   +------------+----+-----+---------+\n",
        "   |            |          |         |\n",
        "Francisco   interdire   robots   trottoirs\n",
        "```\n",
        "```\n",
        "                   ville\n",
        "                     |\n",
        "   +-------+-----+---+--+---------+--------+\n",
        "   |       |     |      |         |        |\n",
        "Londres   est   une   grande   Royaume-   Uni\n",
        "```\n",
        "```\n",
        "            choisit\n",
        "               |\n",
        "   +-----------+-------------+\n",
        "   |           |             |\n",
        "Italie   ArcelorMittal   reprendre\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfwLaFdP07oQ"
      },
      "source": [
        "## Reconnaissance d'entités nommées\n",
        "\n",
        "Les entités nomées sont des expressions qui désignent des noms de lieux (label `LOC`), de personnes (label `PERS`), d'organisation (label `ORG`), ou d'évènement (label `MISC`). Selon les systèmes, les dates/heures et les mesures peuvent aussi être considérées comme des entités nommées.\n",
        "\n",
        "\n",
        "\n",
        "D'un point de vue applicatif, le besoin est parfois d'identifier quelles entités sont en présence. D'autres fois, il peut importer de déterminer les positions/offsets (début/fin en termes de numéro de caractère) de l'entité nommée dans un texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlb0dRU21zsw"
      },
      "source": [
        "### QUESTIONS\n",
        "\n",
        "Le code suivant permet de visualiser entités nommées présentes dans le document analysé.\n",
        "* Listez les types d'entités (_labels_) présentes dans les exemples\n",
        "* Consultez l'analyse des 10 premières phrases exemples de spacy (0 à 9). Trouvez-vous des erreurs de délimitation d'entités nommées ? Dans l'étiquetage du type des entités ? Eventuellement, donner quelques exemples.\n",
        "* Jetez un oeil sur les performances (section *accuracy evaluation*) des modèles pour le français https://spacy.io/models/fr pour avoir une idée de la performance supposée de ceux-ci. Il ne vous est pas demandé de calculer les performances sur les données exemples !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkS1aoU2Brx",
        "outputId": "58dcfd10-21ac-45de-cf1a-98c1a2206b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        }
      },
      "source": [
        "# le code suivant permet de visualiser entités nommées présentes dans le document analysé\n",
        "# les offsets et le type d'entité sont aussi fournis\n",
        "for i in range(0,9):\n",
        "  spacy_doc = nlp(sentences[i])\n",
        "\n",
        "  # pour chaque entité nommé détectée dans la phrase courante\n",
        "  for ent in spacy_doc.ents:\n",
        "\n",
        "    # affiche le texte de l'entité nommée, ses offsets, et son \"type\"\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "  # finalement affiche la phrase en marquant visuellement les zones de textes\n",
        "  # où une entité nommée a été repérée\n",
        "  displacy.render(spacy_doc, style='ent', jupyter=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple 0 5 ORG\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " cherche à acheter une start-up anglaise pour 1 milliard de dollars</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "San Francisco 0 13 LOC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    San Francisco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " envisage d'interdire les robots coursiers sur les trottoirs</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Londres 0 7 LOC\n",
            "Royaume-Uni 32 43 LOC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Londres\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " est une grande ville du \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Royaume-Uni\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L’Italie 0 8 PER\n",
            "ArcelorMittal 17 30 ORG\n",
            "Europe 71 77 LOC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    L’Italie\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " choisit \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ArcelorMittal\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " pour reprendre la plus grande aciérie d’\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Europe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple 0 5 ORG\n",
            "HomePod 12 19 MISC\n",
            "Echo 53 57 LOC\n",
            "Amazon 60 66 ORG\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " lance \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    HomePod\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " parce qu'il se sent menacé par l'\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Echo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " d'\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amazon\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La France 0 9 LOC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    La France\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ne devrait pas manquer d'électricité cet été, même en cas de canicule</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trump 22 27 PER\n",
            "Londres 47 54 LOC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Nouvelles attaques de \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " contre le maire de \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Londres\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Où es-tu ?</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liw6iMfw16KF"
      },
      "source": [
        "### VOS RÉPONSES\n",
        "\n",
        "Erreurs :\n",
        "\n",
        "- délimitation d'entités nommées :\n",
        "```\n",
        "La France 0 9 LOC\n",
        "```\n",
        "- étiquetage du type des entités :\n",
        "```\n",
        "L’Italie 0 8 PER\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoBU3isucVpQ"
      },
      "source": [
        "## Expérience personnelle vs performances attestées\n",
        "\n",
        "L'étiquetage grammaticale consiste à donner une étiquette à chacun des mots. Tous les mots auront une étiquette. La performance correspondra alors à combien d'étiquettes de mots sont correctement trouvés sur le nombre total de mots. On parlera de mesure d'**exactitude** (_accuracy_ en anglais, souvent abrégé en _acc_) dans ce cas.\n",
        "\n",
        "La reconnaissance des entités nommées est une tâche un peu différente. A l'instar de l'étiquetage grammatical, elle peut être vue comme mettre une étiquette \"entité nommée\" à certains des mots. Mais à la différence de l'étiquetage grammatical, il s'agit de déterminer les mots qui doivent recevoir une étiquette \"entité nommée\". Dans cette tâche, on évalue d'une part la capacité à retrouver TOUS LES MOTS qui portent une étiquette \"entité nommée\" ; on parlera de mesure de **rappel** (_recall_). Et d'autre part, on évalue la qualité de la prédiction (sur les mots que l'on dit porter une étiquette \"entité nommée\", combien sont correctes) ; on parlera de mesure de **précision** (_precision_) qui est similaire à la notion d'exactitude.\n",
        "\n",
        "Comme c'est souvent plus simple d'avoir un seul score plutôt que deux, on utilise la mesure de **F-score** qui correspond à une moyenne (harmonique) des scores de précision et de rappel.\n",
        "\n",
        "Si ce n'est pas clair... https://fr.wikipedia.org/wiki/Pr%C3%A9cision_et_rappel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRFF9cpUczG2"
      },
      "source": [
        "### QUESTIONS\n",
        "* Jeter un oeil sur les performances (section *accuracy evaluation*) du modèle utilisé pour le français https://spacy.io/models/fr pour avoir une idée de la performance supposée de celui-ci sur les tâches d'analyse linguistique (tokenization, étiquetage grammatique, lemmatisation, analyse morphologique, analyse en dépendance et reconnaissance d'entités nommées). Est-ce raccord avec ce que vous avez observé ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUhWwwVGc5hA"
      },
      "source": [
        "### VOTRE RÉPONSE\n",
        "\n",
        "**TODO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2GNFxUwaNaM"
      },
      "source": [
        "---\n",
        "# Analyse de textes de genres différents\n",
        "\n",
        "Le code suivant télécharge dans un répertoire `data` un corpus de phrases issus de 4 genres différents : textes parlementaires européens (_legal europarl_), dépèches journalistiques (_news_wikinews_), littératique romanesque (_roman verne_), et des tweets de twitter (_tweets twitter_).\n",
        "\n",
        "Exécuter le.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2MikY8trjs-",
        "outputId": "3f7e3b97-56e3-4398-a762-be66a06da7c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir data\n",
        "!wget -nc https://raw.githubusercontent.com/nicolashernandez/teaching_nlp/main/data/fr_raw_25000sentences_4genres.zip -P data\n",
        "!unzip data/fr_raw_25000sentences_4genres.zip -d data"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-12 08:15:48--  https://raw.githubusercontent.com/nicolashernandez/teaching_nlp/main/data/fr_raw_25000sentences_4genres.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4848508 (4.6M) [application/zip]\n",
            "Saving to: ‘data/fr_raw_25000sentences_4genres.zip’\n",
            "\n",
            "fr_raw_25000sentenc 100%[===================>]   4.62M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-09-12 08:15:48 (50.3 MB/s) - ‘data/fr_raw_25000sentences_4genres.zip’ saved [4848508/4848508]\n",
            "\n",
            "Archive:  data/fr_raw_25000sentences_4genres.zip\n",
            "  inflating: data/legal_europarl.txt  \n",
            "  inflating: data/news_wikinews.txt  \n",
            "  inflating: data/roman_verne.txt    \n",
            "  inflating: data/tweets_twitter.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtcfjtV01OSi"
      },
      "source": [
        "\n",
        "## QUESTIONS\n",
        "\n",
        "Le code suivant charge tour à tour chacun des corpus et traite les 5 premières phrases de chaque corpus. Deux résultats de traitement sont observés : la tokenization et la reconnaissance d'entités nommées à l'aide de spaCy et du modèle pour le français précédemment utilisé.\n",
        "\n",
        "* Quels problèmes de tokenization relevez-vous suivant les genres de texte ? Y-a-t'il des genres pour lesquels la tokenization fonctionne mieux que d'autres ?\n",
        "* Mêmes questions pour la reconnaissance des entités nommées.\n",
        "* Quels corpus (et donc quels genres de texte) ont servi de données d'entraînement pour construire le modèle français utilisé ici avec spaCy (cf. https://spacy.io/models/fr) ? Est-ce que cela peut expliquer les performances observées ?  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ETeuhrev-7z"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "filenames = ['legal_europarl', 'news_wikinews', 'roman_verne', 'tweets_twitter']\n",
        "for filename in filenames:\n",
        "  with open(\"data/\"+filename+\".txt\", 'r', encoding='UTF-8') as file:\n",
        "    i = 0\n",
        "    print('-->', filename.upper())\n",
        "    print()\n",
        "    for line in file:\n",
        "        doc = line.rstrip()\n",
        "        spacy_doc = nlp(doc)\n",
        "        print('Sentence',i,':', doc)\n",
        "        print ('spacy_tokenize:', [token.text for token in spacy_doc])\n",
        "        if spacy_doc.ents: displacy.render(spacy_doc, style='ent', jupyter=True)\n",
        "        #spacy_doc_as_list = [(token.text, token.lemma_, token.pos_) for token in spacy_doc]\n",
        "#            , token.tag_,token.shape_, token.is_alpha, token.is_stop) for token in doc]\n",
        "        #print (pd.DataFrame(spacy_doc_as_list, columns=['Token', 'Lemma', 'POS']))\n",
        "        print ()\n",
        "        i += 1\n",
        "        if i==5: break\n",
        "    print ('------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQz5q0C9_PD"
      },
      "source": [
        "\n",
        "## VOTRE RÉPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsXOzv3zo_qB"
      },
      "source": [
        "---\n",
        "# Multilinguisme\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Donnés les éléments suivants :\n",
        "* https://spacy.io/models\n",
        "* https://fr.wikipedia.org/wiki/Liste_de_langues_par_nombre_total_de_locuteurs\n",
        "* Le score F-score est une moyenne des scores de Précision et de Rappel.\n",
        "* un [tableau des performances de spaCy telles que présentées en oct 2021 pour le 1er modèle de chaque langue](https://github.com/nicolashernandez/teaching_nlp/raw/main/performances%20spacy%20oct%202021.ods)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAx3TzhMhlWU"
      },
      "source": [
        "\n",
        "### QUESTIONS\n",
        "1. Peut-on considérer que la _tokenization_ est un problème réglé ? Quelle est la langue pour laquelle la performance est la plus basse ? Selon vous, est-ce un problème de ressources ou bien de spécificité de la langue ?\n",
        "\n",
        "2. Peut-on considérer que la _segmentation en phrase_ est un problème réglé ? Quelles sont les deux langues pour lesquelles les performances sont les plus basses ? Selon vous, est-ce un problème de ressources ou bien de spécificité de la langue ?  \n",
        "\n",
        "3. Pourquoi des performances d'analyse morphologique et grammatical ne sont pas rapportées pour toutes les langues ?\n",
        "\n",
        "4. Peut-on considérer que l' _étiquetage grammatical_ est un problème réglé ?\n",
        "\n",
        "5. Peut-on considérer que l' _analyse morphologique comprenant la lemmatisation_ est un problème réglé ?\n",
        "\n",
        "\n",
        "6. Peut-on considérer que la _reconnaissance des entités nommées_ est un problème réglé ?\n",
        "\n",
        "7. Peut-on considérer que l'_analyse syntaxique en dépendance_ est un problème réglé ?\n",
        "\n",
        "8. Citer deux langues parmi les langues les plus parlées dans le monde (en nombre total de locuteur) qui ne sont pas prises en charge par spacy.\n",
        "\n",
        "9. Trouvez-vous sur le web des bibliothèques (python) qui offrent (partiellement ou totalement) les mêmes traitements que Spacy sur ces langues ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdDSYDxAiOfm"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "1. Oui, en considérant uniquement ces langues et en supposant de leur évolution future. La performance est la plus basse pour la langue chinoise. Je suppose cela être un problème de spécificité de la langue, les ressources n'étant supposément pas un problème de par le nombre important de locuteurs.\n",
        "2. Non. La performance est la plus basse pour les langues chinoise et macédonienne. Je suppose cela être un problème de spécificité de la langue pour le chinois, et de ressources pour le macédonnien.\n",
        "3. Certaines langues peuvent ne pas avoir de grammaire claire, ou varier fortement selon les différents dialectes.\n",
        "4. Non.\n",
        "5. Non.\n",
        "6. Non.\n",
        "7. Non.\n",
        "8. L'hindi et l'arabe.\n",
        "9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikRxwNo-7K5E"
      },
      "source": [
        "---\n",
        "# Benchmark NLP libs\n",
        "\n",
        "Ci-dessous quelques comparatifs de performance (~qualité et temps de traitement) selon les auteurs de bibliothèques.\n",
        "* spacy vs: stanza, flair https://spacy.io/usage/facts-figures\n",
        "* trankit vs: stanza, spacy... https://trankit.readthedocs.io/en/latest/performance.html\n",
        "* stanford vs: spacy https://nlp.stanford.edu/software/tokenizer.html#Speed (https://twitter.com/chrmanning/status/1013563834655621120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Hehbr6_Pjt"
      },
      "source": [
        "### QUESTIONS\n",
        "* En vous appuyant le comparatif rapporté par spaCy, observer les performances (qualité et temps de traitement) de spaCy, Stanza et de Flair sur des tâches reconnaissance d'entités nommées et de parsing en anglais, diriez-vous que Spacy est 1) la meilleure solution, 2) une solution état de l'art, 3) de performance moindre que les solutions existantes ?\n",
        "* Selon le comparatif de trankit, comment celui-ci se positionne sur la tâche de reconnaissance d'entités nommées par rapport à ses concurrents Stanza et spaCy ? Sur quel corpus et quelle langue peut-on faire ce comparatif ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW8cF6u9_Q52"
      },
      "source": [
        "\n",
        "### VOTRE REPONSE\n",
        "\n",
        "- Selon son comparatif, *spaCy* semble être une solution de performance moindre que les solutions existantes.\n",
        "- Selon son comparatif, *trankit* semble être une solution de meilleure performance que son concurrent *Stanza*, quelle que soit la langue et le jeu de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KiEX6l7lNgN"
      },
      "source": [
        "# Références\n",
        "* https://github.com/clement-plancq/outils-corpus/blob/master/outils_corpus-5.ipynb\n"
      ]
    }
  ]
}