{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpGsVhySA+ryYekEEszOHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/06_biasandethics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2NDYD5Es0Ic"
      },
      "source": [
        "--\n",
        "# Biais des modèles construits sur des données\n",
        "\n",
        "Pour les questions suivantes, expliquez votre démarche et donnez les codes qui soutiennent vos observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modèle non contextuel et similarités en les mots\n",
        "\n",
        "⚠ Cette question a déjà été traitée en cours et n'est donc plus à traiter.\n",
        "\n",
        "### QUESTION \n",
        "* Jouez avec les opérations sur les vecteurs d'embeddings statiques. Prenez le mot \"humain\", retirer \"homme\" et ajouter \"métier\"...\n",
        "* Relevez-vous des situations d'opérations qui mettent à jour des biais sexistes, racistes ou autres ? "
      ],
      "metadata": {
        "id": "vEukLqdiHbYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ],
      "metadata": {
        "id": "xkfc_V29Q4SH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DJ8-vccGwrP"
      },
      "source": [
        "## Génération de textes\n",
        "\n",
        "[huggingface](https://huggingface.co/models) est le \"github\" des modèles pré-entraînés éventuellement fine-tunés.\n",
        "\n",
        "Le code ci-dessous permet d'utiliser un modèle génératif et de tester en anglais la génération de texte."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "NQ6HCpZFz9qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "from transformers import pipeline, set_seed\n",
        "\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "generator(\"The White man worked as a\", max_length=10, num_return_sequences=5)\n",
        "generator(\"The Black man worked as a\", max_length=10, num_return_sequences=5)"
      ],
      "metadata": {
        "id": "2ZPo88Tuz-iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LogIfuPQIQ1f"
      },
      "source": [
        "### QUESTION\n",
        "\n",
        "* Parmi les ressources communautaires de hugging face, recherchez la ressource de génération de texte qui utilise le modèle `gpt-fr-cased-base` pour le français. Donnez le lien de la page et mettez en oeuvre le code mis à disposition. \n",
        "* Donnez des débuts de phrases pour amorcer la génération. Relevez-vous des situations qui mettent à jour des biais sexistes, racistes ou autres ? \n",
        "\n",
        "Pour aller plus loin au sujet de [GPT2](https://huggingface.co/transformers/model_doc/gpt2.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvCpKgxJITi0"
      },
      "source": [
        "#### VOTRE REPONSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyEqlMYvGy-2"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYZWqH9RIvL0"
      },
      "source": [
        "Le code suivant encapsule la partie génération... _accidentellement_ le paramètre `top_k` est passé à 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q_T0duJIuek"
      },
      "source": [
        "def generate (input_sentence):\n",
        "  input_ids = tokenizer.encode(input_sentence, return_tensors='pt')\n",
        "  beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=20, # taille maximale de la séquence \n",
        "    do_sample=True,   \n",
        "    top_k=5, # nombre de séquences générées\n",
        "    top_p=0.95, \n",
        "    num_return_sequences=1\n",
        "  )\n",
        "  print(\"Output:\\n\" + 100 * '-')\n",
        "  print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpqf6EMMKdkE"
      },
      "source": [
        "... afin de pouvoir l'utiliser à votre guise : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2pK6ZFuKaPB"
      },
      "source": [
        "input_sentence = \"Mon mari travaille comme\"\n",
        "generate (input_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction (modèle en production)\n",
        "\n",
        "Soit le texte suivant\n",
        "> *Elle est médecin. Il est infirmier.*\n"
      ],
      "metadata": {
        "id": "8vq37kPRHS5r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZ-kRIWui7t"
      },
      "source": [
        "\n",
        "### QUESTIONS\n",
        "* Ouvrir [Google Translate dans votre navigateur](https://translate.google.fr/?hl=fr&sl=fr&tl=en&text=Elle%20est%20m%C3%A9decin.%20Il%20est%20infirmier.&op=translate)\n",
        "* Traduire du français (langue source) vers l'anglais (langue cible). Cliquer deux fois sur \"Intervertir les langues\" (pour traduire une fois vers l'anglais puis pour retraduire l'anglais vers le français). Observez-vous quelque chose ?\n",
        "* Faire la même chose en prenant comme langue cible du Hongrois. Observez vous quelque chose ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scPvHf9wumB1"
      },
      "source": [
        "### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic detection of bias\n",
        "\n",
        "huggingface met à disposition un modèle *d4data/bias-detection-model* qui détecte les biais des articles de journaux.\n"
      ],
      "metadata": {
        "id": "I5o0ghH4N9E7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### QUESTION\n",
        "* Donnez l'URL du modèle. Testez le modèle de prédiction de biais (en partant du code exemple) et évaluez qualitativement les limites."
      ],
      "metadata": {
        "id": "4zeIYGF3P6QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ],
      "metadata": {
        "id": "IpMjXJOeQT5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traduction avec le modele séquence to sequence T5\n",
        "\n",
        "Le code suivant permet d'[utiliser le modèle seq-to-seq à base de prompt *t5-small* disponible sur hugging face](https://huggingface.co/t5-small)"
      ],
      "metadata": {
        "id": "PegyjFkiNRLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5TokenizerFast.from_pretrained('t5-small')\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small', return_dict=True)\n",
        "\n",
        "input = \"My name is Azeem and I live in India\"\n",
        "\n",
        "# You can also use \"translate English to French\" and \"translate English to Romanian\"\n",
        "input_ids = tokenizer(\"translate English to Romanian: \"+input, return_tensors=\"pt\").input_ids  # Batch size 1\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "\n",
        "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(decoded)"
      ],
      "metadata": {
        "id": "DOX4lW9L4-VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### QUESTION\n",
        "* Testez le modèle de traduction du français vers l'anglais et évaluez qualitativement les limites\n",
        "* Testez de traduire de l'anglais vers du russe et du russe vers de l'anglais... par exemple \"L'esprit est fort mais la chair est faible\".\n",
        "* Développez une application qui prédit les biais en français en passant par la traduction de l'anglais"
      ],
      "metadata": {
        "id": "jZAjav6dOtjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ],
      "metadata": {
        "id": "z_Rsu2IWQuhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculer l'impact de votre usage des GPU dans ce cours en CO2\n",
        "\n",
        "Pour ce faire utilisez l'application [Machine Learning has a carbon footprint](https://mlco2.github.io/impact).\n",
        "\n",
        "Commencez par identifier votre GPU, puis approximez le temps passé sur GPU et calculez... observez les équivalences.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uyewU5oVHxqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ],
      "metadata": {
        "id": "2oxFY_gRQzAp"
      }
    }
  ]
}