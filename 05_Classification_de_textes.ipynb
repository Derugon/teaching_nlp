{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/teaching_nlp/blob/main/05_Classification_de_textes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxdW5mtMGqmy"
      },
      "source": [
        "# Classification de textes\n",
        "\n",
        "La **classification** consiste à attribuer une classe à chaque texte (objet, instance, point) à classer. On parle de *classification binaire* (_binary classification_) quand il y a deux classes exclusives. On parle de *classification en classes multiples* (_multiclass classification_) pour désigner la répartition d'un lot de textes entre plus de deux ensembles (ou classes), une classe par instance. On parle de *classification multi-étiquettes* (_multi-label classification_) pour désigner les problèmes de classification où plusieurs étiquettes (classes) peuvent être assignées à une même instance.\n",
        "\n",
        "Reconnaître si un email est un spam, si une photo contient une voiture... sont des problèmes de classification (binaire).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7PRm8jl2cE0"
      },
      "source": [
        "# Sentiment analysis as a classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee8F8DyZ9v7x"
      },
      "source": [
        "\n",
        "La tâche classique d'analyse de sentiment consiste à annoter un texte donné selon une polarité positive ou négative exprimée dans le texte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbuBLXmt3NyE"
      },
      "source": [
        "## QUESTION\n",
        "\n",
        "* Selon vous la tâche d'analyse de sentiment tel que définie juste au dessus peut se définir comme un problème de 1) classification binaire, 2) classification en classes multiples ou 3) en classification multi-étiquettes ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjOoxLi3m7E"
      },
      "source": [
        "## VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h06bBaA34vf"
      },
      "source": [
        "# Configuration de l'environnement Google Colab en mode GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WveM1n9KFNx6"
      },
      "source": [
        "Quel mode d'exécution utilisez-vous (via GPU ou via CPU) ? Que vous dis le code ci-dessous ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bwHyWGuWiCUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1541fc37-b84b-4eda-c58a-1825cb112d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.7 GB  | Proc size: 4.1 GB\n",
            "GPU RAM Free: 881MB | Used: 14228MB | Util  94% | Total 15109MB\n"
          ]
        }
      ],
      "source": [
        "# memory footprint support libraries/code\n",
        "# https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "#\n",
        "\n",
        "if len(GPUs) >0: \n",
        "  gpu = GPUs[0]\n",
        "  printm()\n",
        "else:\n",
        "  print ('no GPU. Are you sure the hardware accelerator is configured to GPU? To do this go to Runtime→Change runtime type and change the Hardware accelerator to GPU.') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxVCJnn3OBq2"
      },
      "source": [
        "Configurez votre mode d'exécution du Google Colab en mode GPU.\n",
        "\n",
        "> To use the google colab in a GPU mode you have to make sure the hardware accelerator is configured to GPU. To do this go to Runtime→Change runtime type and change the Hardware accelerator to GPU. Sometimes, all GPUs are in use and there is no GPU available.\n",
        "\n",
        "Une fois configuré le GPU, vérifiez l'état de la mémoire sur la carte en réexécutant le code \"memory footprint\" ci-dessus. Le message a-t-il changé favorablement ?\n",
        "\n",
        "Le mode d'exécution GPU est nécessaire pour le fine-tuning de BERT ci-dessous. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE0PnqNnM1tB"
      },
      "source": [
        "# Allociné dataset\n",
        "\n",
        "The [Allociné dataset](https://huggingface.co/datasets/allocine) is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the Allociné.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxo9pzqyVwIG"
      },
      "source": [
        "### From huggingface datahub\n",
        "\n",
        "After execution of this cell, you must restart the runtime in order to use  newly installed versions.\n",
        "\n",
        "Just click on the button on the suggester \"restart runtime\" button (or go the runtime menu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PXgmkHWnxIS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a2ed52-f346-4c91-c4a3-d6edc19a0efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the [allociné dataset](https://huggingface.co/datasets/allocine) from the huggingface hub."
      ],
      "metadata": {
        "id": "1eCtRF0tbm5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "3e3c37d026b342a98099570c69041ff8",
            "1abed1f130624b51ae9e28e790231f0e",
            "13907da6d316429a8d2aa4352308d9fb",
            "824c678dabe84dab8ed45e11cec05d56",
            "ebc37f85026e4f57b7e572d35de0e3a7",
            "e4c6925644584f14bb3a50a1812ac013",
            "440d69351b164f789c8968bb7de18a02",
            "97838a8a50454d229332fa03aac68c48",
            "4c56100a330a46a3874a672fdee9283e",
            "94d04c416b3640f390e02cba5f57b102",
            "99fae420c32549f5a8a02db02306c777"
          ]
        },
        "id": "qvYzPpHJwSEu",
        "outputId": "91bb9145-68c1-465d-cf21-6d3e5748a0cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Allocine Dataset: A Large-Scale French Movie Reviews Dataset.\n",
            " This is a dataset for binary sentiment classification, made of user reviews scraped from Allocine.fr.\n",
            " It contains 100k positive and 100k negative reviews divided into 3 balanced splits: train (160k reviews), val (20k) and test (20k).\n",
            "\n",
            "{'review': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset allocine (/root/.cache/huggingface/datasets/allocine/allocine/1.0.0/ea86b1dc05eae3a45a07b6281f2d4033b5fe7927b1008d06aa457ca1eae660d0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e3c37d026b342a98099570c69041ff8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review', 'label'],\n",
              "        num_rows: 160000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review', 'label'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review', 'label'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# https://huggingface.co/datasets/allocine\n",
        "\n",
        "from datasets import load_dataset_builder\n",
        "ds_builder = load_dataset_builder(\"allocine\")\n",
        "\n",
        "# Inspect dataset description\n",
        "print(ds_builder.info.description)\n",
        "\n",
        "# Inspect dataset features\n",
        "print(ds_builder.info.features)\n",
        "\n",
        "# get_dataset_split_names\n",
        "from datasets import get_dataset_split_names\n",
        "get_dataset_split_names(\"allocine\")\n",
        "\n",
        "# load_dataset\n",
        "from datasets import load_dataset\n",
        "allocine_dataset = load_dataset(\"allocine\")\n",
        "allocine_dataset\n",
        "#train_dataset = load_dataset(\"allocine\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvdy-2-DV9zX"
      },
      "source": [
        "#### Select data ratio to process and create Pandas DataFrame\n",
        "\n",
        "Definition of a method to select a ratio of a dataset split. By default return 100 % of the split."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_dataset_split_ratio(dataset_split, seed=42, ratio=100):\n",
        "  if ratio > 100 or ratio < 1: ratio = 100\n",
        "  reviews = dataset_split['review']\n",
        "  labels = dataset_split['label']\n",
        "  \n",
        "  data = [pair for pair in zip(reviews, labels)]\n",
        "  \n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(data)\n",
        "  \n",
        "  ratio_len = int(len(data)*ratio/100)\n",
        "  \n",
        "  data = list(zip(*data))\n",
        "\n",
        "  return {'review':data[0][:ratio_len], 'label':data[1][:ratio_len]}\n"
      ],
      "metadata": {
        "id": "AIdQWqGa7WmB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of the method to create a dataframe from a huggingface dataset split (`{'review':[], 'label':[]}`) :"
      ],
      "metadata": {
        "id": "2v5boWFkDIhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "BEkNPZg705jM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# From huggingface dataset split to DataFrame\n",
        "def hf_dataset_split_to_df (huggingface_dataset_split):\n",
        "  df = pd.DataFrame(huggingface_dataset_split)\n",
        "  # https://github.com/amaiya/ktrain/blob/master/examples/text/ArabicHotelReviews-nbsvm.ipynb\n",
        "  df['label'] = df['label'].apply(lambda x: 'negative' if x == 0 else 'positive')\n",
        "  df = pd.concat([df, df.label.astype('str').str.get_dummies()], axis=1, sort=False)\n",
        "  df = df[['review', 'negative', 'positive']]\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sélectionner la taille des données sur lesquelles vous voulez travailler et construire la dataframe correspondante.\n",
        "\n",
        "Le code ci-dessous extrait 5 % du corpus. C'est suffisant pour étudier comment fonctionne les modèles présentés ci-après sans attendre trop de temps d'entraînement."
      ],
      "metadata": {
        "id": "uqrzl25ODe2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = 100 # percent of the data\n",
        "\n",
        "train_df = hf_dataset_split_to_df(get_dataset_split_ratio(allocine_dataset['train'], 42, ratio))\n",
        "val_df = hf_dataset_split_to_df(get_dataset_split_ratio(allocine_dataset['validation'], 42, ratio))\n",
        "test_df = hf_dataset_split_to_df(get_dataset_split_ratio(allocine_dataset['test'], 42, ratio))\n",
        "\n",
        "print(train_df.head())\n",
        "print(train_df.describe())\n",
        "print('len(train_df) :', len(train_df))\n",
        "print('len(val_df) :', len(val_df))\n",
        "print('len(test_df) :', len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmwbpxGDCl66",
        "outputId": "66c0ea2a-1b10-4fae-913d-6caf324a5ecd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  negative  positive\n",
            "0  Un excellent thriller d'action où les scènes d...         0         1\n",
            "1  Si le scénariste, qui aurait pu faire un minim...         1         0\n",
            "2  Référence dans la filmographie de Bogart, \"Le ...         1         0\n",
            "3  Un bon scénario, un bon film, une histoire lou...         0         1\n",
            "4  Un scenario vide et une mise en scene trés sop...         1         0\n",
            "            negative       positive\n",
            "count  160000.000000  160000.000000\n",
            "mean        0.496331       0.503669\n",
            "std         0.499988       0.499988\n",
            "min         0.000000       0.000000\n",
            "25%         0.000000       0.000000\n",
            "50%         0.000000       1.000000\n",
            "75%         1.000000       1.000000\n",
            "max         1.000000       1.000000\n",
            "len(train_df) : 160000\n",
            "len(val_df) : 20000\n",
            "len(test_df) : 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLfw1G8wMxkz"
      },
      "source": [
        "# ktrain\n",
        "\n",
        "[ktrain](https://github.com/amaiya/ktrain) a lightweight wrapper for the deep learning library _TensorFlow Keras_ (and other libraries) to help build, train, and deploy neural networks and other machine learning models. Inspired by ML framework extensions like fastai and ludwig, ktrain is designed to make deep learning and AI more accessible and easier to apply for both newcomers and experienced practitioners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration et installation de ktrain\n",
        "\n",
        "Configuration de l'environnement"
      ],
      "metadata": {
        "id": "OMQniIpmoI6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jZ-F6wCZRYpw"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUvbU_z33-Lw"
      },
      "source": [
        "Installation de la bibliothèque ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxWRMgrKR7Q1",
        "outputId": "1d68e8df-c9fe-4c74-c2a1-c5bf38611bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.31.10)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: transformers==4.17.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: syntok>1.3.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.97)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.89.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (0.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (0.0.53)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->ktrain) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0->ktrain) (4.1.1)\n",
            "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
            "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
            "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
            "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
            "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.17.0->ktrain) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2022.9.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0->ktrain) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ktrain) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ktrain) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7LRCuPB4p-y"
      },
      "source": [
        "Import de la bibliothèque ktrain dédié aux traitements de la modalité textuelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2avp8suURzMT"
      },
      "outputs": [],
      "source": [
        "# Execution time 30 s\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYGyWUwn9yPS"
      },
      "source": [
        "## Fonctionnement de ktrain\n",
        "\n",
        "\n",
        "Pour réaliser cette tâche de classification nous allons utiliser la bibliothèque ktrain pour faire un apprentissage par transfert.\n",
        "\n",
        "Les étapes sont les suivantes\n",
        "1. chargement des données avec application d'un prétraitement défini à la volée\n",
        "2. construction d'un modèle de classification sur la base d'un modèle pré-entraîné spécifié\n",
        "3. récupération d'une instance du modèle pour la personnalisation de celui-ci\n",
        "4. recherche d'un bon taux d'apprentissage\n",
        "5. entraînement du classifieur i.e. personnalisation du modèle de base à l'aide d'un taux d'apprentissage défini\n",
        "6. utilisation du nouveau modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAvPw6g49WGa"
      },
      "source": [
        "*ETAPE 1 :* \n",
        "\n",
        "Le type de pré-traitement est fonction du modèle pré-entraîné spécifié."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTBW_SEO9mXi"
      },
      "source": [
        "*ETAPE 2 :*\n",
        "\n",
        "ktrain vient avec quelques modèles pré-entraînés packagés. Pour les connaître, exécutez : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7FvrdBC9n2W",
        "outputId": "5cc45043-a6c5-4502-8555-09f49e1435b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
            "logreg: logistic regression using a trainable Embedding layer\n",
            "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
            "bigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\n",
            "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
            "bert: Bidirectional Encoder Representations from Transformers (BERT) from keras_bert [https://arxiv.org/abs/1810.04805]\n",
            "distilbert: distilled, smaller, and faster BERT from Hugging Face transformers [https://arxiv.org/abs/1910.01108]\n"
          ]
        }
      ],
      "source": [
        "text.print_text_classifiers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae1TJ5nk_K7G"
      },
      "source": [
        "Vous connaissez **[fasttext](https://github.com/facebookresearch/fastText)** de (Facebook/Meta) car vous l'avez déjà utilisé dans un [précédent TP](https://github.com/nicolashernandez/teaching_nlp/blob/main/04_repr%C3%A9sentation_vectorielle_continue.ipynb)... fasttext permet de produire une représentation continue des mots en suivant une approche à la word2vec. Sa spécificité est qu'il propose de traiter la variabilité morphologique des mots en construisant des vecteurs non pas pour des mots mais pour des sous-mots (séquence de caractères). Le vecteur d'un mot est la somme de tous les vecteurs des sous-mots le composant. Cette approche est indépendante de la langue, et montre de meilleurs résultats que word2vec sur des tâches syntaxiques, surtout quand le corpus d'entraînement est petit. Word2vec est légèrement meilleur pour des tâches sémantiques. Un des avantage de FastText est de pouvoir fournir des vecteurs mêmes pour les mots hors vocabulaires.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XtFCEfYWchi"
      },
      "source": [
        "[**NBSVM**](https://medium.com/@asmaiya/a-neural-implementation-of-nbsvm-in-keras-d4ef8c96cb7c) is an approach to text classification proposed by [Wang and Manning](https://www.aclweb.org/anthology/P12-2018) that takes a linear model such as SVM (or logistic regression) and infuses it with Bayesian probabilities by replacing word count features with Naive Bayes log-count ratios. Despite its simplicity, NBSVM models have been shown to be both fast and powerful across a wide range of different text classification datasets. \n",
        "Keras offers a NBSVM model implemented as a neural network using two embedding layers. The first stores the Naive Bayes log-count ratios. The second stores learned weights (or coefficients) for each feature (i.e., word) in this linear model. The prediction, then, is simply the dot product of these two vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0H3RJMw_xhB"
      },
      "source": [
        "**BERT** (_Bidirectional Encoder Representations from Transformers_), proposé par [Google AI Language](https://arxiv.org/pdf/1810.04805.pdf) est un encodeur bidirectionnel qui applique un modèle d'attention Transformers à la modélisation du language (_language modeling_). Il représente l'état de l'art.\n",
        "Les Transformers sont un mécanisme d'attention qui apprennent les relations contextuelles entre les mots dans un texte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3bN2mE_xyi"
      },
      "source": [
        "Il est possible d'[**encapsuler les modèles Transformers du site _hugging face_**](https://github.com/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb). _hugging face_ diffuse les [modèles Transformers pré-entraînés \"officiels\"](https://huggingface.co/transformers/pretrained_models.html) ainsi que les [modèles Transformers construits par la communauté](https://huggingface.co/models).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wINsCEpD1-s"
      },
      "source": [
        "*ETAPE 4 :*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4syPI6CI6Vt6"
      },
      "source": [
        "Le **taux d'apprentissage (_learning rate_)** est un hyperparamètre qui contrôle combien le modèle doit changer en réponse à l'erreur estimée à chaque fois que les poids du modèles sont mis à jour. Choisir un 'lr' trop petit conduit à une longue phase d'entraînement qui peut resté bloquée. Choisir un 'lr' trop grand conduit à un apprentissage sous-optimal des poids et à une instabilité du processus d'entraînement. \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMJHB4zgRCTw"
      },
      "source": [
        "## FastText\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc3RUc_TYDc"
      },
      "source": [
        "*ETAPE 1 :* \n",
        "\n",
        "Les méthodes [`texts_from_csv`](https://amaiya.github.io/ktrain/text/index.html#ktrain.text.texts_from_csv) ou [`texts_from_df`](https://amaiya.github.io/ktrain/text/index.html#ktrain.text.texts_from_df) charge le corpus, normalise les documents (définit un préprocesseur réutilisable), et découpe la collection en données d'entraînement et données de validation (à moins que des données de validation soient passées en argument).\n",
        "\n",
        "Cette étape est commune aux modèles FastText et NBSVM (`preprocess_mode='standard'`). BERT utilise son propre tokenizer. Il faudra faire un pré-traitement dédié (`preprocess_mode='bert'`).\n",
        "\n",
        "```\n",
        "* train_filepath(str): file path to training CSV\n",
        "* text_column(str): name of column containing the text\n",
        "* label_column(list): list of columns that are to be treated as labels\n",
        "* val_filepath(string): file path to test CSV.  If not supplied, 10% of documents in training CSV will be used for testing/validation.\n",
        "* max_features(int): max num of words to consider in vocabulary ; Note: This is only used for preprocess_mode='standard'.\n",
        "* maxlen(int): each document can be of most <maxlen> words. 0 is used as padding ID.\n",
        "* ngram_range(int): size of multi-word phrases to consider e.g., 2 will consider both 1-word phrases and 2-word phrases limited by max_features\n",
        "* preprocess_mode (str):  Either 'standard' (normal tokenization) or one of {'bert', 'distilbert'} tokenization and preprocessing for use with                BERT/DistilBert text classification model.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuKxqzFd3QBU",
        "outputId": "1d720c69-e7be-4bbc-afb1-e30f802b25c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative', 'positive']\n",
            "   negative  positive\n",
            "0         0         1\n",
            "1         1         0\n",
            "2         1         0\n",
            "3         0         1\n",
            "4         1         0\n",
            "['negative', 'positive']\n",
            "   negative  positive\n",
            "0         0         1\n",
            "1         0         1\n",
            "2         1         0\n",
            "3         1         0\n",
            "4         1         0\n",
            "language: fr\n",
            "Word Counts: 186307\n",
            "Nrows: 160000\n",
            "160000 train sequences\n",
            "train sequence lengths:\n",
            "\tmean : 87\n",
            "\t95percentile : 241\n",
            "\t99percentile : 303\n",
            "x_train shape: (160000,400)\n",
            "y_train shape: (160000, 2)\n",
            "Is Multi-Label? False\n",
            "20000 test sequences\n",
            "test sequence lengths:\n",
            "\tmean : 88\n",
            "\t95percentile : 247\n",
            "\t99percentile : 306\n",
            "x_test shape: (20000,400)\n",
            "y_test shape: (20000, 2)\n"
          ]
        }
      ],
      "source": [
        "# fasttext\n",
        "#NUM_WORDS = 50000\n",
        "#MAXLEN = 150\n",
        "#NGRAMS_SIZE = 1# 1 # 8 minutes avec 2 pour 10000 examples\n",
        "\n",
        "# nbsvm \n",
        "#NUM_WORDS = 80000\n",
        "#MAXLEN = 2000\n",
        "#NGRAMS_SIZE = 3\n",
        "\n",
        "(x_train_preproc, y_train_preproc), (x_val_preproc, y_val_preproc), preproc = text.texts_from_df (train_df, \n",
        "                                                                   'review', # name of column containing review text\n",
        "                                                                   label_columns=['negative', 'positive'],\n",
        "                                                                   val_df=val_df, # if None, 10% of data will be used for validation\n",
        "                                          #max_features=NUM_WORDS, \n",
        "                                          #maxlen=MAXLEN,\n",
        "                                          #ngram_range=NGRAMS_SIZE,\n",
        "                                          preprocess_mode='standard' # default\n",
        "                                          )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LktiVGh8NVSW"
      },
      "source": [
        "Observons les 5 premières des données prétraitées. `x_` représente la donnée et `y_` la classe. On note que les données ont été transformées. Chaque mot est remplacé par un identifiant. On note que la classe est décrite par 2 colonnes avec deux codes \"1 0\" et \"0 1\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzzWhW3ZHAq8",
        "outputId": "d7173e49-cce4-4584-b7ca-7c84e9080b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_preproc [[    0     0     0 ...   799     1  4242]\n",
            " [    0     0     0 ... 18669     1   802]\n",
            " [    0     0     0 ...  2196     1     4]\n",
            " [    0     0     0 ...   474   353   734]\n",
            " [    0     0     0 ...  8808    46    81]]\n",
            "y_train_preproc [[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print ('x_train_preproc', x_train_preproc[:5])\n",
        "print ('y_train_preproc', y_train_preproc[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHhCXpcQOPje"
      },
      "source": [
        "*ETAPE 2 et 3:* \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3jEacvRRuih",
        "outputId": "99cf8fbe-b730-430d-8f39-1f962ed37032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "compiling word ID features...\n",
            "maxlen is 400\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "# Build and return a text classification model https://amaiya.github.io/ktrain/text/index.html#ktrain.text.text_classifier\n",
        "fasttext_model = text.text_classifier('fasttext', (x_train_preproc, y_train_preproc), preproc=preproc)\n",
        "\n",
        "# Returns a Learner instance that can be used to tune and train Keras models https://amaiya.github.io/ktrain/index.html#ktrain.get_learner\n",
        "fasttext_learner = ktrain.get_learner(fasttext_model, train_data=(x_train_preproc, y_train_preproc), val_data=(x_val_preproc, y_val_preproc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufKylXAeOVCU"
      },
      "source": [
        "*ETAPE 4 :* \n",
        "\n",
        "La méthode [`lr_find`](https://amaiya.github.io/ktrain/core.html#ktrain.core.Learner.lr_find) implémente la méthode [*Cyclical Learning Rates*](https://arxiv.org/abs/1506.01186) qui permet d'estimer un lr sans une exploration systématique d'un lr qui décroit. L'approche peut prendre seulement le temps de quelques itérations (i.e. du traitement de quelques batchs) sans même tourner sur plusieurs époques. Pour rappel, une époque correspond au traitement de l'ensemble des données d'entrainements par lot/batch d'exemples. *For example,\n",
        "CIFAR-10 has 50, 000 training images and the batchsize is\n",
        "100 so an epoch = 50, 000/100 = 500 iterations*. \n",
        "\n",
        "Then plots loss as learning rate is increased.\n",
        "\n",
        "*Highest learning rate corresponding to a still falling loss should be chosen*. \"[The point of optimality [...] is the point on the training rate plot where the slope is steepest in the downwards direction. That's because this plot shows the loss after one epoch. Points before the steepest slope are training too slowly. Points after the steepest slope are at risk of training too quickly: usually, but not always (it didn't happen in this demo case), they will fall off the mountain in terms of loss because they jump past the point of optimality](https://www.kaggle.com/code/residentmario/finding-an-optimal-learning-rate-with-lr-finder)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "_9_32BN5Ur7e",
        "outputId": "940a1470-e4d4-499d-bf34-f1910a3fba79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n",
            "Epoch 1/1024\n",
            "5000/5000 [==============================] - 9s 2ms/step - loss: 349.5847 - accuracy: 0.5565\n",
            "\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# recherche d'un bon taux d'apprentissage \n",
        "# you can set max_epochs (e.g., max_epochs=5) to estimate LR\n",
        "fasttext_learner.lr_find() # \n",
        "fasttext_learner.lr_plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0eWERAHZ_Go"
      },
      "source": [
        "*ETAPE 5 :* \n",
        "\n",
        "[autofit](https://amaiya.github.io/ktrain/core.html#ktrain.core.Learner.autofit)\n",
        "Automatically train model using a default learning rate schedule shown to work well in practice.  By default, this method currently employs a triangular learning rate policy (https://arxiv.org/abs/1506.01186).  \n",
        "During each epoch, this learning rate policy varies the learning rate from lr/10 to lr and then back to a low learning rate that is near-zero. \n",
        "If epochs is None, then early_stopping and reduce_on_plateau are atomatically\n",
        "set to 6 and 3, respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOMvkq1ZPXV2"
      },
      "source": [
        "#### QUESTION : training\n",
        "\n",
        "* Sur le graph ci-dessus, repérez approximativement la puissance `n` de `1/10^n` où la chute de la loss devient importante. Testez avec cette valeur comme learning rate, observez votre performance (accuracy) sur le train et le val.\n",
        "\n",
        "Dans l'extrait de log ci-dessous, loss et accuracy concerne le corpus de train tandis que  val_loss et val_accuracy le corpus de validation (sur un corpus sample).\n",
        "```\n",
        "Epoch 12/1024\n",
        "244/250 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9589\n",
        "Restoring model weights from the end of the best epoch: 7.\n",
        "250/250 [==============================] - 1s 6ms/step - loss: 0.1108 - accuracy: 0.9589 - val_loss: 0.3864 - val_accuracy: 0.8820\n",
        "Epoch 12: early stopping\n",
        "```\n",
        "* Est-ce normal d'observer un écart d'accuracy entre le train et le val ?\n",
        "* Stoquez le score obtenu en dernière étape, et relancez le finetuning sans changer le paramétrage. Obtenez-vous les mêmes résultats ? Pourquoi ? La réponse est à chercher dans l'initiatilisation des poids du réseau neuronal.\n",
        "* Volontairement (et selon le temps qu'a pris votre entraînement) testez des lr avec d'autres puissances de 10 (0.1, 0.01, 0.001, 0.0001). Attention les lr les plus petites prendront le plus de temps !!! Est-ce que cela marche mieux ? Attention, suivant votre choix de lr l'entraînement peut prendre quelques minutes à au moins 1h....\n",
        "\n",
        "Mon meilleur score est `loss: 0.1108 - accuracy: 0.9589 - val_loss: 0.3864 - val_accuracy: 0.8820` sur le corpus sample et vous ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vY7oJU7U4G0",
        "outputId": "3de9b658-b00f-45a8-abae-a8ef74ca30f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.01...\n",
            "Epoch 1/1024\n",
            "5000/5000 [==============================] - 31s 6ms/step - loss: 0.3741 - accuracy: 0.8334 - val_loss: 0.2278 - val_accuracy: 0.9137\n",
            "Epoch 2/1024\n",
            "5000/5000 [==============================] - 30s 6ms/step - loss: 0.2830 - accuracy: 0.8863 - val_loss: 0.2105 - val_accuracy: 0.9179\n",
            "Epoch 3/1024\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.2657 - accuracy: 0.8947 - val_loss: 0.2112 - val_accuracy: 0.9179\n",
            "Epoch 4/1024\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.2505 - accuracy: 0.9014 - val_loss: 0.2077 - val_accuracy: 0.9181\n",
            "Epoch 5/1024\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2418 - accuracy: 0.9056 - val_loss: 0.2055 - val_accuracy: 0.9185\n",
            "Epoch 6/1024\n",
            "5000/5000 [==============================] - 32s 6ms/step - loss: 0.2338 - accuracy: 0.9099 - val_loss: 0.2054 - val_accuracy: 0.9204\n",
            "Epoch 7/1024\n",
            "5000/5000 [==============================] - 31s 6ms/step - loss: 0.2297 - accuracy: 0.9119 - val_loss: 0.2066 - val_accuracy: 0.9193\n",
            "Epoch 8/1024\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.2208 - accuracy: 0.9153 - val_loss: 0.2030 - val_accuracy: 0.9192\n",
            "Epoch 9/1024\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.2164 - accuracy: 0.9183 - val_loss: 0.2039 - val_accuracy: 0.9185\n",
            "Epoch 10/1024\n",
            "4994/5000 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9195\n",
            "Epoch 00010: Reducing Max LR on Plateau: new max lr will be 0.005 (if not early_stopping).\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.2110 - accuracy: 0.9195 - val_loss: 0.2061 - val_accuracy: 0.9183\n",
            "Epoch 11/1024\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1917 - accuracy: 0.9269 - val_loss: 0.2032 - val_accuracy: 0.9197\n",
            "Epoch 12/1024\n",
            "4999/5000 [============================>.] - ETA: 0s - loss: 0.1845 - accuracy: 0.9304\n",
            "Epoch 00012: Reducing Max LR on Plateau: new max lr will be 0.0025 (if not early_stopping).\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1845 - accuracy: 0.9304 - val_loss: 0.2053 - val_accuracy: 0.9187\n",
            "Epoch 13/1024\n",
            "5000/5000 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9348Restoring model weights from the end of the best epoch: 8.\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.2074 - val_accuracy: 0.9192\n",
            "Epoch 13: early stopping\n",
            "Weights from best epoch have been loaded into model.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa97611ab10>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "LEARNING_RATE = 0.01\n",
        "\n",
        "fasttext_learner.autofit(LEARNING_RATE)\n",
        "# Epoch 16/1024\n",
        "# 4491/4500 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9418Restoring model weights from the end of the best epoch: 11.\n",
        "# 4500/4500 [==============================] - 25s 6ms/step - loss: 0.1539 - accuracy: 0.9418 - val_loss: 0.2173 - val_accuracy: 0.9206\n",
        "# Epoch 16: early stopping\n",
        "\n",
        "# wi all allocine training dataset (at least one hour run) \n",
        "#learner.autofit(0.00001)\n",
        "# Epoch 129/1024\n",
        "# 4497/4500 [============================>.] - ETA: 0s - loss: 0.2197 - accuracy: 0.9135Restoring model weights from the end of the best epoch: 124.\n",
        "# 4500/4500 [==============================] - 29s 6ms/step - loss: 0.2197 - accuracy: 0.9135 - val_loss: 0.2058 - val_accuracy: 0.9204\n",
        "# Epoch 129: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqItionrS_z0"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL BACKUP AND LOAD\n",
        "\n",
        "Le code ci-dessous vous permet de sauver votre modèle pour des usages ultérieurs (il faudra ensuite le télécharger). Cela peut être utile pour des modèles construits sur la totalité des données."
      ],
      "metadata": {
        "id": "4ISGGgwY6HHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('fasttext_allocine.model', 'wb') as model_file:\n",
        "  pickle.dump(fasttext_learner, model_file)"
      ],
      "metadata": {
        "id": "5IZ_Sd5M6GB9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code suivant permet de charger un modèle (peut-être faudra t-il réexécuter jusqu'à l'étape 2-3)."
      ],
      "metadata": {
        "id": "vfNghJ0vqUcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# open a file, where you stored the pickled data\n",
        "with open('fasttext_allocine.model', 'rb') as model_file:\n",
        "  # load information to that file\n",
        "  fasttext_learner = pickle.load(model_file)"
      ],
      "metadata": {
        "id": "jcmyRsVdqT1r"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySqltk4KTHJ7"
      },
      "source": [
        "*ETAPE 6 :* Le code ci-dessous permet d'utiliser le modèle. Notez que le paramétrage `return_proba=True` permet d'obtenir les probas... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOiht1hPani6",
        "outputId": "6766832e-d49a-4777-8d13-d9e4eb487700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative', 'negative', 'negative']\n",
            "[[9.9992156e-01 7.8402598e-05]\n",
            " [9.9880421e-01 1.1957997e-03]\n",
            " [5.5950427e-01 4.4049579e-01]]\n"
          ]
        }
      ],
      "source": [
        "fasttext_predictor = ktrain.get_predictor(fasttext_learner.model, preproc)\n",
        "\n",
        "data = [ \"Ce film était horrible ! L'intrigue était ennuyeuse. Le jeu d'acteur était correct, cependant.\",\n",
        "         \"Le film est vraiment nul. Je veux qu'on me rende mon argent.\",\n",
        "        \"Quelle belle comédie romantique. 10/10 à revoir !\"]\n",
        "\n",
        "# Makes predictions for a list of strings where each string is a document or text snippet.\n",
        "print (fasttext_predictor.predict(data))\n",
        "\n",
        "# If return_proba is True, returns probabilities of each class.\n",
        "print (fasttext_predictor.predict(data,  return_proba=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5l8TyRWThZF"
      },
      "source": [
        "#### QUESTION : évaluation qualitative légère\n",
        "\n",
        "* Tester le modèle. Arrivez-vous à piéger le modèle ? Avec quelle phrase (donnez le code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkowscJhTiPh"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA5hf8I1dXul"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNZjuU8Bc4qI"
      },
      "source": [
        "### QUESTION : Evaluation quantitative\n",
        "\n",
        "Génération d'une hypothèse pour les *review* du corpus de test (`list(test_df['review'])`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews \n",
        "x_test = list(test_df['review'])\n",
        "\n",
        "# labels (gold) \n",
        "y_test = list(test_df['positive'])"
      ],
      "metadata": {
        "id": "V6BGVxPPvzvd"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "32x1JdOCc5Dw"
      },
      "outputs": [],
      "source": [
        "# hypothèse\n",
        "y_hyp = [0 if h == 'negative' else 1 for h in fasttext_predictor.predict(x_test) ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNPvtEt0PzK4"
      },
      "source": [
        "\n",
        "\n",
        "[SemEval 2022 isarcasmeval task](https://sites.google.com/view/semeval2022-isarcasmeval) used the F1-score for the sarcastic class. sklearn permet de spécifier cette mesure avec le paramètre `average = 'binary'` éventuellement accompagné du paramètre qui indique la classe à considérer `pos_label = 1`. This metric should not be confused with the regular macro-F1. sklearn permet de calculer un score macro à l'aide de la valeur `average = 'macro'`.\n",
        "Sans paramétrage c'est le F1-score d'une classe qui est retourné. Les performances rapportées par [Theophile Blart utilise aussi ce paramétrage par défaut](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "YI0p4xFFPzch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f20f242-b68e-4e15-e9cc-81c07b1581a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9181408981471789"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "f1_positive = f1_score(y_test, y_hyp, average = \"binary\", pos_label = 1)\n",
        "f1_positive\n",
        "#OR\n",
        "#p_score_positive = precision_score(y_test, y_hyp, average = \"binary\", pos_label = 1)\n",
        "#r_score_positive = recall_score(y_test, y_hyp, average = \"binary\", pos_label = 1)\n",
        "#f1_positive = (2*p_score_positive*r_score_positive)/(p_score_positive +r_score_positive)\n",
        "\n",
        "# 5 %   0.8922764227642277\n",
        "# 100 % 0.9181408981471789"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ1neD23ao8T"
      },
      "source": [
        "[Theophile Blard rapporte des performances avec différents modèles (CamemBERT, RNN, TF-IDF + LogReg, CNN, fastText (unigrams)) sur le dataset Allociné](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert). Comment vous positionnez-vous par rapport à ses résultats ?   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApxsjcDHE4Im"
      },
      "source": [
        "## NBSVM\n",
        "\n",
        "Le code ci-dessous utilise le même pré-traitement que précédemment et applique un modèle neuronal plus \"simple\" que fasttext.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGp2mrBsg17I",
        "outputId": "1ff047f6-8392-4b61-c89d-83c2fbb30f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "compiling word ID features...\n",
            "maxlen is 400\n",
            "building document-term matrix... this may take a few moments...\n",
            "rows: 1-10000\n",
            "rows: 10001-20000\n",
            "rows: 20001-30000\n",
            "rows: 30001-40000\n",
            "rows: 40001-50000\n",
            "rows: 50001-60000\n",
            "rows: 60001-70000\n",
            "rows: 70001-80000\n",
            "rows: 80001-90000\n",
            "rows: 90001-100000\n",
            "rows: 100001-110000\n",
            "rows: 110001-120000\n",
            "rows: 120001-130000\n",
            "rows: 130001-140000\n",
            "rows: 140001-150000\n",
            "rows: 150001-160000\n",
            "computing log-count ratios...\n",
            "done.\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.01...\n",
            "Epoch 1/1024\n",
            "5000/5000 [==============================] - 32s 6ms/step - loss: 0.2410 - accuracy: 0.9150 - val_loss: 0.2275 - val_accuracy: 0.9211\n",
            "Epoch 2/1024\n",
            "5000/5000 [==============================] - 31s 6ms/step - loss: 0.1923 - accuracy: 0.9310 - val_loss: 0.2478 - val_accuracy: 0.9190\n",
            "Epoch 3/1024\n",
            "4999/5000 [============================>.] - ETA: 0s - loss: 0.1797 - accuracy: 0.9358\n",
            "Epoch 00003: Reducing Max LR on Plateau: new max lr will be 0.005 (if not early_stopping).\n",
            "5000/5000 [==============================] - 26s 5ms/step - loss: 0.1797 - accuracy: 0.9358 - val_loss: 0.2651 - val_accuracy: 0.9173\n",
            "Epoch 4/1024\n",
            "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1520 - accuracy: 0.9446 - val_loss: 0.2644 - val_accuracy: 0.9179\n",
            "Epoch 5/1024\n",
            "4993/5000 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9471\n",
            "Epoch 00005: Reducing Max LR on Plateau: new max lr will be 0.0025 (if not early_stopping).\n",
            "5000/5000 [==============================] - 26s 5ms/step - loss: 0.1451 - accuracy: 0.9471 - val_loss: 0.2680 - val_accuracy: 0.9190\n",
            "Epoch 6/1024\n",
            "4994/5000 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9524Restoring model weights from the end of the best epoch: 1.\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1310 - accuracy: 0.9524 - val_loss: 0.2696 - val_accuracy: 0.9183\n",
            "Epoch 6: early stopping\n",
            "Weights from best epoch have been loaded into model.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa95da98fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# load an NBSVM model\n",
        "nbsvm_model = text.text_classifier('nbsvm', (x_train_preproc, y_train_preproc), preproc=preproc)\n",
        "nbsvm_learner = ktrain.get_learner(nbsvm_model, train_data=(x_train_preproc, y_train_preproc), val_data=(x_val_preproc, y_val_preproc))\n",
        "\n",
        "# fine tune\n",
        "LEARNING_RATE = 0.01\n",
        "nbsvm_learner.autofit(LEARNING_RATE)\n",
        "# Epoch 6/1024\n",
        "#4498/4500 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9544Restoring model weights from the end of the best epoch: 1.\n",
        "#4500/4500 [==============================] - 24s 5ms/step - loss: 0.1264 - accuracy: 0.9544 - val_loss: 0.2677 - val_accuracy: 0.9161\n",
        "#Epoch 6: early stopping\n",
        "\n",
        "# Finally, we will fit our model using and [SGDR learning rate](https://github.com/amaiya/ktrain/blob/master/example-02-tuning-learning-rates.ipynb) schedule by invoking the fit method with the cycle_len parameter (along with the cycle_mult parameter).\n",
        "# learner.fit(0.001, 3, cycle_len=1, cycle_mult=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "évaluation"
      ],
      "metadata": {
        "id": "JsEYbrTGxtv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# données\n",
        "x_test = list(test_df['review']) # reviews \n",
        "y_test = list(test_df['positive']) # labels (gold) \n",
        "\n",
        "# prédiction\n",
        "nbsvm_predictor = ktrain.get_predictor(nbsvm_learner.model, preproc)\n",
        "y_hyp = [0 if h == 'negative' else 1 for h in nbsvm_predictor.predict(x_test) ]\n",
        "\n",
        "# évaluation\n",
        "print(f1_score(y_test, y_hyp))\n",
        "\n",
        "# 5   % 0.903981180311341\n",
        "# 100 % 0.9203585411085926\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQhc_d1F_St9",
        "outputId": "7b627a08-df78-43ce-e028-6881f2ca7f3b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9203585411085926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "backup model"
      ],
      "metadata": {
        "id": "j85WVlKO54h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('nbsvm_allocine.model', 'wb') as model_file:\n",
        "  pickle.dump(nbsvm_learner, model_file)"
      ],
      "metadata": {
        "id": "fi7UPALQ52yQ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code suivant permet de charger un modèle (peut-être faudra t-il réexécuter jusqu'à l'étape 2-3)."
      ],
      "metadata": {
        "id": "V0Ep0XYDIzf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# open a file, where you stored the pickled data\n",
        "with open('nbsvm_allocine.model', 'rb') as model_file:\n",
        "  # load information to that file\n",
        "  nbsvm_learner = pickle.load(model_file)"
      ],
      "metadata": {
        "id": "KAwQk_jpItrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xveDFwSnUzj1"
      },
      "source": [
        "#### QUESTION\n",
        "\n",
        "* Le modèle nbsvm est-il plus performant que le précédent sur les données de validations ? Vous pouvez tester aussi différents learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilof7YlQNtfz"
      },
      "source": [
        "## BERT \n",
        "\n",
        "L'usage du modèle bert requiert que l'on change le prétraitement des données en entrée. Le code suivant réalise le prétraitement, charge un modèle bert et lance la personnalisation (fine tuning) sur 1 cycle avec taux d'apprentissage fixé.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "iAZQI0ucQWSa",
        "outputId": "f3944eda-a50c-477b-f8fc-ea25b38dd057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative', 'positive']\n",
            "   negative  positive\n",
            "0         0         1\n",
            "1         1         0\n",
            "2         1         0\n",
            "3         0         1\n",
            "4         1         0\n",
            "['negative', 'positive']\n",
            "   negative  positive\n",
            "0         0         1\n",
            "1         0         1\n",
            "2         1         0\n",
            "3         1         0\n",
            "4         1         0\n",
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: fr\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: fr\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ETAPE 1 \n",
        "(x_train_preproc, y_train_preproc), (x_val_preproc, y_val_preproc), preproc = text.texts_from_df (train_df, \n",
        "                      'review',\n",
        "                      label_columns = [\"negative\", \"positive\"],\n",
        "                      val_df= val_df, # if None, 10% of data will be used for validation\n",
        "                      ##max_features=NUM_WORDS, \n",
        "                      #maxlen=MAXLEN,\n",
        "                      preprocess_mode='bert' \n",
        "                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpI2LG_Wvqe"
      },
      "source": [
        "#### QUESTION\n",
        "* Exécutez le code en observant l'occupation de la RAM et attendez jusqu'à voir le temps prévisionnel s'afficher. Etes-vous choqué par le temps affiché ? BERT est très gros. Il requiert un peu de temps... Sur l'extrait le temps devrait être de 15 minutes à quelques heures sur le corpus complet.\n",
        "* Si vous êtes en phase d'exploration et que vous ne travaillez pas sur un extrait des données, stoppez l'exécution dans la cellule, et tentez de changer la taille du batch_size (quantité de données traitées en même temps). Vous pouvez tester 12 et éventuellement 128... comme valeurs. Ne lachez pas la barre de la RAM des yeux. Ça passe ? Quel problème rencontrez-vous ? \n",
        "* Reprenez... et passez à la suite..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0ujB3xihhnG",
        "outputId": "7bdf95cf-5b25-4f1f-d542-74c0b3107bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 400\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "1334/1334 [==============================] - 947s 694ms/step - loss: 0.3697 - accuracy: 0.8294 - val_loss: 0.2431 - val_accuracy: 0.8950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa94779c790>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# ETAPE 2 et 3\n",
        "bert_model = text.text_classifier('bert', (x_train_preproc, y_train_preproc) , preproc=preproc)\n",
        "bert_learner = ktrain.get_learner(bert_model, \n",
        "                             train_data=(x_train_preproc, y_train_preproc), \n",
        "                             val_data=(x_val_preproc, y_val_preproc), \n",
        "                             batch_size=6)\n",
        "# ETAPE 5\n",
        "bert_learner.fit_onecycle(2e-5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "évaluation"
      ],
      "metadata": {
        "id": "N3x1kk3U0P2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# données\n",
        "x_test = list(test_df['review'])   # reviews \n",
        "y_test = list(test_df['positive']) # labels (gold) \n",
        "\n",
        "# prédiction\n",
        "bert_predictor = ktrain.get_predictor(bert_learner.model, preproc)\n",
        "y_hyp = [0 if h == 'negative' else 1 for h in bert_predictor.predict(x_test) ]\n",
        "\n",
        "# évaluation\n",
        "print(f1_score(y_test, y_hyp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a33c6de-26e1-4f38-ca49-e9a37e44b1be",
        "id": "NH7qjU610P2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9126413155190133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ici évaluation sur toutes les données de test avec seulement un modèle construit sur un extrait"
      ],
      "metadata": {
        "id": "Ru4fwyzL_Py8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = hf_dataset_split_to_df(allocine_dataset['test'])\n",
        "# données\n",
        "x_test = list(test_df['review'])   # reviews \n",
        "y_test = list(test_df['positive']) # labels (gold) \n",
        "\n",
        "# prédiction\n",
        "bert_predictor = ktrain.get_predictor(bert_learner.model, preproc)\n",
        "y_hyp = [0 if h == 'negative' else 1 for h in bert_predictor.predict(x_test) ]\n",
        "\n",
        "# évaluation\n",
        "print(f1_score(y_test, y_hyp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSoPeviN_J7d",
        "outputId": "3964e2ca-b32b-401e-dc8f-74a7a426faa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9127885862516212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0r6CivJbBUF"
      },
      "source": [
        "## Modèle \"à la bert\" issu de hugging face\n",
        "\n",
        "De nombreux [modèles sont disponibles sur HuggingFace](https://huggingface.co/models). \n",
        "\n",
        "On va tester un modèle plus léger que BERT à savoir 'distilbert-base-uncased'. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = list(train_df['review'])\n",
        "y_train = list(train_df['positive'])\n",
        "\n",
        "x_val = list(val_df['review'])\n",
        "y_val = list(val_df['positive'])\n",
        "\n",
        "x_test = list(test_df['review'])\n",
        "y_test = list(test_df['positive'])\n",
        "\n",
        "## Do not consider the following\n",
        "\n",
        "## Convert a list of string into lists of int then into np.array.\n",
        "## This step should be skiped when running BERT\n",
        "\n",
        "#import numpy as np\n",
        "#y_train = np.array(list(map(int, y_train)))\n",
        "#y_val = np.array(list(map(int, y_val)))\n",
        "#y_test = np.array(list(map(int, y_test)))\n",
        "\n",
        "#print ('x_train', len(x_train), x_train[:10])\n",
        "#print ('y_train',  len(y_train), y_train[:10])\n",
        "#print ('x_val', len(x_val), x_val[:10])\n",
        "#print ('y_val',  len(y_val), y_val[:10])\n",
        "#print ('x_test', len(x_test))\n",
        "#print ('y_test',  len(y_test))"
      ],
      "metadata": {
        "id": "kDBwr4fvzOCU"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "52DqPKJE9d4s",
        "outputId": "f0881fd4-41d0-4177-d9eb-371482a4126c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: fr\n",
            "train sequence lengths:\n",
            "\tmean : 91\n",
            "\t95percentile : 254\n",
            "\t99percentile : 320\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: fr\n",
            "test sequence lengths:\n",
            "\tmean : 92\n",
            "\t95percentile : 260\n",
            "\t99percentile : 322\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "#MODEL_NAME = 'albert-base-v2'\n",
        "#MODEL_NAME = 'camembert-base'\n",
        "\n",
        "CLASS_NAMES = [\"negative\", \"positive\"]\n",
        "\n",
        "distilbert_preproc = text.Transformer(MODEL_NAME, maxlen=500, class_names=CLASS_NAMES)\n",
        "train_preproc = distilbert_preproc.preprocess_train(x_train, y_train)\n",
        "val_preproc = distilbert_preproc.preprocess_test(x_val, y_val)\n",
        "#print (type(trn))\n",
        "#x_train, y_train = trn\n",
        "#x_test, y_test = val  \n",
        "distilbert_model = distilbert_preproc.get_classifier()\n",
        "# batch_size (int):              Batch size to use in training. default:32  \n",
        "#learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6) # 128 dépend de la ram dispo 13 Go par défaut\n",
        "distilbert_learner = ktrain.get_learner(distilbert_model, train_data=train_preproc, val_data=val_preproc, batch_size=12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del distilbert_preproc\n",
        "#del train_preproc\n",
        "#del val_preproc\n",
        "#del distilbert_model\n",
        "#del distilbert_learner"
      ],
      "metadata": {
        "id": "VrmoU03yM6-G"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqM1-j84-4eD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0d913d-f225-4bb0-f1ab-3f113e50e4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.01...\n",
            "  454/13334 [>.............................] - ETA: 2:26:14 - loss: 0.7042 - accuracy: 0.5083"
          ]
        }
      ],
      "source": [
        "distilbert_learner.fit_onecycle(0.01, 1)\n",
        "#learner.fit_onecycle(8e-5, 4)\n",
        "#8e-5 = 8 + 10^(-5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# données\n",
        "x_test = list(test_df['review'])   # reviews \n",
        "y_test = list(test_df['positive']) # labels (gold) \n",
        "\n",
        "# prédiction\n",
        "distilbert_predictor = ktrain.get_predictor(distilbert_learner.model, distilbert_preproc)\n",
        "y_hyp = [0 if h == 'negative' else 1 for h in distilbert_predictor.predict(x_test) ]\n",
        "\n",
        "# évaluation\n",
        "print(f1_score(y_test, y_hyp))\n",
        "# distilbert-base-uncased train sur 5 % 0.6577181208053691\n"
      ],
      "metadata": {
        "id": "LH253Lbk_yXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "backup model"
      ],
      "metadata": {
        "id": "qw8UvziY5vmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('distilbert_allocine.model', 'wb') as model_file:\n",
        "  pickle.dump(distilbert_learner, model_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3mr7y5I5eLf",
        "outputId": "55ca1691-af49-45e9-a231-a33ca0e65a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeM-jNIyb_7M"
      },
      "source": [
        "#### QUESTION\n",
        "* Quelle performance obtenez-vous avec BERT et distilBERT pour quel temps d'entraînement ? Quelle performance comparativement aux 2 modèles précédents nbsvm et fasttext ?\n",
        "* Quelles risques prenez-vous à ne pas réaliser les mêmes prétraitements ou normalisations (voire utiliser des outils différents pour réaliser les mêmes prétraitements ou normalisations supposées) que ceux réalisés sur les corpus ayant servis à construire les modèles ? \n",
        "* En résumé, en mettant dans la balance les questions de performance, les questions de taille de modèles, de temps de \"fine-tuning\"... quelles conclusions faites-vous de l'usage des modèles simples vs les modèles plus complexes à la BERT ?\n",
        "\n",
        "Si le code tourne toujours passez à la question suivante pour gagner du temps..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qni8ELuBcBB1"
      },
      "source": [
        "#### VOTRE REPONSE\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOyw5WCCJX4"
      },
      "source": [
        "# Devoir à rendre \n",
        "[Theophile Blard rapporte des performances avec différents modèles (CamemBERT, RNN, TF-IDF + LogReg, CNN, fastText (unigrams)) sur le dataset Allociné](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert). \n",
        "\n",
        "\n",
        "| Model                                        | Validation Accuracy | Validation F1-Score | Test Accuracy | Test F1-Score |\n",
        "| :--------------------------------------------|--------------------:| -------------------:| -------------:|--------------:|\n",
        "| **[CamemBERT][bert.ipynb]**                  |           **97.39** |           **97.36** |     **97.44** |     **97.34** |\n",
        "| [RNN]                    |               94.39 |               94.34 |         94.58 |         94.39 |\n",
        "| [TF-IDF + LogReg]              |               94.35 |               94.29 |         94.38 |         94.19 |\n",
        "| [CNN]                    |               93.69 |               93.72 |         94.10 |         93.98 |\n",
        "| [fastText (unigrams)]    |               92.88 |               92.75 |         92.90 |         92.57 |\n",
        "\n",
        "\n",
        "Arriverez-vous à faire mieux ?\n",
        "\n",
        "Bien entendu vous avez le droit de choisir les modèles et leur configuration.\n",
        "\n",
        "Explorez les thèmes suivants\n",
        "- data augmentation\n",
        "- model ensembling \n",
        "\n",
        "Ecrivez un rapport d'expériences.\n",
        "\n",
        "## Topics\n",
        "\n",
        "### Data augmentation in NLP\n",
        "TextAttack is a Python framework for adversarial attacks, adversarial training, and [data augmentation in NLP](https://textattack.readthedocs.io/en/latest/2notebook/3_Augmentations.html).\n",
        "\n",
        "Here some hints for [multi-language attacks](https://textattack.readthedocs.io/en/latest/2notebook/Example_4_CamemBERT.html)\n",
        "\n",
        "### Model ensembling \n",
        "\n",
        "- Train/fine-tune multiple models from various architectures and/or dataset folds\n",
        "- Then ensemble them by (hard/soft) voting mechanism or something else...\n",
        "\n",
        "\n",
        "\n",
        "## VOTRE REPONSE\n",
        "\n",
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU6olWGuGzN6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tzxoRA_RGl4"
      },
      "source": [
        "# Références\n",
        "* Text Classification Example: Sentiment Analysis with IMDb Movie Reviews¶ https://nbviewer.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-04-text-classification.ipynb\n",
        "* https://nbviewer.org/github/amaiya/ktrain/blob/master/examples/text/IMDb-BERT.ipynb\n",
        "* ktrain examples of Binary text Classification (Sentiment Analysis with IMDb Movie Reviews) with a nbsvm model (also a bit of bert)  and \n",
        "Multi-Label Text Classification (toxic comments) with fasttext https://nbviewer.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-04-text-classification.ipynb\n",
        "* Text Classification with Hugging Face Transformers in ktrain https://github.com/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb\n",
        "* ktrain api documentation https://amaiya.github.io/ktrain/\n",
        "* Evaluation of various models (CamemBERT, RNN, TF-IDF + LogReg, CNN, fastText (unigrams)) on allocine dataset https://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n",
        "* The Allociné dataset is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the Allociné.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \n",
        "https://huggingface.co/datasets/allocine\n",
        "* Amazon reviews for three product categories: books, DVD, and music. Each sample contains a review text and the associated rating from 1 to 5 stars. Reviews rated above 3 is labeled as positive, and those rated less than 3 is labeled as negative. https://github.com/getalp/Flaubert/tree/master/flue\n",
        "* Twitter API between May and September 2018. The sentiment was generated thanks to AWS Comprehend API. For Spanish and French, tweets were first translated to English using Google Translate, and then analyzed with AWS Comprehend. https://github.com/charlesmalafosse/open-dataset-for-sentiment-analysis/\n",
        "* French dataset for sentiment analysis (Data translated from English to French).  A collection of over 1.5 Million tweets data translated to French, with their sentiment. The data has two columns, polarity and status https://github.com/gamebusterz/French-Sentiment-Analysis-Dataset\n",
        "* English Classification datasets https://ludwig.ai/latest/examples/text_classification/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyME8ORPHAdSbxvsejAto+n/",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e3c37d026b342a98099570c69041ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1abed1f130624b51ae9e28e790231f0e",
              "IPY_MODEL_13907da6d316429a8d2aa4352308d9fb",
              "IPY_MODEL_824c678dabe84dab8ed45e11cec05d56"
            ],
            "layout": "IPY_MODEL_ebc37f85026e4f57b7e572d35de0e3a7"
          }
        },
        "1abed1f130624b51ae9e28e790231f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c6925644584f14bb3a50a1812ac013",
            "placeholder": "​",
            "style": "IPY_MODEL_440d69351b164f789c8968bb7de18a02",
            "value": "100%"
          }
        },
        "13907da6d316429a8d2aa4352308d9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97838a8a50454d229332fa03aac68c48",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c56100a330a46a3874a672fdee9283e",
            "value": 3
          }
        },
        "824c678dabe84dab8ed45e11cec05d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d04c416b3640f390e02cba5f57b102",
            "placeholder": "​",
            "style": "IPY_MODEL_99fae420c32549f5a8a02db02306c777",
            "value": " 3/3 [00:00&lt;00:00, 78.39it/s]"
          }
        },
        "ebc37f85026e4f57b7e572d35de0e3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c6925644584f14bb3a50a1812ac013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440d69351b164f789c8968bb7de18a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97838a8a50454d229332fa03aac68c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c56100a330a46a3874a672fdee9283e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94d04c416b3640f390e02cba5f57b102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99fae420c32549f5a8a02db02306c777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}